# Codebook for MSc Dissertation - Urban Spatial Science
## Gavin Rolls

This is a repository storing all of the code written for my MSc Dissertation in Urban Spatial Science, which focuses on using OvertureMaps POIs to model local employment

A number of different datasets exceed GitHub size limits and have correspondingly not been uploaded to GitHub. Most notably, raw data and machine learning results will not be visible, but all scripts are avaliable here.

## Files in this notebook

The list of `.ipynb` files and their purposes are listed below

`DataQuerying.ipynb` connects with AWS using DuckDB to query the list of POIs in Birmingham and London from the OvertureMaps foundation, and uses the `osmnx` library to query a complete list of OSM building footprints as well as a handful of specific building types.

`DataCleaning.ipynb` contains every pre-processing step used to prepare the raw OSM and OvertureMaps data for use in employment modelling. This includes the loading of any datasets downloaded from the internet, extracting features at the LSOA level, generating POI category counts per LSOA, extracting geographic features of building footprints, and collapsing the POI feature spaces to a more managable size.

`Modelling.ipynb` executes all machine learning models generated using the pipeline described in the report, in addition to defining a handful of the parameters (e.g. feature lists) used to run each model

`Plots.ipynb` Is a master-file for generating and styling almost all of the plots used in the final thesis. No futher analysis is performed in here. The only plots not included in this file are those used concerned with analysis of model outliers and demographic similarities, which is performed in the final file.

`OutlierAnalysis.ipynb` is a separate file that handles the entire pipeline of model outlier analysis, from downloading demographic data to running the analysis and plotting the results. Aside from its reliance on model results, it's a standalone file.

All plots used (regardless of source file) are stored in the `\Plots` directory, which consists mostly of images generated in the aforementioned notebook, but also contains a handful of images from external sources.

## To run this notebook

I've used Jupyter Notebook to write and run my code. If you don't
already have Jupyter Notebook installed, you can run the following in console.

```
pip install jupyter 
```

or

```
brew install jupyter
```

To open a notebook after installation, run

```
jupyter notebook
```

Which should open the Jupyter Dashboard in a localhost window on your browser. All code notebooks can be found in the project root folder. Opening any will allow you to view the requisite code, which can be run using the Python3 IPython Kernel, assuming the requisite libraries and data are in place.

## Required Packages/Libraries

A number of Python libraries/ are required to run the code stored. Each notebook will start with a code chunk dedicated to the entire list of imports needed for the code blocks in that notebook. I advise simply running through the list and using `pip` or `brew` to install each as needed.

## Ignored and Excluded Files

Due to the use of extremely large datasets (>3GB of total data) and extensive model reports as generated by `AutoML`, the `/data` and `/ml_results` directories are not uploaded to GitHub and are instead stored locally. Some datasets, such as OpenStreetMap and OvertureMaps POI data, were queried directly from source in `DataQuerying.ipynb`. Others, including those in the `\data/combined_data` directory were generated as a result of joining or manipulation performed in other sections of the code provided. To run the full set of code, however, datasets such as the Business Register and Employment Survey (BRES) or LSOA-level geographic data will have to be queried independently from online. Table No. 1 in the Dissertation lists every dataset used and its source. All datasets are open and can be accessed without credential.
