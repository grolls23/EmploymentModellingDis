{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7542fb7-3702-466a-8c2d-837e1e6d4ed3",
   "metadata": {},
   "source": [
    "# Modelling\n",
    "\n",
    "This is the script where I store all my ML model runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d305a93-526f-4ed4-993f-96d593fc9618",
   "metadata": {},
   "source": [
    "## Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b90b1626-165f-4b79-8d67-7b3afa023602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library Imports\n",
    "\n",
    "#Basics\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "#Shapely / Spatial\n",
    "from shapely import wkt\n",
    "import shapely.geometry\n",
    "from shapely.geometry import Polygon, MultiPolygon\n",
    "\n",
    "#Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#ML from mljar-supervised\n",
    "from supervised.automl import AutoML\n",
    "\n",
    "#Warning Supression\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31ea067-af33-4415-b9e7-4d3426573f62",
   "metadata": {},
   "source": [
    "### Import Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53f05a2a-040b-45cd-8108-192d695dea50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>LSOA11CD</th>\n",
       "      <th>LSOA11NM_x</th>\n",
       "      <th>LSOA11NM_y</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>population</th>\n",
       "      <th>Area</th>\n",
       "      <th>01 : Crop and animal production, hunting and related service activities</th>\n",
       "      <th>02 : Forestry and logging</th>\n",
       "      <th>03 : Fishing and aquaculture</th>\n",
       "      <th>...</th>\n",
       "      <th>lag_travel</th>\n",
       "      <th>lag_travel_agents</th>\n",
       "      <th>lag_trusts</th>\n",
       "      <th>lag_university_housing</th>\n",
       "      <th>lag_used_vintage_and_consignment</th>\n",
       "      <th>lag_veterinarian</th>\n",
       "      <th>lag_videographer</th>\n",
       "      <th>lag_vitamins_and_supplements</th>\n",
       "      <th>lag_warehouses</th>\n",
       "      <th>lag_window_washing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>E01008881</td>\n",
       "      <td>Birmingham 067A</td>\n",
       "      <td>Birmingham 067A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1599</td>\n",
       "      <td>lsoa2011:E01008881 : Birmingham 067A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>E01008882</td>\n",
       "      <td>Birmingham 066A</td>\n",
       "      <td>Birmingham 066A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1747</td>\n",
       "      <td>lsoa2011:E01008882 : Birmingham 066A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>E01008883</td>\n",
       "      <td>Birmingham 078A</td>\n",
       "      <td>Birmingham 078A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1816</td>\n",
       "      <td>lsoa2011:E01008883 : Birmingham 078A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>E01008884</td>\n",
       "      <td>Birmingham 078B</td>\n",
       "      <td>Birmingham 078B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1870</td>\n",
       "      <td>lsoa2011:E01008884 : Birmingham 078B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>E01008885</td>\n",
       "      <td>Birmingham 076A</td>\n",
       "      <td>Birmingham 076A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1308</td>\n",
       "      <td>lsoa2011:E01008885 : Birmingham 076A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>634</td>\n",
       "      <td>E01033646</td>\n",
       "      <td>Birmingham 031I</td>\n",
       "      <td>Birmingham 031I</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1624</td>\n",
       "      <td>lsoa2011:E01033646 : Birmingham 031I</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>635</td>\n",
       "      <td>E01033647</td>\n",
       "      <td>Birmingham 058E</td>\n",
       "      <td>Birmingham 058E</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1398</td>\n",
       "      <td>lsoa2011:E01033647 : Birmingham 058E</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>636</td>\n",
       "      <td>E01033648</td>\n",
       "      <td>Birmingham 084F</td>\n",
       "      <td>Birmingham 084F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2715</td>\n",
       "      <td>lsoa2011:E01033648 : Birmingham 084F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>637</td>\n",
       "      <td>E01033649</td>\n",
       "      <td>Birmingham 058F</td>\n",
       "      <td>Birmingham 058F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1801</td>\n",
       "      <td>lsoa2011:E01033649 : Birmingham 058F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>638</td>\n",
       "      <td>E01033650</td>\n",
       "      <td>Birmingham 077F</td>\n",
       "      <td>Birmingham 077F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2596</td>\n",
       "      <td>lsoa2011:E01033650 : Birmingham 077F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>639 rows Ã— 742 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0   LSOA11CD       LSOA11NM_x       LSOA11NM_y  Unnamed: 2  \\\n",
       "0             0  E01008881  Birmingham 067A  Birmingham 067A         0.0   \n",
       "1             1  E01008882  Birmingham 066A  Birmingham 066A         0.0   \n",
       "2             2  E01008883  Birmingham 078A  Birmingham 078A         0.0   \n",
       "3             3  E01008884  Birmingham 078B  Birmingham 078B         0.0   \n",
       "4             4  E01008885  Birmingham 076A  Birmingham 076A         0.0   \n",
       "..          ...        ...              ...              ...         ...   \n",
       "634         634  E01033646  Birmingham 031I  Birmingham 031I         0.0   \n",
       "635         635  E01033647  Birmingham 058E  Birmingham 058E         0.0   \n",
       "636         636  E01033648  Birmingham 084F  Birmingham 084F         0.0   \n",
       "637         637  E01033649  Birmingham 058F  Birmingham 058F         0.0   \n",
       "638         638  E01033650  Birmingham 077F  Birmingham 077F         0.0   \n",
       "\n",
       "     population                                  Area  \\\n",
       "0          1599  lsoa2011:E01008881 : Birmingham 067A   \n",
       "1          1747  lsoa2011:E01008882 : Birmingham 066A   \n",
       "2          1816  lsoa2011:E01008883 : Birmingham 078A   \n",
       "3          1870  lsoa2011:E01008884 : Birmingham 078B   \n",
       "4          1308  lsoa2011:E01008885 : Birmingham 076A   \n",
       "..          ...                                   ...   \n",
       "634        1624  lsoa2011:E01033646 : Birmingham 031I   \n",
       "635        1398  lsoa2011:E01033647 : Birmingham 058E   \n",
       "636        2715  lsoa2011:E01033648 : Birmingham 084F   \n",
       "637        1801  lsoa2011:E01033649 : Birmingham 058F   \n",
       "638        2596  lsoa2011:E01033650 : Birmingham 077F   \n",
       "\n",
       "     01 : Crop and animal production, hunting and related service activities  \\\n",
       "0                                                  0.0                         \n",
       "1                                                  0.0                         \n",
       "2                                                  0.0                         \n",
       "3                                                  0.0                         \n",
       "4                                                  0.0                         \n",
       "..                                                 ...                         \n",
       "634                                                0.0                         \n",
       "635                                                0.0                         \n",
       "636                                                0.0                         \n",
       "637                                                0.0                         \n",
       "638                                                0.0                         \n",
       "\n",
       "     02 : Forestry and logging  03 : Fishing and aquaculture  ...  lag_travel  \\\n",
       "0                          0.0                           0.0  ...    0.000000   \n",
       "1                          0.0                           0.0  ...    0.166667   \n",
       "2                          0.0                           0.0  ...    0.166667   \n",
       "3                          0.0                           0.0  ...    0.333333   \n",
       "4                          0.0                           0.0  ...    0.000000   \n",
       "..                         ...                           ...  ...         ...   \n",
       "634                        0.0                           0.0  ...    0.166667   \n",
       "635                        0.0                           0.0  ...    0.166667   \n",
       "636                        0.0                           0.0  ...    0.000000   \n",
       "637                        0.0                           0.0  ...    0.333333   \n",
       "638                        0.0                           0.0  ...    0.000000   \n",
       "\n",
       "     lag_travel_agents  lag_trusts  lag_university_housing  \\\n",
       "0             0.166667         0.0                     0.0   \n",
       "1             0.000000         0.0                     0.0   \n",
       "2             0.000000         0.0                     0.0   \n",
       "3             0.000000         0.0                     0.0   \n",
       "4             0.166667         0.0                     0.0   \n",
       "..                 ...         ...                     ...   \n",
       "634           0.000000         0.0                     0.0   \n",
       "635           0.000000         0.0                     0.0   \n",
       "636           0.000000         0.0                     0.0   \n",
       "637           0.000000         0.0                     0.0   \n",
       "638           0.000000         0.0                     0.0   \n",
       "\n",
       "     lag_used_vintage_and_consignment  lag_veterinarian  lag_videographer  \\\n",
       "0                                 0.0               0.0               0.0   \n",
       "1                                 0.0               0.0               0.0   \n",
       "2                                 0.0               0.0               0.0   \n",
       "3                                 0.0               0.0               0.0   \n",
       "4                                 0.0               0.0               0.0   \n",
       "..                                ...               ...               ...   \n",
       "634                               0.0               0.0               0.0   \n",
       "635                               0.0               0.0               0.0   \n",
       "636                               0.0               0.0               0.0   \n",
       "637                               0.0               0.0               0.0   \n",
       "638                               0.0               0.0               0.0   \n",
       "\n",
       "     lag_vitamins_and_supplements  lag_warehouses  lag_window_washing  \n",
       "0                        0.000000        0.333333                 0.0  \n",
       "1                        0.000000        0.500000                 0.0  \n",
       "2                        0.000000        0.000000                 0.0  \n",
       "3                        0.166667        0.500000                 0.0  \n",
       "4                        0.000000        0.000000                 0.0  \n",
       "..                            ...             ...                 ...  \n",
       "634                      0.166667        0.000000                 0.0  \n",
       "635                      0.000000        0.000000                 0.0  \n",
       "636                      0.000000        0.000000                 0.0  \n",
       "637                      0.166667        0.000000                 0.0  \n",
       "638                      0.000000        0.000000                 0.0  \n",
       "\n",
       "[639 rows x 742 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read London CSV\n",
    "all_data_london = pd.read_csv(\"data/combined_data/lag/all_data_london_lag.csv\")\n",
    "\n",
    "# Read in feature column set\n",
    "with open(\"data/combined_data/total_feature_columns_london.csv\", 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Reconstruct\n",
    "feature_columns_london_lag = [''.join(line.strip().split(',')) for line in lines]\n",
    "\n",
    "# Create non-laged column set\n",
    "feature_columns_london = [col for col in feature_columns_london_lag if not col.startswith('lag_')]\n",
    "\n",
    "# ---\n",
    "\n",
    "# Read Birmingham CSV\n",
    "all_data_bham = pd.read_csv(\"data/combined_data/lag/all_data_bham_lag.csv\")\n",
    "\n",
    "# Read in feature column set\n",
    "with open(\"data/combined_data/total_feature_columns_bham.csv\", 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Reconstruct\n",
    "feature_columns_bham_lag = [''.join(line.strip().split(',')) for line in lines]\n",
    "\n",
    "# Create non-lagged column set\n",
    "feature_columns_bham = [col for col in feature_columns_bham_lag if not col.startswith('lag_')]\n",
    "\n",
    "# Fix null values ending up in logged variables\n",
    "all_data_london.fillna(0)\n",
    "all_data_bham.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "581a5ad1-f57d-4764-b71b-568a4e4f8c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Download POI & auxillary-only feature spaces (No building footprint information)\n",
    "\n",
    "# London\n",
    "# Read in POI feature column set\n",
    "with open(\"data/combined_data/feature_columns_london_poi.csv\", 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Reconstruct\n",
    "feature_columns_london_poi = [''.join(line.strip().split(',')) for line in lines]\n",
    "\n",
    "# Birmingham\n",
    "# Read in POI feature column set\n",
    "with open(\"data/combined_data/feature_columns_bham_poi.csv\", 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Reconstruct\n",
    "feature_columns_bham_poi = [''.join(line.strip().split(',')) for line in lines]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5488444a-67fc-4aca-8e79-065018e090cb",
   "metadata": {},
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e93f99a8-c74f-4436-8877-6d11cc2f3103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model has already been fitted. You can use predict methods or select a new 'results_path' for a new 'fit()'.\n",
      "R^2 Score: 0.7207009026018532\n",
      "RMSE: 0.678412914276123\n"
     ]
    }
   ],
   "source": [
    "# Ignore depracation warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london_lag\n",
    "target = 'log_total_employment'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(results_path=\"ml_results/dummy_models/test\", mode='Explain')\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_log_employment = r2_score(y_test, predictions)\n",
    "rmse_log_employment = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_log_employment}')\n",
    "print(f'RMSE: {rmse_log_employment}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all = automl.predict(all_data_london[features])\n",
    "geometries = all_data_london.loc[all_data_london[target].index, 'geometry']\n",
    "\n",
    "results_test = pd.DataFrame({\n",
    "    'geometry': geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca014449-6c4c-46d6-ba87-a578cbb9881d",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ce02ced4-41b4-46d0-89da-b9900f64442d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: ml_results/log_employment_london/\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['CatBoost', 'Xgboost', 'Random Forest']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "1_Default_Xgboost rmse 0.638237 trained in 44.72 seconds\n",
      "2_Default_CatBoost rmse 0.624872 trained in 39.45 seconds\n",
      "3_Default_RandomForest rmse 0.692124 trained in 1092.47 seconds\n",
      "* Step not_so_random will try to check up to 12 models\n",
      "4_Xgboost rmse 0.647595 trained in 31.74 seconds\n",
      "8_CatBoost rmse 0.62888 trained in 57.43 seconds\n",
      "12_RandomForest rmse 0.689969 trained in 42.49 seconds\n",
      "5_Xgboost rmse 0.646129 trained in 955.1 seconds\n",
      "9_CatBoost rmse 0.640378 trained in 954.04 seconds\n",
      "13_RandomForest rmse 0.713245 trained in 57.77 seconds\n",
      "6_Xgboost rmse 0.631339 trained in 29.05 seconds\n",
      "10_CatBoost rmse 0.627944 trained in 359.69 seconds\n",
      "14_RandomForest rmse 0.677261 trained in 62.38 seconds\n",
      "7_Xgboost rmse 0.635899 trained in 27.49 seconds\n",
      "11_CatBoost rmse 0.65143 trained in 42.03 seconds\n",
      "15_RandomForest rmse 0.67456 trained in 313.99 seconds\n",
      "Skip hill_climbing_1 because of the time limit.\n",
      "Skip hill_climbing_2 because of the time limit.\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble rmse 0.617282 trained in 0.17 seconds\n",
      "AutoML fit time: 4117.39 seconds\n",
      "AutoML best model: Ensemble\n",
      "R^2 Score: 0.7578170639491384\n",
      "RMSE: 0.6317294239997864\n"
     ]
    }
   ],
   "source": [
    "### Employment (log), NO Spatial Lag, London (1)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london\n",
    "target = 'log_total_employment'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/log_employment_london/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_1 = r2_score(y_test, predictions)\n",
    "rmse_1 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_1}')\n",
    "print(f'RMSE: {rmse_1}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_1 = automl.predict(all_data_london[features])\n",
    "london_geometries = all_data_london.loc[all_data_london[target].index, 'geometry']\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': london_geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all_1,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ac80575c-2245-4464-abdd-a8997967e727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: ml_results/log_employment_bham/\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['CatBoost', 'Xgboost', 'Random Forest']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "1_Default_Xgboost rmse 0.803686 trained in 5.65 seconds\n",
      "2_Default_CatBoost rmse 0.783334 trained in 18.54 seconds\n",
      "3_Default_RandomForest rmse 0.821087 trained in 24.78 seconds\n",
      "* Step not_so_random will try to check up to 12 models\n",
      "4_Xgboost rmse 0.807126 trained in 5.22 seconds\n",
      "8_CatBoost rmse 0.810248 trained in 22.31 seconds\n",
      "12_RandomForest rmse 0.816138 trained in 57.95 seconds\n",
      "5_Xgboost rmse 0.808929 trained in 5.8 seconds\n",
      "9_CatBoost rmse 0.830576 trained in 20.01 seconds\n",
      "13_RandomForest rmse 0.848962 trained in 56.66 seconds\n",
      "6_Xgboost rmse 0.791632 trained in 4.91 seconds\n",
      "10_CatBoost rmse 0.811724 trained in 19.82 seconds\n",
      "14_RandomForest rmse 0.817142 trained in 24.16 seconds\n",
      "7_Xgboost rmse 0.861031 trained in 4.85 seconds\n",
      "11_CatBoost rmse 0.854616 trained in 19.84 seconds\n",
      "15_RandomForest rmse 0.824156 trained in 65.1 seconds\n",
      "* Step hill_climbing_1 will try to check up to 18 models\n",
      "16_CatBoost rmse 0.795161 trained in 19.39 seconds\n",
      "17_CatBoost rmse 0.799599 trained in 18.81 seconds\n",
      "18_Xgboost rmse 0.792724 trained in 5.24 seconds\n",
      "19_Xgboost rmse 0.798389 trained in 5.27 seconds\n",
      "20_Xgboost rmse 0.801649 trained in 5.36 seconds\n",
      "21_Xgboost rmse 0.801951 trained in 5.54 seconds\n",
      "22_Xgboost rmse 0.797301 trained in 5.28 seconds\n",
      "23_Xgboost rmse 0.81387 trained in 5.55 seconds\n",
      "24_CatBoost rmse 0.809749 trained in 47.23 seconds\n",
      "25_CatBoost rmse 0.819835 trained in 20.94 seconds\n",
      "26_CatBoost rmse 0.801445 trained in 21.29 seconds\n",
      "27_CatBoost rmse 0.825881 trained in 19.57 seconds\n",
      "28_RandomForest rmse 0.812049 trained in 55.3 seconds\n",
      "29_RandomForest rmse 0.820499 trained in 26.16 seconds\n",
      "30_RandomForest rmse 0.809917 trained in 25.73 seconds\n",
      "31_RandomForest rmse 0.829734 trained in 24.04 seconds\n",
      "32_RandomForest rmse 0.816113 trained in 56.83 seconds\n",
      "33_RandomForest rmse 0.820707 trained in 24.05 seconds\n",
      "* Step hill_climbing_2 will try to check up to 10 models\n",
      "34_Xgboost rmse 0.797041 trained in 5.24 seconds\n",
      "35_Xgboost rmse 0.798353 trained in 5.45 seconds\n",
      "36_Xgboost rmse 0.798988 trained in 6.04 seconds\n",
      "37_Xgboost rmse 0.798183 trained in 5.87 seconds\n",
      "38_CatBoost rmse 0.792413 trained in 22.1 seconds\n",
      "39_Xgboost rmse 0.801037 trained in 6.73 seconds\n",
      "40_RandomForest rmse 0.805922 trained in 956.12 seconds\n",
      "41_RandomForest rmse 0.80454 trained in 29.39 seconds\n",
      "42_RandomForest rmse 0.813594 trained in 23.26 seconds\n",
      "43_RandomForest rmse 0.813903 trained in 994.4 seconds\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble rmse 0.767987 trained in 1.08 seconds\n",
      "AutoML fit time: 2821.1 seconds\n",
      "AutoML best model: Ensemble\n",
      "R^2 Score: 0.63966144185158\n",
      "RMSE: 0.7145385146141052\n"
     ]
    }
   ],
   "source": [
    "### Employment (log), NO Spatial Lag, Birmingham (2)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_bham\n",
    "target = 'log_total_employment'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_bham[features], all_data_bham[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/log_employment_bham/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_2 = r2_score(y_test, predictions)\n",
    "rmse_2 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_2}')\n",
    "print(f'RMSE: {rmse_2}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_2 = automl.predict(all_data_bham[features])\n",
    "bham_geometries = all_data_bham.loc[all_data_bham[target].index, 'geometry']\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': bham_geometries,\n",
    "    'observed': all_data_bham[target],\n",
    "    'predicted': predictions_all_2,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cbef0bf3-04a1-489c-ae7b-5552895992bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: ml_results/log_employment_london_lag/\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['CatBoost', 'Xgboost', 'Random Forest']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "1_Default_Xgboost rmse 0.638593 trained in 1086.36 seconds\n",
      "2_Default_CatBoost rmse 0.63385 trained in 2029.01 seconds\n",
      "3_Default_RandomForest rmse 0.693922 trained in 2068.46 seconds\n",
      "Skip not_so_random because of the time limit.\n",
      "Skip hill_climbing_1 because of the time limit.\n",
      "Skip hill_climbing_2 because of the time limit.\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble rmse 0.627695 trained in 0.05 seconds\n",
      "AutoML fit time: 5186.08 seconds\n",
      "AutoML best model: Ensemble\n",
      "R^2 Score: 0.7547717661754779\n",
      "RMSE: 0.635688841342926\n"
     ]
    }
   ],
   "source": [
    "### Employment (log), Spatial Lag, London (3)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london_lag\n",
    "target = 'log_total_employment'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/log_employment_london_lag/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_3 = r2_score(y_test, predictions)\n",
    "rmse_3 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_3}')\n",
    "print(f'RMSE: {rmse_3}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_3 = automl.predict(all_data_london[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': london_geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all_3,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5e16db-a923-45df-96fe-aa63e186fa14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gavinrolls/anaconda3/envs/urbsim/lib/python3.11/site-packages/supervised/preprocessing/exclude_missing_target.py:25: UserWarning: There are samples with missing target values in the data which will be excluded for further analysis\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: ml_results/log_employment_bham_lag/\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['CatBoost', 'Xgboost', 'Random Forest']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n"
     ]
    }
   ],
   "source": [
    "### Employment (log), Spatial Lag, Birmingham (4)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_bham_lag\n",
    "target = 'log_total_employment'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_bham[features], all_data_bham[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/log_employment_bham_lag/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_4 = r2_score(y_test, predictions)\n",
    "rmse_4 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_4}')\n",
    "print(f'RMSE: {rmse_4}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_4 = automl.predict(all_data_bham[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': bham_geometries,\n",
    "    'observed': all_data_bham[target],\n",
    "    'predicted': predictions_all_4,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8e39466b-44a3-4721-b6c1-4ad1484b0f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: ml_results/employment_density_london/\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['CatBoost', 'Xgboost', 'Random Forest']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "1_Default_Xgboost rmse 0.008187 trained in 90.4 seconds\n",
      "2_Default_CatBoost rmse 0.007915 trained in 175.05 seconds\n",
      "3_Default_RandomForest rmse 0.008384 trained in 72.8 seconds\n",
      "* Step not_so_random will try to check up to 12 models\n",
      "4_Xgboost rmse 0.007647 trained in 542.18 seconds\n",
      "8_CatBoost rmse 0.008524 trained in 320.1 seconds\n",
      "12_RandomForest rmse 0.008001 trained in 128.94 seconds\n",
      "5_Xgboost rmse 0.008374 trained in 763.09 seconds\n",
      "9_CatBoost rmse 0.008263 trained in 55.59 seconds\n",
      "13_RandomForest rmse 0.008615 trained in 297.25 seconds\n",
      "6_Xgboost rmse 0.007685 trained in 30.17 seconds\n",
      "10_CatBoost rmse 0.008248 trained in 853.21 seconds\n",
      "14_RandomForest rmse 0.008165 trained in 510.33 seconds\n",
      "7_Xgboost rmse 0.008324 trained in 34.02 seconds\n",
      "11_CatBoost rmse 0.008847 trained in 115.03 seconds\n",
      "15_RandomForest rmse 0.008238 trained in 124.83 seconds\n",
      "Skip hill_climbing_1 because of the time limit.\n",
      "Skip hill_climbing_2 because of the time limit.\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble rmse 0.007328 trained in 0.17 seconds\n",
      "AutoML fit time: 4647.57 seconds\n",
      "AutoML best model: Ensemble\n",
      "R^2 Score: 0.7138141098436666\n",
      "RMSE: 0.008915472775697708\n"
     ]
    }
   ],
   "source": [
    "### Employment Density, NO Spatial Lag, London (5)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london\n",
    "target = 'employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/employment_density_london/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_5 = r2_score(y_test, predictions)\n",
    "rmse_5 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_5}')\n",
    "print(f'RMSE: {rmse_5}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_5 = automl.predict(all_data_london[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': london_geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all_5,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1faae03a-3177-4923-a949-53cae255a64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: ml_results/employment_density_bham/\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['CatBoost', 'Xgboost', 'Random Forest']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "1_Default_Xgboost rmse 0.006401 trained in 54.94 seconds\n",
      "2_Default_CatBoost rmse 0.006805 trained in 20.89 seconds\n",
      "3_Default_RandomForest rmse 0.005864 trained in 21.74 seconds\n",
      "* Step not_so_random will try to check up to 12 models\n",
      "4_Xgboost rmse 0.005535 trained in 28.11 seconds\n",
      "8_CatBoost rmse 0.006953 trained in 27.14 seconds\n",
      "12_RandomForest rmse 0.006101 trained in 1000.47 seconds\n",
      "5_Xgboost rmse 0.006364 trained in 5.41 seconds\n",
      "9_CatBoost rmse 0.007136 trained in 20.74 seconds\n",
      "13_RandomForest rmse 0.006015 trained in 340.22 seconds\n",
      "6_Xgboost rmse 0.006276 trained in 9.46 seconds\n",
      "10_CatBoost rmse 0.006911 trained in 1067.53 seconds\n",
      "14_RandomForest rmse 0.006096 trained in 25.12 seconds\n",
      "7_Xgboost rmse 0.007043 trained in 5.29 seconds\n",
      "11_CatBoost rmse 0.006892 trained in 950.76 seconds\n",
      "15_RandomForest rmse 0.005946 trained in 21.97 seconds\n",
      "Skip hill_climbing_1 because of the time limit.\n",
      "Skip hill_climbing_2 because of the time limit.\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble rmse 0.005475 trained in 0.17 seconds\n",
      "AutoML fit time: 3606.68 seconds\n",
      "AutoML best model: Ensemble\n",
      "R^2 Score: 0.8094032597719285\n",
      "RMSE: 0.0012556178262457252\n"
     ]
    }
   ],
   "source": [
    "### Employment Density, NO Spatial Lag, Birmingham (6)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_bham\n",
    "target = 'employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_bham[features], all_data_bham[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/employment_density_bham/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_6 = r2_score(y_test, predictions)\n",
    "rmse_6 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_6}')\n",
    "print(f'RMSE: {rmse_6}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_6 = automl.predict(all_data_bham[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': bham_geometries,\n",
    "    'observed': all_data_bham[target],\n",
    "    'predicted': predictions_all_6,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "907fde61-ed19-43a6-b9b6-3951fb0bd473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: ml_results/employment_density_london_lag/\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['CatBoost', 'Xgboost', 'Random Forest']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "1_Default_Xgboost rmse 0.008538 trained in 4032.39 seconds\n",
      "2_Default_CatBoost rmse 0.008209 trained in 4009.11 seconds\n",
      "3_Default_RandomForest rmse 0.008585 trained in 3168.71 seconds\n",
      "Skip not_so_random because of the time limit.\n",
      "Skip hill_climbing_1 because of the time limit.\n",
      "Skip hill_climbing_2 because of the time limit.\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble rmse 0.008103 trained in 0.05 seconds\n",
      "AutoML fit time: 11212.59 seconds\n",
      "AutoML best model: Ensemble\n",
      "R^2 Score: 0.7209666533175008\n",
      "RMSE: 0.008803357370197773\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'predictions_all_7' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 53\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m#Save results for plotting\u001b[39;00m\n\u001b[1;32m     48\u001b[0m predictions_all_5 \u001b[38;5;241m=\u001b[39m automl\u001b[38;5;241m.\u001b[39mpredict(all_data_london[features])\n\u001b[1;32m     50\u001b[0m results_office_density_cleaned_perform \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m'\u001b[39m: london_geometries,\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobserved\u001b[39m\u001b[38;5;124m'\u001b[39m: all_data_london[target],\n\u001b[0;32m---> 53\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mpredictions_all_7\u001b[49m,\n\u001b[1;32m     54\u001b[0m })\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predictions_all_7' is not defined"
     ]
    }
   ],
   "source": [
    "### Employment Density, Spatial Lag, London (7)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london_lag\n",
    "target = 'employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/employment_density_london_lag/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_7 = r2_score(y_test, predictions)\n",
    "rmse_7 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_7}')\n",
    "print(f'RMSE: {rmse_7}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_7 = automl.predict(all_data_london[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': london_geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all_7,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bb150e-d907-41c8-a5cb-2d3d0e065417",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Employment Density, Spatial Lag, Birmingham (8)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_bham_lag\n",
    "target = 'employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_bham[features], all_data_bham[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/employment_density_bham_lag/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_8 = r2_score(y_test, predictions)\n",
    "rmse_8 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_8}')\n",
    "print(f'RMSE: {rmse_8}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_8 = automl.predict(all_data_bham[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': bham_geometries,\n",
    "    'observed': all_data_bham[target],\n",
    "    'predicted': predictions_all_8,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f6e4682-7e10-4638-bb3c-a08c426b9f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: ml_results/office_employment_density_london/\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['CatBoost', 'Xgboost', 'Random Forest']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "1_Default_Xgboost rmse 0.005575 trained in 45.87 seconds\n",
      "2_Default_CatBoost rmse 0.005711 trained in 80.76 seconds\n",
      "3_Default_RandomForest rmse 0.005811 trained in 71.91 seconds\n",
      "* Step not_so_random will try to check up to 12 models\n",
      "4_Xgboost rmse 0.005082 trained in 55.85 seconds\n",
      "8_CatBoost rmse 0.006341 trained in 112.95 seconds\n",
      "12_RandomForest rmse 0.005813 trained in 57.83 seconds\n",
      "5_Xgboost rmse 0.005617 trained in 42.74 seconds\n",
      "9_CatBoost rmse 0.006491 trained in 67.46 seconds\n",
      "13_RandomForest rmse 0.005893 trained in 53.56 seconds\n",
      "6_Xgboost rmse 0.005671 trained in 42.41 seconds\n",
      "10_CatBoost rmse 0.006009 trained in 62.75 seconds\n",
      "14_RandomForest rmse 0.005768 trained in 45.16 seconds\n",
      "7_Xgboost rmse 0.005956 trained in 42.47 seconds\n",
      "11_CatBoost rmse 0.006672 trained in 59.17 seconds\n",
      "15_RandomForest rmse 0.005797 trained in 46.88 seconds\n",
      "* Step hill_climbing_1 will try to check up to 17 models\n",
      "16_Xgboost rmse 0.005012 trained in 40.84 seconds\n",
      "17_Xgboost rmse 0.005077 trained in 40.65 seconds\n",
      "18_Xgboost rmse 0.005638 trained in 39.15 seconds\n",
      "19_Xgboost rmse 0.005571 trained in 38.34 seconds\n",
      "20_Xgboost rmse 0.005567 trained in 37.66 seconds\n",
      "21_Xgboost rmse 0.005652 trained in 39.96 seconds\n",
      "22_CatBoost rmse 0.005657 trained in 64.44 seconds\n",
      "23_CatBoost rmse 0.005799 trained in 55.96 seconds\n",
      "24_RandomForest rmse 0.00576 trained in 50.57 seconds\n",
      "25_RandomForest rmse 0.005794 trained in 45.4 seconds\n",
      "26_RandomForest rmse 0.005774 trained in 46.77 seconds\n",
      "27_RandomForest rmse 0.005734 trained in 57.46 seconds\n",
      "28_RandomForest rmse 0.005865 trained in 46.87 seconds\n",
      "29_CatBoost rmse 0.005988 trained in 70.77 seconds\n",
      "30_CatBoost rmse 0.006058 trained in 67.14 seconds\n",
      "31_CatBoost rmse 0.006152 trained in 95.13 seconds\n",
      "32_CatBoost rmse 0.006218 trained in 64.13 seconds\n",
      "* Step hill_climbing_2 will try to check up to 8 models\n",
      "33_Xgboost rmse 0.005041 trained in 41.1 seconds\n",
      "34_Xgboost rmse 0.005067 trained in 45.67 seconds\n",
      "35_Xgboost rmse 0.005006 trained in 41.44 seconds\n",
      "36_CatBoost rmse 0.005656 trained in 58.87 seconds\n",
      "37_CatBoost rmse 0.00563 trained in 58.7 seconds\n",
      "38_RandomForest rmse 0.005552 trained in 48.35 seconds\n",
      "39_RandomForest rmse 0.005743 trained in 50.03 seconds\n",
      "40_CatBoost rmse 0.005638 trained in 51.34 seconds\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble rmse 0.004962 trained in 0.91 seconds\n",
      "AutoML fit time: 2205.3 seconds\n",
      "AutoML best model: Ensemble\n",
      "R^2 Score: 0.5798782180896167\n",
      "RMSE: 0.007589899934828281\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'london_geometries' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 51\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m#Save results for plotting\u001b[39;00m\n\u001b[1;32m     48\u001b[0m predictions_all_9 \u001b[38;5;241m=\u001b[39m automl\u001b[38;5;241m.\u001b[39mpredict(all_data_london[features])\n\u001b[1;32m     50\u001b[0m results_office_density_cleaned_perform \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mlondon_geometries\u001b[49m,\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobserved\u001b[39m\u001b[38;5;124m'\u001b[39m: all_data_london[target],\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted\u001b[39m\u001b[38;5;124m'\u001b[39m: predictions_all_9,\n\u001b[1;32m     54\u001b[0m })\n",
      "\u001b[0;31mNameError\u001b[0m: name 'london_geometries' is not defined"
     ]
    }
   ],
   "source": [
    "### Office Employment Density , NO Spatial Lag, London (9)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london\n",
    "target = 'office_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/office_employment_density_london/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_9 = r2_score(y_test, predictions)\n",
    "rmse_9 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_9}')\n",
    "print(f'RMSE: {rmse_9}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_9 = automl.predict(all_data_london[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': london_geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all_9,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015c372b-1b93-4550-b7f5-ece1ad3149b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Office Employment Density , NO Spatial Lag, Birmingham (10)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_bham\n",
    "target = 'office_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_bham[features], all_data_bham[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/office_employment_density_bham/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_10 = r2_score(y_test, predictions)\n",
    "rmse_10 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_10}')\n",
    "print(f'RMSE: {rmse_10}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_10 = automl.predict(all_data_bham[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': bham_geometries,\n",
    "    'observed': all_data_bham[target],\n",
    "    'predicted': predictions_all_10,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3160a4-8d0e-4048-acb5-a9f8e51ef901",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Office Employment Density, Spatial Lag, London (11)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london_lag\n",
    "target = 'office_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/office_employment_density_london_lag/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_11 = r2_score(y_test, predictions)\n",
    "rmse_11 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_11}')\n",
    "print(f'RMSE: {rmse_11}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_11 = automl.predict(all_data_london[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': london_geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all_11,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c793ac54-59e8-4ff0-b95a-0bb60d1edd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Office Employment Density (log), Spatial Lag, Birmingham (12)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_bham_lag\n",
    "target = 'office_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_bham[features], all_data_bham[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/office_employment_density_bham_lag/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_12 = r2_score(y_test, predictions)\n",
    "rmse_12 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_12}')\n",
    "print(f'RMSE: {rmse_12}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_12 = automl.predict(all_data_bham[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': bham_geometries,\n",
    "    'observed': all_data_bham[target],\n",
    "    'predicted': predictions_all_12,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0592585-a869-42b2-9ccd-c7ebe0bef895",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Employment (log), NO Spatial Lag, London, POI only (13)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london_poi\n",
    "target = 'log_total_employment'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/log_employment_london_poi/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_13 = r2_score(y_test, predictions)\n",
    "rmse_13 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_13}')\n",
    "print(f'RMSE: {rmse_13}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_13 = automl.predict(all_data_london[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': london_geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all_13,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ff96c6-9be8-4705-83e2-67f8876eb238",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Employment (log), NO Spatial Lag, Brimingham, POI only (14)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_bham_poi\n",
    "target = 'log_total_employment'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_bham[features], all_data_bham[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/log_employment_bham_poi/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_14 = r2_score(y_test, predictions)\n",
    "rmse_14 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_14}')\n",
    "print(f'RMSE: {rmse_14}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_14 = automl.predict(all_data_bham[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': bham_geometries,\n",
    "    'observed': all_data_bham[target],\n",
    "    'predicted': predictions_all_14,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4bf1d6-902a-4011-b805-4e1d2df8644e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Employment Density, NO Spatial Lag, London, POI only (15)\n",
    "\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london_poi\n",
    "target = 'employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/employment_density_london_poi/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_15 = r2_score(y_test, predictions)\n",
    "rmse_15 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_15}')\n",
    "print(f'RMSE: {rmse_15}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_15 = automl.predict(all_data_london[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': london_geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all_15,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b18222-1efa-4451-b8a1-5d26ba8f83cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Employment Density, NO Spatial Lag, Brimingham, POI only (16)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_bham_poi\n",
    "target = 'employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_bham[features], all_data_bham[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/employment_density_bham_poi/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_16 = r2_score(y_test, predictions)\n",
    "rmse_16 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_16}')\n",
    "print(f'RMSE: {rmse_16}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_16 = automl.predict(all_data_bham[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': bham_geometries,\n",
    "    'observed': all_data_bham[target],\n",
    "    'predicted': predictions_all_16,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154710f6-e527-4512-8861-573d0f26d504",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Office Employment Density, NO Spatial Lag, London, POI only (17)\n",
    "\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london_poi\n",
    "target = 'office_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/office_employment_density_london_poi/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_17 = r2_score(y_test, predictions)\n",
    "rmse_17 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_17}')\n",
    "print(f'RMSE: {rmse_17}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_17 = automl.predict(all_data_london[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': london_geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all_17,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27df441e-a493-4c24-88e7-a302f6e05843",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Office Employment Density, NO Spatial Lag, Birmingham, POI only (18)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_bham_poi\n",
    "target = 'office_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_bham[features], all_data_bham[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/office_employment_density_bham_poi/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_18 = r2_score(y_test, predictions)\n",
    "rmse_18 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_18}')\n",
    "print(f'RMSE: {rmse_18}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_10 = automl.predict(all_data_bham[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': bham_geometries,\n",
    "    'observed': all_data_bham[target],\n",
    "    'predicted': predictions_all_18,\n",
    "})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "urbsim",
   "language": "python",
   "name": "urbsim"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
