{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7542fb7-3702-466a-8c2d-837e1e6d4ed3",
   "metadata": {},
   "source": [
    "# Modelling\n",
    "\n",
    "This is the script where I store all my ML model runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d305a93-526f-4ed4-993f-96d593fc9618",
   "metadata": {},
   "source": [
    "## Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b90b1626-165f-4b79-8d67-7b3afa023602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library Imports\n",
    "\n",
    "#Basics\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "#Shapely / Spatial\n",
    "from shapely import wkt\n",
    "import shapely.geometry\n",
    "from shapely.geometry import Polygon, MultiPolygon\n",
    "\n",
    "#Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#ML from mljar-supervised\n",
    "from supervised.automl import AutoML\n",
    "\n",
    "#Warning Supression\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31ea067-af33-4415-b9e7-4d3426573f62",
   "metadata": {},
   "source": [
    "### Import Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53f05a2a-040b-45cd-8108-192d695dea50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>LSOA11CD</th>\n",
       "      <th>LSOA11NM_x</th>\n",
       "      <th>LSOA11NM_y</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>population</th>\n",
       "      <th>Area</th>\n",
       "      <th>01 : Crop and animal production, hunting and related service activities</th>\n",
       "      <th>02 : Forestry and logging</th>\n",
       "      <th>03 : Fishing and aquaculture</th>\n",
       "      <th>...</th>\n",
       "      <th>lag_travel</th>\n",
       "      <th>lag_travel_agents</th>\n",
       "      <th>lag_trusts</th>\n",
       "      <th>lag_university_housing</th>\n",
       "      <th>lag_used_vintage_and_consignment</th>\n",
       "      <th>lag_veterinarian</th>\n",
       "      <th>lag_videographer</th>\n",
       "      <th>lag_vitamins_and_supplements</th>\n",
       "      <th>lag_warehouses</th>\n",
       "      <th>lag_window_washing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>E01008881</td>\n",
       "      <td>Birmingham 067A</td>\n",
       "      <td>Birmingham 067A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1599</td>\n",
       "      <td>lsoa2011:E01008881 : Birmingham 067A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>E01008882</td>\n",
       "      <td>Birmingham 066A</td>\n",
       "      <td>Birmingham 066A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1747</td>\n",
       "      <td>lsoa2011:E01008882 : Birmingham 066A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>E01008883</td>\n",
       "      <td>Birmingham 078A</td>\n",
       "      <td>Birmingham 078A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1816</td>\n",
       "      <td>lsoa2011:E01008883 : Birmingham 078A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>E01008884</td>\n",
       "      <td>Birmingham 078B</td>\n",
       "      <td>Birmingham 078B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1870</td>\n",
       "      <td>lsoa2011:E01008884 : Birmingham 078B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>E01008885</td>\n",
       "      <td>Birmingham 076A</td>\n",
       "      <td>Birmingham 076A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1308</td>\n",
       "      <td>lsoa2011:E01008885 : Birmingham 076A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>634</td>\n",
       "      <td>E01033646</td>\n",
       "      <td>Birmingham 031I</td>\n",
       "      <td>Birmingham 031I</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1624</td>\n",
       "      <td>lsoa2011:E01033646 : Birmingham 031I</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>635</td>\n",
       "      <td>E01033647</td>\n",
       "      <td>Birmingham 058E</td>\n",
       "      <td>Birmingham 058E</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1398</td>\n",
       "      <td>lsoa2011:E01033647 : Birmingham 058E</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>636</td>\n",
       "      <td>E01033648</td>\n",
       "      <td>Birmingham 084F</td>\n",
       "      <td>Birmingham 084F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2715</td>\n",
       "      <td>lsoa2011:E01033648 : Birmingham 084F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>637</td>\n",
       "      <td>E01033649</td>\n",
       "      <td>Birmingham 058F</td>\n",
       "      <td>Birmingham 058F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1801</td>\n",
       "      <td>lsoa2011:E01033649 : Birmingham 058F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>638</td>\n",
       "      <td>E01033650</td>\n",
       "      <td>Birmingham 077F</td>\n",
       "      <td>Birmingham 077F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2596</td>\n",
       "      <td>lsoa2011:E01033650 : Birmingham 077F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>639 rows × 742 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0   LSOA11CD       LSOA11NM_x       LSOA11NM_y  Unnamed: 2  \\\n",
       "0             0  E01008881  Birmingham 067A  Birmingham 067A         0.0   \n",
       "1             1  E01008882  Birmingham 066A  Birmingham 066A         0.0   \n",
       "2             2  E01008883  Birmingham 078A  Birmingham 078A         0.0   \n",
       "3             3  E01008884  Birmingham 078B  Birmingham 078B         0.0   \n",
       "4             4  E01008885  Birmingham 076A  Birmingham 076A         0.0   \n",
       "..          ...        ...              ...              ...         ...   \n",
       "634         634  E01033646  Birmingham 031I  Birmingham 031I         0.0   \n",
       "635         635  E01033647  Birmingham 058E  Birmingham 058E         0.0   \n",
       "636         636  E01033648  Birmingham 084F  Birmingham 084F         0.0   \n",
       "637         637  E01033649  Birmingham 058F  Birmingham 058F         0.0   \n",
       "638         638  E01033650  Birmingham 077F  Birmingham 077F         0.0   \n",
       "\n",
       "     population                                  Area  \\\n",
       "0          1599  lsoa2011:E01008881 : Birmingham 067A   \n",
       "1          1747  lsoa2011:E01008882 : Birmingham 066A   \n",
       "2          1816  lsoa2011:E01008883 : Birmingham 078A   \n",
       "3          1870  lsoa2011:E01008884 : Birmingham 078B   \n",
       "4          1308  lsoa2011:E01008885 : Birmingham 076A   \n",
       "..          ...                                   ...   \n",
       "634        1624  lsoa2011:E01033646 : Birmingham 031I   \n",
       "635        1398  lsoa2011:E01033647 : Birmingham 058E   \n",
       "636        2715  lsoa2011:E01033648 : Birmingham 084F   \n",
       "637        1801  lsoa2011:E01033649 : Birmingham 058F   \n",
       "638        2596  lsoa2011:E01033650 : Birmingham 077F   \n",
       "\n",
       "     01 : Crop and animal production, hunting and related service activities  \\\n",
       "0                                                  0.0                         \n",
       "1                                                  0.0                         \n",
       "2                                                  0.0                         \n",
       "3                                                  0.0                         \n",
       "4                                                  0.0                         \n",
       "..                                                 ...                         \n",
       "634                                                0.0                         \n",
       "635                                                0.0                         \n",
       "636                                                0.0                         \n",
       "637                                                0.0                         \n",
       "638                                                0.0                         \n",
       "\n",
       "     02 : Forestry and logging  03 : Fishing and aquaculture  ...  lag_travel  \\\n",
       "0                          0.0                           0.0  ...    0.000000   \n",
       "1                          0.0                           0.0  ...    0.166667   \n",
       "2                          0.0                           0.0  ...    0.166667   \n",
       "3                          0.0                           0.0  ...    0.333333   \n",
       "4                          0.0                           0.0  ...    0.000000   \n",
       "..                         ...                           ...  ...         ...   \n",
       "634                        0.0                           0.0  ...    0.166667   \n",
       "635                        0.0                           0.0  ...    0.166667   \n",
       "636                        0.0                           0.0  ...    0.000000   \n",
       "637                        0.0                           0.0  ...    0.333333   \n",
       "638                        0.0                           0.0  ...    0.000000   \n",
       "\n",
       "     lag_travel_agents  lag_trusts  lag_university_housing  \\\n",
       "0             0.166667         0.0                     0.0   \n",
       "1             0.000000         0.0                     0.0   \n",
       "2             0.000000         0.0                     0.0   \n",
       "3             0.000000         0.0                     0.0   \n",
       "4             0.166667         0.0                     0.0   \n",
       "..                 ...         ...                     ...   \n",
       "634           0.000000         0.0                     0.0   \n",
       "635           0.000000         0.0                     0.0   \n",
       "636           0.000000         0.0                     0.0   \n",
       "637           0.000000         0.0                     0.0   \n",
       "638           0.000000         0.0                     0.0   \n",
       "\n",
       "     lag_used_vintage_and_consignment  lag_veterinarian  lag_videographer  \\\n",
       "0                                 0.0               0.0               0.0   \n",
       "1                                 0.0               0.0               0.0   \n",
       "2                                 0.0               0.0               0.0   \n",
       "3                                 0.0               0.0               0.0   \n",
       "4                                 0.0               0.0               0.0   \n",
       "..                                ...               ...               ...   \n",
       "634                               0.0               0.0               0.0   \n",
       "635                               0.0               0.0               0.0   \n",
       "636                               0.0               0.0               0.0   \n",
       "637                               0.0               0.0               0.0   \n",
       "638                               0.0               0.0               0.0   \n",
       "\n",
       "     lag_vitamins_and_supplements  lag_warehouses  lag_window_washing  \n",
       "0                        0.000000        0.333333                 0.0  \n",
       "1                        0.000000        0.500000                 0.0  \n",
       "2                        0.000000        0.000000                 0.0  \n",
       "3                        0.166667        0.500000                 0.0  \n",
       "4                        0.000000        0.000000                 0.0  \n",
       "..                            ...             ...                 ...  \n",
       "634                      0.166667        0.000000                 0.0  \n",
       "635                      0.000000        0.000000                 0.0  \n",
       "636                      0.000000        0.000000                 0.0  \n",
       "637                      0.166667        0.000000                 0.0  \n",
       "638                      0.000000        0.000000                 0.0  \n",
       "\n",
       "[639 rows x 742 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read London CSV\n",
    "all_data_london = pd.read_csv(\"data/combined_data/lag/all_data_london_lag.csv\")\n",
    "\n",
    "# Read in feature column set\n",
    "with open(\"data/combined_data/total_feature_columns_london.csv\", 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Reconstruct\n",
    "feature_columns_london_lag = [''.join(line.strip().split(',')) for line in lines]\n",
    "\n",
    "# Create non-laged column set\n",
    "feature_columns_london = [col for col in feature_columns_london_lag if not col.startswith('lag_')]\n",
    "\n",
    "# ---\n",
    "\n",
    "# Read Birmingham CSV\n",
    "all_data_bham = pd.read_csv(\"data/combined_data/lag/all_data_bham_lag.csv\")\n",
    "\n",
    "# Read in feature column set\n",
    "with open(\"data/combined_data/total_feature_columns_bham.csv\", 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Reconstruct\n",
    "feature_columns_bham_lag = [''.join(line.strip().split(',')) for line in lines]\n",
    "\n",
    "# Create non-lagged column set\n",
    "feature_columns_bham = [col for col in feature_columns_bham_lag if not col.startswith('lag_')]\n",
    "\n",
    "# Fix null values ending up in logged variables\n",
    "all_data_london.fillna(0)\n",
    "all_data_bham.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "581a5ad1-f57d-4764-b71b-568a4e4f8c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Lag (but no building cols) feature spaces\n",
    "\n",
    "# List all building footprint related columns here\n",
    "columns_to_remove = ['num_buildings','num_retail_buildings','num_residential_buildings','num_office_buildings','num_commercial_buildings',\n",
    "                    'log_num_buildings','all_avg_building_area','all_lsoa_area_ratio','all_total_area',\n",
    "                     'retail_avg_building_area','retail_lsoa_area_ratio','retail_total_area',\n",
    "                     'residential_avg_building_area','residential_lsoa_area_ratio','residential_total_area',\n",
    "                     'commercial_avg_building_area','commercial_lsoa_area_ratio','commercial_total_area',\n",
    "                     'office_avg_building_area','office_lsoa_area_ratio','office_total_area',\n",
    "                     'lag_num_retail_buildings','lag_num_residential_buildings','lag_num_office_buildings','lag_num_commercial_buildings',\n",
    "                    'lag_log_num_buildings','lag_all_avg_building_area','lag_all_lsoa_area_ratio','lag_all_total_area',\n",
    "                     'lag_retail_avg_building_area','lag_retail_lsoa_area_ratio','lag_retail_total_area',\n",
    "                     'lag_residential_avg_building_area','lag_residential_lsoa_area_ratio','lag_residential_total_area',\n",
    "                     'lag_commercial_avg_building_area','lag_commercial_lsoa_area_ratio','lag_commercial_total_area',\n",
    "                     'lag_office_avg_building_area','lag_office_lsoa_area_ratio','lag_office_total_area',\n",
    "                    ]\n",
    "\n",
    "feature_columns_london_lag_poi = [col for col in feature_columns_london_lag if col not in columns_to_remove]\n",
    "\n",
    "feature_columns_bham_lag_poi = [col for col in feature_columns_bham_lag if col not in columns_to_remove]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa391bf0-c409-43af-811e-771e35bff90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download POI & auxillary-only feature spaces (No building footprint information)\n",
    "\n",
    "# London\n",
    "# Read in POI feature column set\n",
    "with open(\"data/combined_data/feature_columns_london_poi.csv\", 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Reconstruct\n",
    "feature_columns_london_poi = [''.join(line.strip().split(',')) for line in lines]\n",
    "\n",
    "# Birmingham\n",
    "# Read in POI feature column set\n",
    "with open(\"data/combined_data/feature_columns_bham_poi.csv\", 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Reconstruct\n",
    "feature_columns_bham_poi = [''.join(line.strip().split(',')) for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1bf237-cbfa-4ce2-9745-768d454fb859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get log of density columns\n",
    "\n",
    "\n",
    "min_non_zero_london_employment_density = all_data_london['employment_density'].loc[all_data_london['employment_density'] > 0].min()\n",
    "min_non_zero_london_office_employment_density = all_data_london['office_employment_density'].loc[all_data_london['office_employment_density'] > 0].min()\n",
    "\n",
    "epsilon_london_employment_density = min_non_zero_london_employment_density / 10\n",
    "epsilon_london_office_employment_density = min_non_zero_london_office_employment_density / 10\n",
    "\n",
    "all_data_london['log_employment_density'] = np.log(all_data_london['employment_density'].replace(0, epsilon_london_employment_density))\n",
    "all_data_london['log_office_employment_density'] = np.log(all_data_london['office_employment_density'].replace(0, epsilon_london_office_employment_density))\n",
    "\n",
    "# Birmingham\n",
    "min_non_zero_bham_employment_density = all_data_bham['employment_density'].loc[all_data_bham['employment_density'] > 0].min()\n",
    "min_non_zero_bham_office_employment_density = all_data_bham['office_employment_density'].loc[all_data_bham['office_employment_density'] > 0].min()\n",
    "\n",
    "epsilon_bham_employment_density = min_non_zero_bham_employment_density / 10\n",
    "epsilon_bham_office_employment_density = min_non_zero_bham_office_employment_density / 10\n",
    "\n",
    "all_data_bham['log_employment_density'] = np.log(all_data_bham['employment_density'].replace(0, epsilon_bham_employment_density))\n",
    "all_data_bham['log_office_employment_density'] = np.log(all_data_bham['office_employment_density'].replace(0, epsilon_bham_office_employment_density))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1476d20c-344b-422d-8b04-e6b747f1d5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Geometries and Names\n",
    "\n",
    "london_geometries = all_data_london['geometry']\n",
    "bham_geometries = all_data_bham['geometry']\n",
    "\n",
    "london_names = all_data_london['LSOA11CD']\n",
    "bham_names = all_data_bham['LSOA11CD']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5488444a-67fc-4aca-8e79-065018e090cb",
   "metadata": {},
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e93f99a8-c74f-4436-8877-6d11cc2f3103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model has already been fitted. You can use predict methods or select a new 'results_path' for a new 'fit()'.\n",
      "R^2 Score: 0.7207009026018532\n",
      "RMSE: 0.678412914276123\n"
     ]
    }
   ],
   "source": [
    "# Ignore depracation warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london_lag\n",
    "target = 'log_total_employment'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(results_path=\"ml_results/dummy_models/test\", mode='Explain')\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_log_employment = r2_score(y_test, predictions)\n",
    "rmse_log_employment = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_log_employment}')\n",
    "print(f'RMSE: {rmse_log_employment}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all = automl.predict(all_data_london[features])\n",
    "\n",
    "results_test = pd.DataFrame({\n",
    "    'geometry': london_geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca014449-6c4c-46d6-ba87-a578cbb9881d",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ce02ced4-41b4-46d0-89da-b9900f64442d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: ml_results/log_employment_london/\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['CatBoost', 'Xgboost', 'Random Forest']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "1_Default_Xgboost rmse 0.638237 trained in 44.72 seconds\n",
      "2_Default_CatBoost rmse 0.624872 trained in 39.45 seconds\n",
      "3_Default_RandomForest rmse 0.692124 trained in 1092.47 seconds\n",
      "* Step not_so_random will try to check up to 12 models\n",
      "4_Xgboost rmse 0.647595 trained in 31.74 seconds\n",
      "8_CatBoost rmse 0.62888 trained in 57.43 seconds\n",
      "12_RandomForest rmse 0.689969 trained in 42.49 seconds\n",
      "5_Xgboost rmse 0.646129 trained in 955.1 seconds\n",
      "9_CatBoost rmse 0.640378 trained in 954.04 seconds\n",
      "13_RandomForest rmse 0.713245 trained in 57.77 seconds\n",
      "6_Xgboost rmse 0.631339 trained in 29.05 seconds\n",
      "10_CatBoost rmse 0.627944 trained in 359.69 seconds\n",
      "14_RandomForest rmse 0.677261 trained in 62.38 seconds\n",
      "7_Xgboost rmse 0.635899 trained in 27.49 seconds\n",
      "11_CatBoost rmse 0.65143 trained in 42.03 seconds\n",
      "15_RandomForest rmse 0.67456 trained in 313.99 seconds\n",
      "Skip hill_climbing_1 because of the time limit.\n",
      "Skip hill_climbing_2 because of the time limit.\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble rmse 0.617282 trained in 0.17 seconds\n",
      "AutoML fit time: 4117.39 seconds\n",
      "AutoML best model: Ensemble\n",
      "R^2 Score: 0.7578170639491384\n",
      "RMSE: 0.6317294239997864\n"
     ]
    }
   ],
   "source": [
    "### Employment (log), NO Spatial Lag, London (1)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london\n",
    "target = 'log_total_employment'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/log_employment_london/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_1 = r2_score(y_test, predictions)\n",
    "rmse_1 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_1}')\n",
    "print(f'RMSE: {rmse_1}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_1 = automl.predict(all_data_london[features])\n",
    "london_geometries = all_data_london.loc[all_data_london[target].index, 'geometry']\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': london_geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all_1,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ac80575c-2245-4464-abdd-a8997967e727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: ml_results/log_employment_bham/\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['CatBoost', 'Xgboost', 'Random Forest']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "1_Default_Xgboost rmse 0.803686 trained in 5.65 seconds\n",
      "2_Default_CatBoost rmse 0.783334 trained in 18.54 seconds\n",
      "3_Default_RandomForest rmse 0.821087 trained in 24.78 seconds\n",
      "* Step not_so_random will try to check up to 12 models\n",
      "4_Xgboost rmse 0.807126 trained in 5.22 seconds\n",
      "8_CatBoost rmse 0.810248 trained in 22.31 seconds\n",
      "12_RandomForest rmse 0.816138 trained in 57.95 seconds\n",
      "5_Xgboost rmse 0.808929 trained in 5.8 seconds\n",
      "9_CatBoost rmse 0.830576 trained in 20.01 seconds\n",
      "13_RandomForest rmse 0.848962 trained in 56.66 seconds\n",
      "6_Xgboost rmse 0.791632 trained in 4.91 seconds\n",
      "10_CatBoost rmse 0.811724 trained in 19.82 seconds\n",
      "14_RandomForest rmse 0.817142 trained in 24.16 seconds\n",
      "7_Xgboost rmse 0.861031 trained in 4.85 seconds\n",
      "11_CatBoost rmse 0.854616 trained in 19.84 seconds\n",
      "15_RandomForest rmse 0.824156 trained in 65.1 seconds\n",
      "* Step hill_climbing_1 will try to check up to 18 models\n",
      "16_CatBoost rmse 0.795161 trained in 19.39 seconds\n",
      "17_CatBoost rmse 0.799599 trained in 18.81 seconds\n",
      "18_Xgboost rmse 0.792724 trained in 5.24 seconds\n",
      "19_Xgboost rmse 0.798389 trained in 5.27 seconds\n",
      "20_Xgboost rmse 0.801649 trained in 5.36 seconds\n",
      "21_Xgboost rmse 0.801951 trained in 5.54 seconds\n",
      "22_Xgboost rmse 0.797301 trained in 5.28 seconds\n",
      "23_Xgboost rmse 0.81387 trained in 5.55 seconds\n",
      "24_CatBoost rmse 0.809749 trained in 47.23 seconds\n",
      "25_CatBoost rmse 0.819835 trained in 20.94 seconds\n",
      "26_CatBoost rmse 0.801445 trained in 21.29 seconds\n",
      "27_CatBoost rmse 0.825881 trained in 19.57 seconds\n",
      "28_RandomForest rmse 0.812049 trained in 55.3 seconds\n",
      "29_RandomForest rmse 0.820499 trained in 26.16 seconds\n",
      "30_RandomForest rmse 0.809917 trained in 25.73 seconds\n",
      "31_RandomForest rmse 0.829734 trained in 24.04 seconds\n",
      "32_RandomForest rmse 0.816113 trained in 56.83 seconds\n",
      "33_RandomForest rmse 0.820707 trained in 24.05 seconds\n",
      "* Step hill_climbing_2 will try to check up to 10 models\n",
      "34_Xgboost rmse 0.797041 trained in 5.24 seconds\n",
      "35_Xgboost rmse 0.798353 trained in 5.45 seconds\n",
      "36_Xgboost rmse 0.798988 trained in 6.04 seconds\n",
      "37_Xgboost rmse 0.798183 trained in 5.87 seconds\n",
      "38_CatBoost rmse 0.792413 trained in 22.1 seconds\n",
      "39_Xgboost rmse 0.801037 trained in 6.73 seconds\n",
      "40_RandomForest rmse 0.805922 trained in 956.12 seconds\n",
      "41_RandomForest rmse 0.80454 trained in 29.39 seconds\n",
      "42_RandomForest rmse 0.813594 trained in 23.26 seconds\n",
      "43_RandomForest rmse 0.813903 trained in 994.4 seconds\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble rmse 0.767987 trained in 1.08 seconds\n",
      "AutoML fit time: 2821.1 seconds\n",
      "AutoML best model: Ensemble\n",
      "R^2 Score: 0.63966144185158\n",
      "RMSE: 0.7145385146141052\n"
     ]
    }
   ],
   "source": [
    "### Employment (log), NO Spatial Lag, Birmingham (2)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_bham\n",
    "target = 'log_total_employment'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_bham[features], all_data_bham[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/log_employment_bham/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_2 = r2_score(y_test, predictions)\n",
    "rmse_2 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_2}')\n",
    "print(f'RMSE: {rmse_2}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_2 = automl.predict(all_data_bham[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': bham_geometries,\n",
    "    'observed': all_data_bham[target],\n",
    "    'predicted': predictions_all_2,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cbef0bf3-04a1-489c-ae7b-5552895992bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: ml_results/log_employment_london_lag/\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['CatBoost', 'Xgboost', 'Random Forest']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "1_Default_Xgboost rmse 0.638593 trained in 1086.36 seconds\n",
      "2_Default_CatBoost rmse 0.63385 trained in 2029.01 seconds\n",
      "3_Default_RandomForest rmse 0.693922 trained in 2068.46 seconds\n",
      "Skip not_so_random because of the time limit.\n",
      "Skip hill_climbing_1 because of the time limit.\n",
      "Skip hill_climbing_2 because of the time limit.\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble rmse 0.627695 trained in 0.05 seconds\n",
      "AutoML fit time: 5186.08 seconds\n",
      "AutoML best model: Ensemble\n",
      "R^2 Score: 0.7547717661754779\n",
      "RMSE: 0.635688841342926\n"
     ]
    }
   ],
   "source": [
    "### Employment (log), Spatial Lag, London (3)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london_lag\n",
    "target = 'log_total_employment'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/log_employment_london_lag/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_3 = r2_score(y_test, predictions)\n",
    "rmse_3 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_3}')\n",
    "print(f'RMSE: {rmse_3}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_3 = automl.predict(all_data_london[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': london_geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all_3,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c5e16db-a923-45df-96fe-aa63e186fa14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gavinrolls/anaconda3/envs/urbsim/lib/python3.11/site-packages/supervised/preprocessing/exclude_missing_target.py:25: UserWarning: There are samples with missing target values in the data which will be excluded for further analysis\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model has already been fitted. You can use predict methods or select a new 'results_path' for a new 'fit()'.\n",
      "R^2 Score: 0.6180309508339799\n",
      "RMSE: 0.7356722354888916\n"
     ]
    }
   ],
   "source": [
    "### Employment (log), Spatial Lag, Birmingham (4)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_bham_lag\n",
    "target = 'log_total_employment'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_bham[features], all_data_bham[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/log_employment_bham_lag/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_4 = r2_score(y_test, predictions)\n",
    "rmse_4 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_4}')\n",
    "print(f'RMSE: {rmse_4}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_4 = automl.predict(all_data_bham[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': bham_geometries,\n",
    "    'observed': all_data_bham[target],\n",
    "    'predicted': predictions_all_4,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8e39466b-44a3-4721-b6c1-4ad1484b0f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: ml_results/employment_density_london/\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['CatBoost', 'Xgboost', 'Random Forest']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "1_Default_Xgboost rmse 0.711278 trained in 52.53 seconds\n",
      "2_Default_CatBoost rmse 0.679557 trained in 62.23 seconds\n",
      "3_Default_RandomForest rmse 0.803243 trained in 43.05 seconds\n",
      "* Step not_so_random will try to check up to 12 models\n",
      "4_Xgboost rmse 0.706569 trained in 43.27 seconds\n",
      "8_CatBoost rmse 0.68361 trained in 76.41 seconds\n",
      "12_RandomForest rmse 0.807704 trained in 69.05 seconds\n",
      "5_Xgboost rmse 0.728611 trained in 46.56 seconds\n",
      "9_CatBoost rmse 0.705359 trained in 70.99 seconds\n",
      "13_RandomForest rmse 0.83544 trained in 61.51 seconds\n",
      "6_Xgboost rmse 0.694949 trained in 35.09 seconds\n",
      "10_CatBoost rmse 0.682747 trained in 55.81 seconds\n",
      "14_RandomForest rmse 0.758195 trained in 68.14 seconds\n",
      "7_Xgboost rmse 0.702578 trained in 39.85 seconds\n",
      "11_CatBoost rmse 0.716132 trained in 54.48 seconds\n",
      "15_RandomForest rmse 0.764481 trained in 44.5 seconds\n",
      "* Step hill_climbing_1 will try to check up to 17 models\n",
      "16_CatBoost rmse 0.680324 trained in 64.33 seconds\n",
      "17_CatBoost rmse 0.68341 trained in 49.42 seconds\n",
      "18_CatBoost rmse 0.682535 trained in 66.0 seconds\n",
      "19_CatBoost rmse 0.691594 trained in 54.45 seconds\n",
      "20_CatBoost rmse 0.679384 trained in 102.49 seconds\n",
      "21_CatBoost rmse 0.689438 trained in 69.99 seconds\n",
      "22_Xgboost rmse 0.694574 trained in 37.01 seconds\n",
      "23_Xgboost rmse 0.692538 trained in 37.1 seconds\n",
      "24_Xgboost rmse 0.69705 trained in 42.59 seconds\n",
      "25_Xgboost rmse 0.701961 trained in 40.84 seconds\n",
      "26_Xgboost rmse 0.704639 trained in 41.86 seconds\n",
      "27_Xgboost rmse 0.712852 trained in 38.27 seconds\n",
      "28_RandomForest rmse 0.755796 trained in 56.57 seconds\n",
      "29_RandomForest rmse 0.759645 trained in 41.05 seconds\n",
      "30_RandomForest rmse 0.761312 trained in 76.44 seconds\n",
      "31_RandomForest rmse 0.802914 trained in 52.23 seconds\n",
      "32_RandomForest rmse 0.803781 trained in 42.33 seconds\n",
      "* Step hill_climbing_2 will try to check up to 11 models\n",
      "33_CatBoost rmse 0.680566 trained in 85.49 seconds\n",
      "34_CatBoost rmse 0.681903 trained in 87.42 seconds\n",
      "35_CatBoost rmse 0.684802 trained in 52.26 seconds\n",
      "36_CatBoost rmse 0.683143 trained in 59.09 seconds\n",
      "37_Xgboost rmse 0.695347 trained in 41.75 seconds\n",
      "38_Xgboost rmse 0.696322 trained in 41.4 seconds\n",
      "39_Xgboost rmse 0.688817 trained in 43.17 seconds\n",
      "40_Xgboost rmse 0.69494 trained in 40.32 seconds\n",
      "41_Xgboost rmse 0.691064 trained in 42.41 seconds\n",
      "42_Xgboost rmse 0.692203 trained in 50.16 seconds\n",
      "43_RandomForest rmse 0.754223 trained in 68.77 seconds\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble rmse 0.672166 trained in 1.12 seconds\n",
      "AutoML fit time: 2370.25 seconds\n",
      "AutoML best model: Ensemble\n",
      "R^2 Score: 0.6253442136592793\n",
      "RMSE: 0.9332378506660461\n"
     ]
    }
   ],
   "source": [
    "### Employment Density, NO Spatial Lag, London (5)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london\n",
    "target = 'log_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/employment_density_london/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_5 = r2_score(y_test, predictions)\n",
    "rmse_5 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_5}')\n",
    "print(f'RMSE: {rmse_5}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_5 = automl.predict(all_data_london[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': london_geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all_5,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1faae03a-3177-4923-a949-53cae255a64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model has already been fitted. You can use predict methods or select a new 'results_path' for a new 'fit()'.\n",
      "R^2 Score: 0.5111932494414406\n",
      "RMSE: 0.7408556938171387\n"
     ]
    }
   ],
   "source": [
    "### Employment Density, NO Spatial Lag, Birmingham (6)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_bham\n",
    "target = 'log_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_bham[features], all_data_bham[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/employment_density_bham/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_6 = r2_score(y_test, predictions)\n",
    "rmse_6 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_6}')\n",
    "print(f'RMSE: {rmse_6}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_6 = automl.predict(all_data_bham[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': bham_geometries,\n",
    "    'observed': all_data_bham[target],\n",
    "    'predicted': predictions_all_6,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "907fde61-ed19-43a6-b9b6-3951fb0bd473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: ml_results/employment_density_london_lag/\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['CatBoost', 'Xgboost', 'Random Forest']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "1_Default_Xgboost rmse 0.697738 trained in 232.55 seconds\n",
      "2_Default_CatBoost rmse 0.690238 trained in 300.13 seconds\n",
      "3_Default_RandomForest rmse 0.798875 trained in 162.55 seconds\n",
      "* Step not_so_random will try to check up to 12 models\n",
      "4_Xgboost rmse 0.709979 trained in 268.49 seconds\n",
      "8_CatBoost rmse 0.688124 trained in 397.58 seconds\n",
      "12_RandomForest rmse 0.800764 trained in 184.92 seconds\n",
      "5_Xgboost rmse 0.71357 trained in 252.43 seconds\n",
      "9_CatBoost rmse 0.718557 trained in 361.72 seconds\n",
      "13_RandomForest rmse 0.831279 trained in 275.18 seconds\n",
      "6_Xgboost rmse 0.698883 trained in 274.21 seconds\n",
      "10_CatBoost rmse 0.689076 trained in 366.7 seconds\n",
      "14_RandomForest rmse 0.757065 trained in 278.86 seconds\n",
      "7_Xgboost rmse 0.712213 trained in 265.95 seconds\n",
      "11_CatBoost rmse 0.732671 trained in 362.07 seconds\n",
      "15_RandomForest rmse 0.760273 trained in 274.73 seconds\n",
      "Skip hill_climbing_1 because of the time limit.\n",
      "Skip hill_climbing_2 because of the time limit.\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble rmse 0.679376 trained in 0.24 seconds\n",
      "AutoML fit time: 4267.29 seconds\n",
      "AutoML best model: Ensemble\n",
      "R^2 Score: 0.6193226198819964\n",
      "RMSE: 0.9407076835632324\n"
     ]
    }
   ],
   "source": [
    "### Employment Density, Spatial Lag, London (7)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london_lag\n",
    "target = 'log_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/employment_density_london_lag/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_7 = r2_score(y_test, predictions)\n",
    "rmse_7 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_7}')\n",
    "print(f'RMSE: {rmse_7}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_7 = automl.predict(all_data_london[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': london_geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all_7,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17bb150e-d907-41c8-a5cb-2d3d0e065417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: ml_results/employment_density_bham_lag/\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['CatBoost', 'Xgboost', 'Random Forest']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "1_Default_Xgboost rmse 1.353418 trained in 24.32 seconds\n",
      "2_Default_CatBoost rmse 1.267603 trained in 78.14 seconds\n",
      "3_Default_RandomForest rmse 1.408913 trained in 69.99 seconds\n",
      "* Step not_so_random will try to check up to 12 models\n",
      "4_Xgboost rmse 1.173889 trained in 34.61 seconds\n",
      "8_CatBoost rmse 1.295899 trained in 94.62 seconds\n",
      "12_RandomForest rmse 1.33304 trained in 47.69 seconds\n",
      "5_Xgboost rmse 1.379647 trained in 23.25 seconds\n",
      "9_CatBoost rmse 1.269862 trained in 76.41 seconds\n",
      "13_RandomForest rmse 1.391013 trained in 73.61 seconds\n",
      "6_Xgboost rmse 1.226054 trained in 35.36 seconds\n",
      "10_CatBoost rmse 1.268741 trained in 73.33 seconds\n",
      "14_RandomForest rmse 1.348335 trained in 46.03 seconds\n",
      "7_Xgboost rmse 1.359508 trained in 14.63 seconds\n",
      "11_CatBoost rmse 1.363368 trained in 67.34 seconds\n",
      "15_RandomForest rmse 1.372384 trained in 38.48 seconds\n",
      "* Step hill_climbing_1 will try to check up to 16 models\n",
      "16_Xgboost rmse 1.157348 trained in 21.87 seconds\n",
      "17_Xgboost rmse 1.1854 trained in 25.32 seconds\n",
      "18_Xgboost rmse 1.223913 trained in 18.22 seconds\n",
      "19_Xgboost rmse 1.23847 trained in 20.61 seconds\n",
      "20_CatBoost rmse 1.260111 trained in 66.76 seconds\n",
      "21_CatBoost rmse 1.301924 trained in 59.02 seconds\n",
      "22_CatBoost rmse 1.256219 trained in 70.61 seconds\n",
      "23_CatBoost rmse 1.292834 trained in 63.99 seconds\n",
      "24_CatBoost rmse 1.275645 trained in 77.79 seconds\n",
      "25_RandomForest rmse 1.333603 trained in 47.19 seconds\n",
      "26_RandomForest rmse 1.369193 trained in 41.29 seconds\n",
      "27_RandomForest rmse 1.35427 trained in 42.12 seconds\n",
      "28_RandomForest rmse 1.344816 trained in 41.5 seconds\n",
      "29_Xgboost rmse 1.334026 trained in 21.53 seconds\n",
      "30_Xgboost rmse 1.371441 trained in 19.22 seconds\n",
      "31_RandomForest rmse 1.372037 trained in 40.13 seconds\n",
      "* Step hill_climbing_2 will try to check up to 6 models\n",
      "32_Xgboost rmse 1.127068 trained in 22.91 seconds\n",
      "33_Xgboost rmse 1.128246 trained in 27.47 seconds\n",
      "34_Xgboost rmse 1.133041 trained in 23.28 seconds\n",
      "35_CatBoost rmse 1.259759 trained in 69.81 seconds\n",
      "36_CatBoost rmse 1.24988 trained in 65.06 seconds\n",
      "37_CatBoost rmse 1.288869 trained in 80.29 seconds\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble rmse 1.122467 trained in 0.79 seconds\n",
      "AutoML fit time: 1782.97 seconds\n",
      "AutoML best model: Ensemble\n",
      "R^2 Score: 0.37332302956948293\n",
      "RMSE: 0.838854968547821\n"
     ]
    }
   ],
   "source": [
    "### Employment Density, Spatial Lag, Birmingham (8)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_bham_lag\n",
    "target = 'log_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_bham[features], all_data_bham[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/employment_density_bham_lag/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_8 = r2_score(y_test, predictions)\n",
    "rmse_8 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_8}')\n",
    "print(f'RMSE: {rmse_8}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_8 = automl.predict(all_data_bham[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': bham_geometries,\n",
    "    'observed': all_data_bham[target],\n",
    "    'predicted': predictions_all_8,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f6e4682-7e10-4638-bb3c-a08c426b9f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: ml_results/office_employment_density_london/\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['CatBoost', 'Xgboost', 'Random Forest']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "1_Default_Xgboost rmse 2.739224 trained in 49.6 seconds\n",
      "2_Default_CatBoost rmse 2.71313 trained in 46.79 seconds\n",
      "3_Default_RandomForest rmse 2.760138 trained in 38.08 seconds\n",
      "* Step not_so_random will try to check up to 12 models\n",
      "4_Xgboost rmse 2.762019 trained in 33.26 seconds\n",
      "8_CatBoost rmse 2.713449 trained in 51.59 seconds\n",
      "12_RandomForest rmse 2.754715 trained in 65.6 seconds\n",
      "5_Xgboost rmse 2.758853 trained in 35.07 seconds\n",
      "9_CatBoost rmse 2.769966 trained in 60.98 seconds\n",
      "13_RandomForest rmse 2.770016 trained in 60.39 seconds\n",
      "6_Xgboost rmse 2.71209 trained in 35.54 seconds\n",
      "10_CatBoost rmse 2.709689 trained in 50.22 seconds\n",
      "14_RandomForest rmse 2.751655 trained in 42.11 seconds\n",
      "7_Xgboost rmse 2.723612 trained in 34.46 seconds\n",
      "11_CatBoost rmse 2.799481 trained in 49.16 seconds\n",
      "15_RandomForest rmse 2.741244 trained in 56.08 seconds\n",
      "* Step hill_climbing_1 will try to check up to 17 models\n",
      "16_CatBoost rmse 2.713267 trained in 58.0 seconds\n",
      "17_CatBoost rmse 2.733501 trained in 48.39 seconds\n",
      "18_Xgboost rmse 2.715049 trained in 36.56 seconds\n",
      "19_Xgboost rmse 2.720897 trained in 37.94 seconds\n",
      "20_CatBoost rmse 2.711933 trained in 54.88 seconds\n",
      "21_CatBoost rmse 2.727665 trained in 50.9 seconds\n",
      "22_CatBoost rmse 2.715669 trained in 74.52 seconds\n",
      "23_CatBoost rmse 2.711428 trained in 58.79 seconds\n",
      "24_Xgboost rmse 2.716767 trained in 38.04 seconds\n",
      "25_Xgboost rmse 2.72445 trained in 37.49 seconds\n",
      "26_Xgboost rmse 2.722816 trained in 37.62 seconds\n",
      "27_Xgboost rmse 2.744242 trained in 37.77 seconds\n",
      "28_RandomForest rmse 2.740208 trained in 55.14 seconds\n",
      "29_RandomForest rmse 2.751671 trained in 45.27 seconds\n",
      "30_RandomForest rmse 2.753954 trained in 44.11 seconds\n",
      "31_RandomForest rmse 2.756553 trained in 62.85 seconds\n",
      "32_RandomForest rmse 2.754825 trained in 81.5 seconds\n",
      "* Step hill_climbing_2 will try to check up to 11 models\n",
      "33_CatBoost rmse 2.715577 trained in 58.37 seconds\n",
      "34_CatBoost rmse 2.714813 trained in 61.37 seconds\n",
      "35_CatBoost rmse 2.718929 trained in 59.19 seconds\n",
      "36_CatBoost rmse 2.712293 trained in 57.11 seconds\n",
      "37_Xgboost rmse 2.72213 trained in 38.95 seconds\n",
      "38_Xgboost rmse 2.712368 trained in 38.88 seconds\n",
      "39_Xgboost rmse 2.718075 trained in 36.75 seconds\n",
      "40_Xgboost rmse 2.705494 trained in 38.86 seconds\n",
      "41_Xgboost rmse 2.742799 trained in 38.97 seconds\n",
      "42_Xgboost rmse 2.730743 trained in 36.47 seconds\n",
      "43_RandomForest rmse 2.738993 trained in 58.23 seconds\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble rmse 2.686453 trained in 1.04 seconds\n",
      "AutoML fit time: 2114.95 seconds\n",
      "AutoML best model: Ensemble\n",
      "R^2 Score: 0.27610491010100624\n",
      "RMSE: 2.7615818977355957\n"
     ]
    }
   ],
   "source": [
    "### Office Employment Density , NO Spatial Lag, London (9)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london\n",
    "target = 'log_office_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/office_employment_density_london/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_9 = r2_score(y_test, predictions)\n",
    "rmse_9 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_9}')\n",
    "print(f'RMSE: {rmse_9}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_9 = automl.predict(all_data_london[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': london_geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all_9,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "015c372b-1b93-4550-b7f5-ece1ad3149b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: ml_results/office_employment_density_bham/\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['CatBoost', 'Xgboost', 'Random Forest']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "1_Default_Xgboost rmse 5.404019 trained in 5.21 seconds\n",
      "2_Default_CatBoost rmse 5.122997 trained in 15.11 seconds\n",
      "3_Default_RandomForest rmse 5.151581 trained in 17.66 seconds\n",
      "* Step not_so_random will try to check up to 12 models\n",
      "4_Xgboost rmse 5.401887 trained in 5.19 seconds\n",
      "8_CatBoost rmse 5.132065 trained in 16.97 seconds\n",
      "12_RandomForest rmse 5.126394 trained in 21.73 seconds\n",
      "5_Xgboost rmse 5.463122 trained in 4.87 seconds\n",
      "9_CatBoost rmse 5.375915 trained in 17.82 seconds\n",
      "13_RandomForest rmse 5.120823 trained in 21.18 seconds\n",
      "6_Xgboost rmse 5.246069 trained in 5.14 seconds\n",
      "10_CatBoost rmse 5.132518 trained in 16.16 seconds\n",
      "14_RandomForest rmse 5.216656 trained in 37.21 seconds\n",
      "7_Xgboost rmse 5.118275 trained in 5.75 seconds\n",
      "11_CatBoost rmse 5.564022 trained in 19.57 seconds\n",
      "15_RandomForest rmse 5.148596 trained in 19.09 seconds\n",
      "* Step hill_climbing_1 will try to check up to 16 models\n",
      "16_Xgboost rmse 5.118275 trained in 4.88 seconds\n",
      "17_Xgboost rmse 5.118275 trained in 5.21 seconds\n",
      "18_RandomForest rmse 5.120313 trained in 18.98 seconds\n",
      "19_CatBoost rmse 5.118059 trained in 16.06 seconds\n",
      "20_CatBoost rmse 5.157867 trained in 15.46 seconds\n",
      "21_RandomForest rmse 5.138602 trained in 20.19 seconds\n",
      "22_RandomForest rmse 5.108533 trained in 30.72 seconds\n",
      "23_CatBoost rmse 5.142392 trained in 18.55 seconds\n",
      "24_CatBoost rmse 5.146983 trained in 16.39 seconds\n",
      "25_CatBoost rmse 5.129658 trained in 15.47 seconds\n",
      "26_CatBoost rmse 5.135349 trained in 14.5 seconds\n",
      "27_RandomForest rmse 5.15447 trained in 18.79 seconds\n",
      "28_Xgboost rmse 5.23588 trained in 7.92 seconds\n",
      "29_Xgboost rmse 5.246069 trained in 10.89 seconds\n",
      "30_Xgboost rmse 5.3519 trained in 7.47 seconds\n",
      "31_Xgboost rmse 5.387265 trained in 12.17 seconds\n",
      "* Step hill_climbing_2 will try to check up to 11 models\n",
      "32_RandomForest rmse 5.115283 trained in 65.25 seconds\n",
      "33_CatBoost rmse 5.12575 trained in 39.92 seconds\n",
      "34_Xgboost rmse 5.104942 trained in 10.78 seconds\n",
      "35_Xgboost rmse 5.110614 trained in 10.87 seconds\n",
      "36_Xgboost rmse 5.104942 trained in 9.88 seconds\n",
      "37_Xgboost rmse 5.110614 trained in 10.31 seconds\n",
      "38_Xgboost rmse 5.104942 trained in 9.86 seconds\n",
      "39_Xgboost rmse 5.110614 trained in 9.3 seconds\n",
      "40_RandomForest rmse 5.117547 trained in 42.39 seconds\n",
      "41_CatBoost rmse 5.138344 trained in 39.32 seconds\n",
      "42_CatBoost rmse 5.0879 trained in 42.85 seconds\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble rmse 5.060277 trained in 1.56 seconds\n",
      "AutoML fit time: 781.37 seconds\n",
      "AutoML best model: Ensemble\n",
      "R^2 Score: 0.21593458288922895\n",
      "RMSE: 4.864013195037842\n"
     ]
    }
   ],
   "source": [
    "### Office Employment Density , NO Spatial Lag, Birmingham (10)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_bham\n",
    "target = 'log_office_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_bham[features], all_data_bham[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/office_employment_density_bham/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_10 = r2_score(y_test, predictions)\n",
    "rmse_10 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_10}')\n",
    "print(f'RMSE: {rmse_10}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_10 = automl.predict(all_data_bham[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': bham_geometries,\n",
    "    'observed': all_data_bham[target],\n",
    "    'predicted': predictions_all_10,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7d3160a4-8d0e-4048-acb5-a9f8e51ef901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: ml_results/office_employment_density_london_lag/\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['CatBoost', 'Xgboost', 'Random Forest']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "1_Default_Xgboost rmse 2.72239 trained in 479.15 seconds\n",
      "2_Default_CatBoost rmse 2.694881 trained in 1326.25 seconds\n",
      "3_Default_RandomForest rmse 2.733079 trained in 456.66 seconds\n",
      "* Step not_so_random will try to check up to 12 models\n",
      "4_Xgboost rmse 2.741218 trained in 403.56 seconds\n",
      "8_CatBoost rmse 2.678956 trained in 448.05 seconds\n",
      "12_RandomForest rmse 2.729309 trained in 481.29 seconds\n",
      "5_Xgboost rmse 2.738837 trained in 272.36 seconds\n",
      "9_CatBoost rmse 2.765419 trained in 1396.51 seconds\n",
      "13_RandomForest rmse 2.741959 trained in 1270.79 seconds\n",
      "6_Xgboost rmse 2.69272 trained in 258.42 seconds\n",
      "10_CatBoost rmse 2.67656 trained in 393.39 seconds\n",
      "14_RandomForest rmse 2.731702 trained in 198.01 seconds\n",
      "7_Xgboost rmse 2.689241 trained in 291.27 seconds\n",
      "11_CatBoost rmse 2.762793 trained in 489.44 seconds\n",
      "15_RandomForest rmse 2.721873 trained in 277.38 seconds\n",
      "Skip hill_climbing_1 because of the time limit.\n",
      "Skip hill_climbing_2 because of the time limit.\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble rmse 2.653081 trained in 0.18 seconds\n",
      "AutoML fit time: 8454.63 seconds\n",
      "AutoML best model: Ensemble\n",
      "R^2 Score: 0.2994245739928941\n",
      "RMSE: 2.7167367935180664\n"
     ]
    }
   ],
   "source": [
    "### Office Employment Density, Spatial Lag, London (11)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london_lag\n",
    "target = 'log_office_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/office_employment_density_london_lag/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_11 = r2_score(y_test, predictions)\n",
    "rmse_11 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_11}')\n",
    "print(f'RMSE: {rmse_11}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_11 = automl.predict(all_data_london[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': london_geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all_11,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c793ac54-59e8-4ff0-b95a-0bb60d1edd9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: ml_results/office_employment_density_bham_lag/\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['CatBoost', 'Xgboost', 'Random Forest']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "1_Default_Xgboost rmse 5.336605 trained in 19.38 seconds\n",
      "2_Default_CatBoost rmse 5.02307 trained in 61.29 seconds\n",
      "3_Default_RandomForest rmse 5.043493 trained in 42.99 seconds\n",
      "* Step not_so_random will try to check up to 12 models\n",
      "4_Xgboost rmse 5.300897 trained in 16.67 seconds\n",
      "8_CatBoost rmse 5.023225 trained in 68.6 seconds\n",
      "12_RandomForest rmse 4.962146 trained in 51.38 seconds\n",
      "5_Xgboost rmse 5.45159 trained in 17.15 seconds\n",
      "9_CatBoost rmse 5.248273 trained in 67.69 seconds\n",
      "13_RandomForest rmse 4.997425 trained in 40.14 seconds\n",
      "6_Xgboost rmse 5.12106 trained in 16.09 seconds\n",
      "10_CatBoost rmse 5.076031 trained in 62.01 seconds\n",
      "14_RandomForest rmse 5.08087 trained in 42.53 seconds\n",
      "7_Xgboost rmse 4.967613 trained in 14.06 seconds\n",
      "11_CatBoost rmse 5.517362 trained in 63.48 seconds\n",
      "15_RandomForest rmse 4.974259 trained in 41.85 seconds\n",
      "* Step hill_climbing_1 will try to check up to 16 models\n",
      "16_RandomForest rmse 5.007734 trained in 47.5 seconds\n",
      "17_RandomForest rmse 4.967341 trained in 48.72 seconds\n",
      "18_Xgboost rmse 4.967613 trained in 15.42 seconds\n",
      "19_Xgboost rmse 4.967613 trained in 16.14 seconds\n",
      "20_RandomForest rmse 4.98028 trained in 42.86 seconds\n",
      "21_RandomForest rmse 4.982823 trained in 40.4 seconds\n",
      "22_CatBoost rmse 5.000583 trained in 62.4 seconds\n",
      "23_CatBoost rmse 4.989771 trained in 62.16 seconds\n",
      "24_CatBoost rmse 5.043473 trained in 72.88 seconds\n",
      "25_CatBoost rmse 5.022048 trained in 66.35 seconds\n",
      "26_CatBoost rmse 5.062768 trained in 66.74 seconds\n",
      "27_CatBoost rmse 5.073171 trained in 63.93 seconds\n",
      "28_Xgboost rmse 5.094158 trained in 19.24 seconds\n",
      "29_Xgboost rmse 5.12106 trained in 18.28 seconds\n",
      "30_Xgboost rmse 5.299218 trained in 18.21 seconds\n",
      "31_Xgboost rmse 5.323439 trained in 18.03 seconds\n",
      "* Step hill_climbing_2 will try to check up to 11 models\n",
      "32_RandomForest rmse 5.025529 trained in 59.76 seconds\n",
      "33_Xgboost rmse 5.003273 trained in 15.53 seconds\n",
      "34_Xgboost rmse 5.049415 trained in 16.97 seconds\n",
      "35_Xgboost rmse 5.003273 trained in 18.63 seconds\n",
      "36_Xgboost rmse 5.049415 trained in 18.98 seconds\n",
      "37_Xgboost rmse 5.003273 trained in 17.9 seconds\n",
      "38_Xgboost rmse 5.049415 trained in 17.49 seconds\n",
      "39_CatBoost rmse 5.024078 trained in 63.0 seconds\n",
      "40_CatBoost rmse 5.051631 trained in 64.43 seconds\n",
      "41_CatBoost rmse 5.0894 trained in 68.3 seconds\n",
      "42_CatBoost rmse 5.054453 trained in 68.95 seconds\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble rmse 4.879884 trained in 1.11 seconds\n",
      "AutoML fit time: 1757.97 seconds\n",
      "AutoML best model: Ensemble\n",
      "R^2 Score: 0.20913983486148735\n",
      "RMSE: 4.885044097900391\n"
     ]
    }
   ],
   "source": [
    "### Office Employment Density (log), Spatial Lag, Birmingham (12)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_bham_lag\n",
    "target = 'log_office_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_bham[features], all_data_bham[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/office_employment_density_bham_lag/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_12 = r2_score(y_test, predictions)\n",
    "rmse_12 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_12}')\n",
    "print(f'RMSE: {rmse_12}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_12 = automl.predict(all_data_bham[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': bham_geometries,\n",
    "    'observed': all_data_bham[target],\n",
    "    'predicted': predictions_all_12,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c0592585-a869-42b2-9ccd-c7ebe0bef895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model has already been fitted. You can use predict methods or select a new 'results_path' for a new 'fit()'.\n",
      "R^2 Score: 0.7256287050510382\n",
      "RMSE: 0.672401487827301\n"
     ]
    }
   ],
   "source": [
    "### Employment (log), NO Spatial Lag, London, POI only (13)\n",
    "\n",
    "# Ignore depracation warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london_poi\n",
    "target = 'log_total_employment'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/log_employment_london_poi/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_13 = r2_score(y_test, predictions)\n",
    "rmse_13 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_13}')\n",
    "print(f'RMSE: {rmse_13}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_13 = automl.predict(all_data_london[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': london_geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all_13,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b3ff96c6-9be8-4705-83e2-67f8876eb238",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gavinrolls/anaconda3/envs/urbsim/lib/python3.11/site-packages/supervised/preprocessing/exclude_missing_target.py:25: UserWarning: There are samples with missing target values in the data which will be excluded for further analysis\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: ml_results/log_employment_bham_poi/\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['CatBoost', 'Xgboost', 'Random Forest']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "1_Default_Xgboost rmse 0.796247 trained in 1077.34 seconds\n",
      "2_Default_CatBoost rmse 0.811589 trained in 10.74 seconds\n",
      "3_Default_RandomForest rmse 0.819108 trained in 18.32 seconds\n",
      "* Step not_so_random will try to check up to 12 models\n",
      "4_Xgboost rmse 0.814556 trained in 4.52 seconds\n",
      "8_CatBoost rmse 0.820528 trained in 17.07 seconds\n",
      "12_RandomForest rmse 0.81786 trained in 18.95 seconds\n",
      "5_Xgboost rmse 0.818373 trained in 5.14 seconds\n",
      "9_CatBoost rmse 0.835969 trained in 14.25 seconds\n",
      "13_RandomForest rmse 0.847451 trained in 20.41 seconds\n",
      "6_Xgboost rmse 0.786124 trained in 4.86 seconds\n",
      "10_CatBoost rmse 0.823456 trained in 13.13 seconds\n",
      "14_RandomForest rmse 0.816404 trained in 20.54 seconds\n",
      "7_Xgboost rmse 0.860902 trained in 4.61 seconds\n",
      "11_CatBoost rmse 0.859474 trained in 13.83 seconds\n",
      "15_RandomForest rmse 0.824256 trained in 19.11 seconds\n",
      "* Step hill_climbing_1 will try to check up to 18 models\n",
      "16_Xgboost rmse 0.78515 trained in 4.85 seconds\n",
      "17_Xgboost rmse 0.789404 trained in 4.81 seconds\n",
      "18_Xgboost rmse 0.78776 trained in 4.72 seconds\n",
      "19_Xgboost rmse 0.807992 trained in 5.16 seconds\n",
      "20_CatBoost rmse 0.794589 trained in 13.96 seconds\n",
      "21_CatBoost rmse 0.810056 trained in 12.73 seconds\n",
      "22_Xgboost rmse 0.810594 trained in 5.48 seconds\n",
      "23_Xgboost rmse 0.812881 trained in 5.85 seconds\n",
      "24_RandomForest rmse 0.808417 trained in 20.7 seconds\n",
      "25_RandomForest rmse 0.828899 trained in 18.61 seconds\n",
      "26_RandomForest rmse 0.81791 trained in 19.22 seconds\n",
      "27_RandomForest rmse 0.820985 trained in 21.68 seconds\n",
      "28_RandomForest rmse 0.813939 trained in 20.54 seconds\n",
      "29_RandomForest rmse 0.825659 trained in 20.7 seconds\n",
      "30_CatBoost rmse 0.826822 trained in 22.93 seconds\n",
      "31_CatBoost rmse 0.837677 trained in 14.62 seconds\n",
      "32_CatBoost rmse 0.81028 trained in 14.74 seconds\n",
      "33_CatBoost rmse 0.818305 trained in 13.59 seconds\n",
      "* Step hill_climbing_2 will try to check up to 11 models\n",
      "34_Xgboost rmse 0.784243 trained in 4.96 seconds\n",
      "35_Xgboost rmse 0.788559 trained in 4.93 seconds\n",
      "36_Xgboost rmse 0.785134 trained in 5.0 seconds\n",
      "37_Xgboost rmse 0.788556 trained in 5.14 seconds\n",
      "38_Xgboost rmse 0.798748 trained in 5.15 seconds\n",
      "39_CatBoost rmse 0.804644 trained in 27.01 seconds\n",
      "40_RandomForest rmse 0.800958 trained in 18.56 seconds\n",
      "41_CatBoost rmse 0.814851 trained in 17.99 seconds\n",
      "42_RandomForest rmse 0.809814 trained in 17.02 seconds\n",
      "43_RandomForest rmse 0.813948 trained in 24.13 seconds\n",
      "44_RandomForest rmse 0.808648 trained in 17.94 seconds\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble rmse 0.768035 trained in 1.09 seconds\n",
      "AutoML fit time: 1676.53 seconds\n",
      "AutoML best model: Ensemble\n",
      "R^2 Score: 0.629515890174141\n",
      "RMSE: 0.7245278358459473\n"
     ]
    }
   ],
   "source": [
    "### Employment (log), NO Spatial Lag, Brimingham, POI only (14)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_bham_poi\n",
    "target = 'log_total_employment'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_bham[features], all_data_bham[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/log_employment_bham_poi/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_14 = r2_score(y_test, predictions)\n",
    "rmse_14 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_14}')\n",
    "print(f'RMSE: {rmse_14}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_14 = automl.predict(all_data_bham[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': bham_geometries,\n",
    "    'observed': all_data_bham[target],\n",
    "    'predicted': predictions_all_14,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2d4bf1d6-902a-4011-b805-4e1d2df8644e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: ml_results/employment_density_london_poi/\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['CatBoost', 'Xgboost', 'Random Forest']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "1_Default_Xgboost rmse 0.840984 trained in 44.7 seconds\n",
      "2_Default_CatBoost rmse 0.814014 trained in 59.57 seconds\n",
      "3_Default_RandomForest rmse 0.924622 trained in 51.37 seconds\n",
      "* Step not_so_random will try to check up to 12 models\n",
      "4_Xgboost rmse 0.84294 trained in 45.0 seconds\n",
      "8_CatBoost rmse 0.81187 trained in 72.75 seconds\n",
      "12_RandomForest rmse 0.922826 trained in 50.62 seconds\n",
      "5_Xgboost rmse 0.852902 trained in 46.74 seconds\n",
      "9_CatBoost rmse 0.828331 trained in 65.24 seconds\n",
      "13_RandomForest rmse 0.942056 trained in 55.18 seconds\n",
      "6_Xgboost rmse 0.821199 trained in 42.32 seconds\n",
      "10_CatBoost rmse 0.810297 trained in 58.9 seconds\n",
      "14_RandomForest rmse 0.905125 trained in 91.12 seconds\n",
      "7_Xgboost rmse 0.828008 trained in 43.57 seconds\n",
      "11_CatBoost rmse 0.840954 trained in 58.99 seconds\n",
      "15_RandomForest rmse 0.900128 trained in 65.81 seconds\n",
      "* Step hill_climbing_1 will try to check up to 17 models\n",
      "16_CatBoost rmse 0.80753 trained in 65.93 seconds\n",
      "17_CatBoost rmse 0.818943 trained in 52.48 seconds\n",
      "18_CatBoost rmse 0.811036 trained in 97.24 seconds\n",
      "19_CatBoost rmse 0.817061 trained in 60.27 seconds\n",
      "20_CatBoost rmse 0.812105 trained in 64.44 seconds\n",
      "21_CatBoost rmse 0.820547 trained in 53.71 seconds\n",
      "22_Xgboost rmse 0.82159 trained in 41.43 seconds\n",
      "23_Xgboost rmse 0.821568 trained in 42.39 seconds\n",
      "24_Xgboost rmse 0.827118 trained in 38.93 seconds\n",
      "25_Xgboost rmse 0.831562 trained in 40.35 seconds\n",
      "26_Xgboost rmse 0.832297 trained in 43.92 seconds\n",
      "27_Xgboost rmse 0.846882 trained in 49.47 seconds\n",
      "28_RandomForest rmse 0.899549 trained in 58.15 seconds\n",
      "29_RandomForest rmse 0.904449 trained in 87.28 seconds\n",
      "30_RandomForest rmse 0.906677 trained in 70.79 seconds\n",
      "31_RandomForest rmse 0.922751 trained in 50.48 seconds\n",
      "32_RandomForest rmse 0.923266 trained in 50.02 seconds\n",
      "* Step hill_climbing_2 will try to check up to 12 models\n",
      "33_CatBoost rmse 0.808846 trained in 71.67 seconds\n",
      "34_CatBoost rmse 0.813224 trained in 58.66 seconds\n",
      "35_CatBoost rmse 0.810257 trained in 91.75 seconds\n",
      "36_CatBoost rmse 0.812278 trained in 102.9 seconds\n",
      "37_Xgboost rmse 0.821872 trained in 44.24 seconds\n",
      "38_Xgboost rmse 0.821578 trained in 43.99 seconds\n",
      "39_Xgboost rmse 0.826858 trained in 43.33 seconds\n",
      "40_Xgboost rmse 0.820945 trained in 44.53 seconds\n",
      "41_Xgboost rmse 0.821691 trained in 42.92 seconds\n",
      "42_Xgboost rmse 0.821186 trained in 43.49 seconds\n",
      "43_RandomForest rmse 0.899371 trained in 73.81 seconds\n",
      "44_RandomForest rmse 0.904233 trained in 86.56 seconds\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble rmse 0.802351 trained in 1.34 seconds\n",
      "AutoML fit time: 2594.06 seconds\n",
      "AutoML best model: Ensemble\n",
      "R^2 Score: 0.5580651501729622\n",
      "RMSE: 1.0135735273361206\n"
     ]
    }
   ],
   "source": [
    "### Employment Density, NO Spatial Lag, London, POI only (15)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london_poi\n",
    "target = 'log_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/employment_density_london_poi/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_15 = r2_score(y_test, predictions)\n",
    "rmse_15 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_15}')\n",
    "print(f'RMSE: {rmse_15}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_15 = automl.predict(all_data_london[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': london_geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all_15,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "88b18222-1efa-4451-b8a1-5d26ba8f83cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: ml_results/employment_density_bham_poi/\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['CatBoost', 'Xgboost', 'Random Forest']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "1_Default_Xgboost rmse 1.517861 trained in 6.26 seconds\n",
      "2_Default_CatBoost rmse 1.408012 trained in 17.48 seconds\n",
      "3_Default_RandomForest rmse 1.376875 trained in 21.37 seconds\n",
      "* Step not_so_random will try to check up to 12 models\n",
      "4_Xgboost rmse 1.370111 trained in 6.04 seconds\n",
      "8_CatBoost rmse 1.411766 trained in 23.26 seconds\n",
      "12_RandomForest rmse 1.390271 trained in 27.25 seconds\n",
      "5_Xgboost rmse 1.514992 trained in 5.73 seconds\n",
      "9_CatBoost rmse 1.39722 trained in 19.47 seconds\n",
      "13_RandomForest rmse 1.383289 trained in 26.58 seconds\n",
      "6_Xgboost rmse 1.342191 trained in 5.39 seconds\n",
      "10_CatBoost rmse 1.391042 trained in 16.18 seconds\n",
      "14_RandomForest rmse 1.360327 trained in 19.27 seconds\n",
      "7_Xgboost rmse 1.417122 trained in 5.21 seconds\n",
      "11_CatBoost rmse 1.413605 trained in 15.51 seconds\n",
      "15_RandomForest rmse 1.373942 trained in 24.64 seconds\n",
      "* Step hill_climbing_1 will try to check up to 16 models\n",
      "16_Xgboost rmse 1.344318 trained in 5.27 seconds\n",
      "17_Xgboost rmse 1.341487 trained in 5.19 seconds\n",
      "18_RandomForest rmse 1.356987 trained in 19.67 seconds\n",
      "19_RandomForest rmse 1.364384 trained in 19.18 seconds\n",
      "20_Xgboost rmse 1.384566 trained in 5.34 seconds\n",
      "21_Xgboost rmse 1.382354 trained in 5.49 seconds\n",
      "22_RandomForest rmse 1.367087 trained in 24.48 seconds\n",
      "23_RandomForest rmse 1.382068 trained in 19.63 seconds\n",
      "24_RandomForest rmse 1.377571 trained in 20.08 seconds\n",
      "25_CatBoost rmse 1.405167 trained in 18.52 seconds\n",
      "26_CatBoost rmse 1.382428 trained in 15.64 seconds\n",
      "27_CatBoost rmse 1.369638 trained in 21.68 seconds\n",
      "28_CatBoost rmse 1.409935 trained in 16.47 seconds\n",
      "29_CatBoost rmse 1.408465 trained in 15.46 seconds\n",
      "30_Xgboost rmse 1.417122 trained in 5.52 seconds\n",
      "31_Xgboost rmse 1.417122 trained in 5.51 seconds\n",
      "* Step hill_climbing_2 will try to check up to 10 models\n",
      "32_Xgboost rmse 1.348734 trained in 5.59 seconds\n",
      "33_Xgboost rmse 1.354254 trained in 5.56 seconds\n",
      "34_Xgboost rmse 1.346779 trained in 5.85 seconds\n",
      "35_Xgboost rmse 1.354942 trained in 5.63 seconds\n",
      "36_Xgboost rmse 1.353275 trained in 5.61 seconds\n",
      "37_Xgboost rmse 1.348106 trained in 5.62 seconds\n",
      "38_RandomForest rmse 1.367208 trained in 21.03 seconds\n",
      "39_CatBoost rmse 1.396107 trained in 22.27 seconds\n",
      "40_CatBoost rmse 1.393261 trained in 15.83 seconds\n",
      "41_CatBoost rmse 1.406717 trained in 16.23 seconds\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble rmse 1.322194 trained in 1.04 seconds\n",
      "AutoML fit time: 594.38 seconds\n",
      "AutoML best model: Ensemble\n",
      "R^2 Score: 0.5037960684151483\n",
      "RMSE: 0.7464403510093689\n"
     ]
    }
   ],
   "source": [
    "### Employment Density, NO Spatial Lag, Brimingham, POI only (16)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_bham_poi\n",
    "target = 'log_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_bham[features], all_data_bham[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/employment_density_bham_poi/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_16 = r2_score(y_test, predictions)\n",
    "rmse_16 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_16}')\n",
    "print(f'RMSE: {rmse_16}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_16 = automl.predict(all_data_bham[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': bham_geometries,\n",
    "    'observed': all_data_bham[target],\n",
    "    'predicted': predictions_all_16,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "154710f6-e527-4512-8861-573d0f26d504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: ml_results/office_employment_density_london_poi/\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['CatBoost', 'Xgboost', 'Random Forest']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "1_Default_Xgboost rmse 2.802686 trained in 40.11 seconds\n",
      "2_Default_CatBoost rmse 2.762391 trained in 53.19 seconds\n",
      "3_Default_RandomForest rmse 2.825558 trained in 64.46 seconds\n",
      "* Step not_so_random will try to check up to 12 models\n",
      "4_Xgboost rmse 2.801478 trained in 42.66 seconds\n",
      "8_CatBoost rmse 2.766985 trained in 62.17 seconds\n",
      "12_RandomForest rmse 2.821661 trained in 41.78 seconds\n",
      "5_Xgboost rmse 2.835608 trained in 38.75 seconds\n",
      "9_CatBoost rmse 2.82143 trained in 61.87 seconds\n",
      "13_RandomForest rmse 2.834388 trained in 49.4 seconds\n",
      "6_Xgboost rmse 2.77333 trained in 40.05 seconds\n",
      "10_CatBoost rmse 2.764909 trained in 57.18 seconds\n",
      "14_RandomForest rmse 2.819163 trained in 59.75 seconds\n",
      "7_Xgboost rmse 2.76677 trained in 38.05 seconds\n",
      "11_CatBoost rmse 2.829712 trained in 57.78 seconds\n",
      "15_RandomForest rmse 2.80696 trained in 61.22 seconds\n",
      "* Step hill_climbing_1 will try to check up to 17 models\n",
      "16_CatBoost rmse 2.766942 trained in 54.13 seconds\n",
      "17_CatBoost rmse 2.776197 trained in 50.93 seconds\n",
      "18_CatBoost rmse 2.766564 trained in 56.85 seconds\n",
      "19_CatBoost rmse 2.770399 trained in 49.24 seconds\n",
      "20_Xgboost rmse 2.762353 trained in 37.88 seconds\n",
      "21_Xgboost rmse 2.769972 trained in 38.36 seconds\n",
      "22_CatBoost rmse 2.765467 trained in 69.69 seconds\n",
      "23_CatBoost rmse 2.770135 trained in 54.63 seconds\n",
      "24_Xgboost rmse 2.76055 trained in 36.95 seconds\n",
      "25_Xgboost rmse 2.773617 trained in 37.45 seconds\n",
      "26_Xgboost rmse 2.791422 trained in 39.5 seconds\n",
      "27_Xgboost rmse 2.816002 trained in 38.9 seconds\n",
      "28_RandomForest rmse 2.809274 trained in 57.11 seconds\n",
      "29_RandomForest rmse 2.819857 trained in 48.4 seconds\n",
      "30_RandomForest rmse 2.819925 trained in 48.54 seconds\n",
      "31_RandomForest rmse 2.821813 trained in 41.56 seconds\n",
      "32_RandomForest rmse 2.821848 trained in 41.95 seconds\n",
      "* Step hill_climbing_2 will try to check up to 11 models\n",
      "33_Xgboost rmse 2.761494 trained in 38.79 seconds\n",
      "34_Xgboost rmse 2.767602 trained in 38.84 seconds\n",
      "35_Xgboost rmse 2.77348 trained in 36.38 seconds\n",
      "36_Xgboost rmse 2.762746 trained in 36.18 seconds\n",
      "37_CatBoost rmse 2.763042 trained in 53.93 seconds\n",
      "38_CatBoost rmse 2.767985 trained in 53.95 seconds\n",
      "39_CatBoost rmse 2.765683 trained in 69.49 seconds\n",
      "40_CatBoost rmse 2.766126 trained in 68.98 seconds\n",
      "41_Xgboost rmse 2.774146 trained in 37.78 seconds\n",
      "42_Xgboost rmse 2.764265 trained in 37.42 seconds\n",
      "43_RandomForest rmse 2.808132 trained in 56.97 seconds\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble rmse 2.735418 trained in 1.2 seconds\n",
      "AutoML fit time: 2125.53 seconds\n",
      "AutoML best model: Ensemble\n",
      "R^2 Score: 0.2724395361638151\n",
      "RMSE: 2.7685647010803223\n"
     ]
    }
   ],
   "source": [
    "### Office Employment Density, NO Spatial Lag, London, POI only (17)\n",
    "\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london_poi\n",
    "target = 'log_office_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/office_employment_density_london_poi/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_17 = r2_score(y_test, predictions)\n",
    "rmse_17 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_17}')\n",
    "print(f'RMSE: {rmse_17}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_17 = automl.predict(all_data_london[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': london_geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all_17,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "27df441e-a493-4c24-88e7-a302f6e05843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: ml_results/office_employment_density_bham_poi/\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['CatBoost', 'Xgboost', 'Random Forest']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "1_Default_Xgboost rmse 5.42164 trained in 5.6 seconds\n",
      "2_Default_CatBoost rmse 5.09459 trained in 15.02 seconds\n",
      "3_Default_RandomForest rmse 5.192729 trained in 17.84 seconds\n",
      "* Step not_so_random will try to check up to 12 models\n",
      "4_Xgboost rmse 5.411548 trained in 6.45 seconds\n",
      "8_CatBoost rmse 5.125306 trained in 17.7 seconds\n",
      "12_RandomForest rmse 5.093381 trained in 32.24 seconds\n",
      "5_Xgboost rmse 5.451696 trained in 5.33 seconds\n",
      "9_CatBoost rmse 5.528178 trained in 18.15 seconds\n",
      "13_RandomForest rmse 5.113417 trained in 17.51 seconds\n",
      "6_Xgboost rmse 5.237071 trained in 5.09 seconds\n",
      "10_CatBoost rmse 5.094644 trained in 14.95 seconds\n",
      "14_RandomForest rmse 5.21777 trained in 34.11 seconds\n",
      "7_Xgboost rmse 5.123908 trained in 5.16 seconds\n",
      "11_CatBoost rmse 5.377812 trained in 17.16 seconds\n",
      "15_RandomForest rmse 5.13658 trained in 17.84 seconds\n",
      "* Step hill_climbing_1 will try to check up to 16 models\n",
      "16_RandomForest rmse 5.11866 trained in 20.67 seconds\n",
      "17_RandomForest rmse 5.09422 trained in 30.7 seconds\n",
      "18_CatBoost rmse 5.107586 trained in 15.26 seconds\n",
      "19_CatBoost rmse 5.112516 trained in 14.45 seconds\n",
      "20_CatBoost rmse 5.115135 trained in 16.23 seconds\n",
      "21_CatBoost rmse 5.134207 trained in 15.05 seconds\n",
      "22_RandomForest rmse 5.116225 trained in 17.64 seconds\n",
      "23_Xgboost rmse 5.123908 trained in 5.41 seconds\n",
      "24_Xgboost rmse 5.123908 trained in 5.33 seconds\n",
      "25_CatBoost rmse 5.118976 trained in 19.94 seconds\n",
      "26_CatBoost rmse 5.119062 trained in 16.39 seconds\n",
      "27_RandomForest rmse 5.144066 trained in 17.33 seconds\n",
      "28_Xgboost rmse 5.223811 trained in 5.38 seconds\n",
      "29_Xgboost rmse 5.228181 trained in 5.31 seconds\n",
      "30_Xgboost rmse 5.369363 trained in 5.26 seconds\n",
      "31_Xgboost rmse 5.417096 trained in 5.43 seconds\n",
      "* Step hill_climbing_2 will try to check up to 10 models\n",
      "32_RandomForest rmse 5.075179 trained in 30.62 seconds\n",
      "33_CatBoost rmse 5.121987 trained in 15.5 seconds\n",
      "34_CatBoost rmse 5.126371 trained in 15.44 seconds\n",
      "35_CatBoost rmse 5.098723 trained in 15.95 seconds\n",
      "36_Xgboost rmse 5.117574 trained in 5.11 seconds\n",
      "37_Xgboost rmse 5.132156 trained in 5.18 seconds\n",
      "38_Xgboost rmse 5.117574 trained in 5.11 seconds\n",
      "39_Xgboost rmse 5.132156 trained in 5.22 seconds\n",
      "40_Xgboost rmse 5.117574 trained in 5.33 seconds\n",
      "41_Xgboost rmse 5.132156 trained in 5.04 seconds\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble rmse 5.04001 trained in 1.01 seconds\n",
      "AutoML fit time: 576.22 seconds\n",
      "AutoML best model: Ensemble\n",
      "R^2 Score: 0.20234312135809418\n",
      "RMSE: 4.905990123748779\n"
     ]
    }
   ],
   "source": [
    "### Office Employment Density, NO Spatial Lag, Birmingham, POI only (18)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_bham_poi\n",
    "target = 'log_office_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_bham[features], all_data_bham[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/office_employment_density_bham_poi/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_18 = r2_score(y_test, predictions)\n",
    "rmse_18 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_18}')\n",
    "print(f'RMSE: {rmse_18}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_18 = automl.predict(all_data_bham[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': bham_geometries,\n",
    "    'observed': all_data_bham[target],\n",
    "    'predicted': predictions_all_18,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcb1705-7a08-4f36-97bc-fe4b06fb175f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abadb44-cad5-4e42-afb1-696b1611f5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: ml_results/employment_london_lag_poi/\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['CatBoost', 'Xgboost', 'Random Forest']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "1_Default_Xgboost rmse 0.677317 trained in 178.57 seconds\n",
      "2_Default_CatBoost rmse 0.667763 trained in 219.62 seconds\n",
      "3_Default_RandomForest rmse 0.705324 trained in 156.94 seconds\n",
      "* Step not_so_random will try to check up to 12 models\n",
      "4_Xgboost rmse 0.682807 trained in 181.02 seconds\n",
      "8_CatBoost rmse 0.669091 trained in 270.9 seconds\n",
      "12_RandomForest rmse 0.708888 trained in 198.86 seconds\n",
      "5_Xgboost rmse 0.684443 trained in 240.9 seconds\n",
      "9_CatBoost rmse 0.682518 trained in 308.91 seconds\n"
     ]
    }
   ],
   "source": [
    "### Employment (log), Spatial Lag, NO building footprints, London (19)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london_lag_poi\n",
    "target = 'log_total_employment'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/employment_london_lag_poi/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_19 = r2_score(y_test, predictions)\n",
    "rmse_19 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_19}')\n",
    "print(f'RMSE: {rmse_19}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_19 = automl.predict(all_data_london[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': london_geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all_19,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14a7257-f1e2-4bf5-a856-8868805a693a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Employment (log), Spatial Lag, NO building footprints, Birmingham (20)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_bham_lag_poi\n",
    "target = 'log_total_employment'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_bham[features], all_data_bham[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/employment_bham_lag_poi/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_20 = r2_score(y_test, predictions)\n",
    "rmse_20 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_20}')\n",
    "print(f'RMSE: {rmse_20}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_20 = automl.predict(all_data_bham[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': bham_geometries,\n",
    "    'observed': all_data_bham[target],\n",
    "    'predicted': predictions_all_20,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "40f2d5e8-ab8d-4d04-9381-8fa39bc509e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: ml_results/employment_density_london_lag_poi/\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['CatBoost', 'Xgboost', 'Random Forest']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "1_Default_Xgboost rmse 0.801042 trained in 234.29 seconds\n",
      "2_Default_CatBoost rmse 0.781642 trained in 248.68 seconds\n",
      "3_Default_RandomForest rmse 0.891102 trained in 124.55 seconds\n",
      "* Step not_so_random will try to check up to 12 models\n",
      "4_Xgboost rmse 0.802904 trained in 196.18 seconds\n",
      "8_CatBoost rmse 0.779447 trained in 289.54 seconds\n",
      "12_RandomForest rmse 0.889156 trained in 154.03 seconds\n",
      "5_Xgboost rmse 0.808586 trained in 231.27 seconds\n",
      "9_CatBoost rmse 0.803207 trained in 262.67 seconds\n",
      "13_RandomForest rmse 0.911861 trained in 144.13 seconds\n",
      "6_Xgboost rmse 0.789101 trained in 205.39 seconds\n",
      "10_CatBoost rmse 0.785207 trained in 248.92 seconds\n",
      "14_RandomForest rmse 0.86432 trained in 231.03 seconds\n",
      "7_Xgboost rmse 0.793159 trained in 154.99 seconds\n",
      "11_CatBoost rmse 0.816749 trained in 234.38 seconds\n",
      "15_RandomForest rmse 0.861774 trained in 179.87 seconds\n",
      "* Step hill_climbing_1 will try to check up to 17 models\n",
      "16_CatBoost rmse 0.776301 trained in 325.54 seconds\n",
      "17_CatBoost rmse 0.780876 trained in 261.27 seconds\n",
      "18_CatBoost rmse 0.778514 trained in 273.98 seconds\n",
      "19_CatBoost rmse 0.789969 trained in 242.36 seconds\n",
      "20_CatBoost rmse 0.776111 trained in 256.97 seconds\n",
      "21_CatBoost rmse 0.793201 trained in 238.89 seconds\n",
      "22_Xgboost rmse 0.788285 trained in 181.63 seconds\n",
      "23_Xgboost rmse 0.791264 trained in 183.19 seconds\n",
      "24_Xgboost rmse 0.793391 trained in 159.69 seconds\n",
      "25_Xgboost rmse 0.7939 trained in 175.99 seconds\n",
      "26_Xgboost rmse 0.797741 trained in 189.56 seconds\n",
      "27_Xgboost rmse 0.806301 trained in 214.47 seconds\n",
      "28_RandomForest rmse 0.861311 trained in 162.26 seconds\n",
      "29_RandomForest rmse 0.863359 trained in 207.87 seconds\n",
      "30_RandomForest rmse 0.865246 trained in 205.64 seconds\n",
      "31_RandomForest rmse 0.888977 trained in 190.38 seconds\n",
      "32_RandomForest rmse 0.88884 trained in 202.02 seconds\n",
      "Skip hill_climbing_2 because of the time limit.\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble rmse 0.766436 trained in 0.69 seconds\n",
      "AutoML fit time: 6829.76 seconds\n",
      "AutoML best model: Ensemble\n",
      "R^2 Score: 0.5666858129850117\n",
      "RMSE: 1.0036391019821167\n"
     ]
    }
   ],
   "source": [
    "### Employment density (log), Spatial Lag, NO building footprints, London (21)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london_lag_poi\n",
    "target = 'log_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/employment_density_london_lag_poi/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_21 = r2_score(y_test, predictions)\n",
    "rmse_21 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_21}')\n",
    "print(f'RMSE: {rmse_21}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_21 = automl.predict(all_data_london[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': london_geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all_21,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "93b64d0d-1da7-4353-9e1d-eec5d2be71f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: ml_results/employment_density_bham_lag_poi/\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['CatBoost', 'Xgboost', 'Random Forest']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "1_Default_Xgboost rmse 1.335387 trained in 16.57 seconds\n",
      "2_Default_CatBoost rmse 1.262813 trained in 55.41 seconds\n",
      "3_Default_RandomForest rmse 1.402475 trained in 46.06 seconds\n",
      "* Step not_so_random will try to check up to 12 models\n",
      "4_Xgboost rmse 1.165377 trained in 34.73 seconds\n",
      "8_CatBoost rmse 1.319645 trained in 100.3 seconds\n",
      "12_RandomForest rmse 1.357303 trained in 76.95 seconds\n",
      "5_Xgboost rmse 1.351206 trained in 1070.59 seconds\n",
      "9_CatBoost rmse 1.247835 trained in 963.75 seconds\n",
      "13_RandomForest rmse 1.385545 trained in 594.24 seconds\n",
      "6_Xgboost rmse 1.214773 trained in 15.63 seconds\n",
      "10_CatBoost rmse 1.269773 trained in 57.99 seconds\n",
      "14_RandomForest rmse 1.345136 trained in 38.48 seconds\n",
      "7_Xgboost rmse 1.383273 trained in 11.81 seconds\n",
      "11_CatBoost rmse 1.233263 trained in 401.05 seconds\n",
      "15_RandomForest rmse 1.364417 trained in 991.38 seconds\n",
      "Skip hill_climbing_1 because of the time limit.\n",
      "Skip hill_climbing_2 because of the time limit.\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble rmse 1.141649 trained in 0.17 seconds\n",
      "AutoML fit time: 4483.03 seconds\n",
      "AutoML best model: Ensemble\n",
      "R^2 Score: 0.41782173622298036\n",
      "RMSE: 0.8085241317749023\n"
     ]
    }
   ],
   "source": [
    "### Employment density (log), Spatial Lag, NO building footprints, Birmingham (22)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_bham_lag_poi\n",
    "target = 'log_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_bham[features], all_data_bham[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/employment_density_bham_lag_poi/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_22 = r2_score(y_test, predictions)\n",
    "rmse_22 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_22}')\n",
    "print(f'RMSE: {rmse_22}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_22 = automl.predict(all_data_bham[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': bham_geometries,\n",
    "    'observed': all_data_bham[target],\n",
    "    'predicted': predictions_all_22,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "85017eb0-6561-4e24-b5be-040f01e41dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: ml_results/office_employment_density_london_lag_poi/\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['CatBoost', 'Xgboost', 'Random Forest']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "1_Default_Xgboost rmse 2.743325 trained in 177.61 seconds\n",
      "2_Default_CatBoost rmse 2.711086 trained in 254.01 seconds\n",
      "3_Default_RandomForest rmse 2.769916 trained in 148.55 seconds\n",
      "* Step not_so_random will try to check up to 12 models\n",
      "4_Xgboost rmse 2.766055 trained in 172.38 seconds\n",
      "8_CatBoost rmse 2.703473 trained in 228.35 seconds\n",
      "12_RandomForest rmse 2.766345 trained in 235.72 seconds\n",
      "5_Xgboost rmse 2.790125 trained in 173.95 seconds\n",
      "9_CatBoost rmse 2.793531 trained in 252.11 seconds\n",
      "13_RandomForest rmse 2.776139 trained in 180.98 seconds\n",
      "6_Xgboost rmse 2.717779 trained in 148.35 seconds\n",
      "10_CatBoost rmse 2.702684 trained in 258.82 seconds\n",
      "14_RandomForest rmse 2.781135 trained in 165.51 seconds\n",
      "7_Xgboost rmse 2.740375 trained in 145.77 seconds\n",
      "11_CatBoost rmse 2.798356 trained in 242.35 seconds\n",
      "15_RandomForest rmse 2.758488 trained in 189.4 seconds\n",
      "* Step hill_climbing_1 will try to check up to 17 models\n",
      "16_CatBoost rmse 2.69544 trained in 263.89 seconds\n",
      "17_CatBoost rmse 2.73322 trained in 234.04 seconds\n",
      "18_CatBoost rmse 2.694704 trained in 257.47 seconds\n",
      "19_CatBoost rmse 2.708441 trained in 247.74 seconds\n",
      "20_CatBoost rmse 2.703493 trained in 246.5 seconds\n",
      "21_CatBoost rmse 2.717704 trained in 229.23 seconds\n",
      "22_Xgboost rmse 2.713668 trained in 168.46 seconds\n",
      "23_Xgboost rmse 2.704843 trained in 157.35 seconds\n",
      "24_Xgboost rmse 2.74959 trained in 295.89 seconds\n",
      "25_Xgboost rmse 2.745301 trained in 386.75 seconds\n",
      "26_Xgboost rmse 2.745508 trained in 1482.18 seconds\n",
      "27_Xgboost rmse 2.767604 trained in 407.3 seconds\n",
      "28_RandomForest rmse 2.757467 trained in 1180.93 seconds\n",
      "29_RandomForest rmse 2.767308 trained in 332.57 seconds\n",
      "30_RandomForest rmse 2.766621 trained in 402.56 seconds\n",
      "31_RandomForest rmse 2.771123 trained in 334.98 seconds\n",
      "32_RandomForest rmse 2.770339 trained in 272.71 seconds\n",
      "Skip hill_climbing_2 because of the time limit.\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble rmse 2.679915 trained in 0.97 seconds\n",
      "AutoML fit time: 9895.78 seconds\n",
      "AutoML best model: Ensemble\n",
      "R^2 Score: 0.29234974927845814\n",
      "RMSE: 2.730419874191284\n"
     ]
    }
   ],
   "source": [
    "### Office Employment Density (log), Spatial Lag, NO building footprints, London (23)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london_lag_poi\n",
    "target = 'log_office_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/office_employment_density_london_lag_poi/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_23 = r2_score(y_test, predictions)\n",
    "rmse_23 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_23}')\n",
    "print(f'RMSE: {rmse_23}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_23 = automl.predict(all_data_london[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': london_geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all_23,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "02f9d2cc-5125-442c-a25c-e1ec7e645a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: ml_results/office_employment_density_bham_lag_poi/\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['CatBoost', 'Xgboost', 'Random Forest']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "1_Default_Xgboost rmse 5.170603 trained in 50.54 seconds\n",
      "2_Default_CatBoost rmse 5.027686 trained in 131.82 seconds\n",
      "3_Default_RandomForest rmse 5.044921 trained in 75.68 seconds\n",
      "* Step not_so_random will try to check up to 12 models\n",
      "4_Xgboost rmse 5.167932 trained in 46.28 seconds\n",
      "8_CatBoost rmse 4.975918 trained in 139.04 seconds\n",
      "12_RandomForest rmse 4.997316 trained in 71.29 seconds\n",
      "5_Xgboost rmse 5.371165 trained in 45.6 seconds\n",
      "9_CatBoost rmse 5.28615 trained in 149.47 seconds\n",
      "13_RandomForest rmse 5.006942 trained in 74.55 seconds\n",
      "6_Xgboost rmse 4.988582 trained in 43.82 seconds\n",
      "10_CatBoost rmse 5.017229 trained in 131.3 seconds\n",
      "14_RandomForest rmse 5.046811 trained in 78.16 seconds\n",
      "7_Xgboost rmse 4.965466 trained in 45.56 seconds\n",
      "11_CatBoost rmse 5.36897 trained in 138.62 seconds\n",
      "15_RandomForest rmse 4.987373 trained in 76.48 seconds\n",
      "* Step hill_climbing_1 will try to check up to 16 models\n",
      "16_Xgboost rmse 4.965466 trained in 41.11 seconds\n",
      "17_Xgboost rmse 4.965466 trained in 42.72 seconds\n",
      "18_CatBoost rmse 5.009706 trained in 157.36 seconds\n",
      "19_CatBoost rmse 5.01521 trained in 139.47 seconds\n",
      "20_RandomForest rmse 4.981016 trained in 75.75 seconds\n",
      "21_Xgboost rmse 4.977734 trained in 48.19 seconds\n",
      "22_Xgboost rmse 4.988006 trained in 43.46 seconds\n",
      "23_RandomForest rmse 4.952248 trained in 63.07 seconds\n",
      "24_RandomForest rmse 4.982026 trained in 70.62 seconds\n",
      "25_RandomForest rmse 4.98544 trained in 77.24 seconds\n",
      "26_CatBoost rmse 5.007575 trained in 1066.25 seconds\n",
      "27_CatBoost rmse 4.990852 trained in 1007.36 seconds\n",
      "28_CatBoost rmse 5.042337 trained in 423.49 seconds\n",
      "29_CatBoost rmse 5.03579 trained in 53.65 seconds\n",
      "30_Xgboost rmse 5.152551 trained in 14.34 seconds\n",
      "31_Xgboost rmse 5.244703 trained in 13.23 seconds\n",
      "Skip hill_climbing_2 because of the time limit.\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble rmse 4.87907 trained in 0.6 seconds\n",
      "AutoML fit time: 4659.52 seconds\n",
      "AutoML best model: Ensemble\n",
      "R^2 Score: 0.22169328138719024\n",
      "RMSE: 4.846118450164795\n"
     ]
    }
   ],
   "source": [
    "### Office Employment Density (log), Spatial Lag, NO building footprints, Birmingham (24)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_bham_lag_poi\n",
    "target = 'log_office_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_bham[features], all_data_bham[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/office_employment_density_bham_lag_poi/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_24 = r2_score(y_test, predictions)\n",
    "rmse_24 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_24}')\n",
    "print(f'RMSE: {rmse_24}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_24 = automl.predict(all_data_bham[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': bham_geometries,\n",
    "    'observed': all_data_bham[target],\n",
    "    'predicted': predictions_all_24,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024e2553-1a43-4da2-ac78-f84b9536d8ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "95b4bac7-1f3e-4b26-9a31-6014e0048a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model has already been fitted. You can use predict methods or select a new 'results_path' for a new 'fit()'.\n",
      "R^2 Score: 0.7102393476371849\n",
      "RMSE: 0.6910015940666199\n"
     ]
    }
   ],
   "source": [
    "### Employment (log), NO Spatial Lag, London,  POI EXCLUSIVE (25)\n",
    "\n",
    "# Ignore depracation warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london_poi = [column for column in feature_columns_london_poi if column != 'log_num_places']\n",
    "target = 'log_total_employment'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/poi_exclusive_london/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_25 = r2_score(y_test, predictions)\n",
    "rmse_25 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_25}')\n",
    "print(f'RMSE: {rmse_25}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_25 = automl.predict(all_data_london[features])\n",
    "\n",
    "results_london_poi = pd.DataFrame({\n",
    "    'name': london_names,\n",
    "    'geometry': london_geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all_25,\n",
    "})\n",
    "\n",
    "# Save to project folder\n",
    "results_london_poi.to_csv(\"data/combined_data/model_results_london_poi.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "37b651d4-c97d-41b2-86ed-5cce34f30be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model has already been fitted. You can use predict methods or select a new 'results_path' for a new 'fit()'.\n",
      "R^2 Score: 0.6226217466175756\n",
      "RMSE: 0.7312378883361816\n"
     ]
    }
   ],
   "source": [
    "### Employment (log), NO Spatial Lag, Birmingham, POI EXCLUSIVE (26)\n",
    "\n",
    "# Ignore depracation warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_bham_poi = [column for column in feature_columns_bham_poi if column != 'log_num_places']\n",
    "target = 'log_total_employment'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_bham[features], all_data_bham[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/poi_exclusive_bham/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_26 = r2_score(y_test, predictions)\n",
    "rmse_26 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_26}')\n",
    "print(f'RMSE: {rmse_26}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_26 = automl.predict(all_data_bham[features])\n",
    "\n",
    "results_bham_poi = pd.DataFrame({\n",
    "    'name': bham_names,\n",
    "    'geometry': bham_geometries,\n",
    "    'observed': all_data_bham[target],\n",
    "    'predicted': predictions_all_26,\n",
    "})\n",
    "\n",
    "# Save to project folder\n",
    "results_bham_poi.to_csv(\"data/combined_data/model_results_bham_poi.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9e4b08-aeb6-45c8-bb64-1d5cce0c8e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Employment Density, NO Spatial Lag, London,  POI EXCLUSIVE (27)\n",
    "\n",
    "# Ignore depracation warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london_poi = [column for column in feature_columns_london_poi if column != 'log_num_places']\n",
    "target = 'log_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/poi_exclusive_london_density/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_27 = r2_score(y_test, predictions)\n",
    "rmse_27 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_27}')\n",
    "print(f'RMSE: {rmse_27}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_27 = automl.predict(all_data_london[features])\n",
    "\n",
    "results_london_poi_density = pd.DataFrame({\n",
    "    'name': london_names,\n",
    "    'geometry': london_geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all_27,\n",
    "})\n",
    "\n",
    "# Save to project folder\n",
    "results_london_poi_density.to_csv(\"data/combined_data/model_results_london_poi_density.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b6d36b-2df9-4a0b-87ae-1873ca72ce4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Employment Density, NO Spatial Lag, Birmingham, POI EXCLUSIVE (28)\n",
    "\n",
    "# Ignore depracation warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_bham_poi = [column for column in feature_columns_bham_poi if column != 'log_num_places']\n",
    "target = 'log_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_bham[features], all_data_bham[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/poi_exclusive_bham_density/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_28 = r2_score(y_test, predictions)\n",
    "rmse_28 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_28}')\n",
    "print(f'RMSE: {rmse_28}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_28 = automl.predict(all_data_bham[features])\n",
    "\n",
    "results_bham_poi_density = pd.DataFrame({\n",
    "    'name': bham_names,\n",
    "    'geometry': bham_geometries,\n",
    "    'observed': all_data_bham[target],\n",
    "    'predicted': predictions_all_28,\n",
    "})\n",
    "\n",
    "# Save to project folder\n",
    "results_bham_poi_density.to_csv(\"data/combined_data/model_results_bham_poi_density.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e4dfa3-da73-4d14-8fc5-b121ae958d42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27713eaa-20a6-4da1-81a1-c5fa18748288",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Office Employment Density, NO Spatial Lag, London, POI EXCLUSIVE (29)\n",
    "\n",
    "# Ignore depracation warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london_poi = [column for column in feature_columns_london_poi if column != 'log_num_places']\n",
    "target = 'log_office_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/poi_exclusive_london_office_density/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_29 = r2_score(y_test, predictions)\n",
    "rmse_29 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_29}')\n",
    "print(f'RMSE: {rmse_29}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_29 = automl.predict(all_data_london[features])\n",
    "\n",
    "results_london_poi_density = pd.DataFrame({\n",
    "    'name': london_names,\n",
    "    'geometry': london_geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all_29,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e10c011-c997-4083-9127-b16785ecdb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Office Employment Density, NO Spatial Lag, Birmingham, POI EXCLUSIVE (30)\n",
    "\n",
    "# Ignore depracation warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_bham_poi = [column for column in feature_columns_bham_poi if column != 'log_num_places']\n",
    "target = 'log_office_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_bham[features], all_data_bham[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/poi_exclusive_bham_density/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_30 = r2_score(y_test, predictions)\n",
    "rmse_30 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_30}')\n",
    "print(f'RMSE: {rmse_30}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_30 = automl.predict(all_data_bham[features])\n",
    "\n",
    "results_bham_poi_density = pd.DataFrame({\n",
    "    'name': bham_names,\n",
    "    'geometry': bham_geometries,\n",
    "    'observed': all_data_bham[target],\n",
    "    'predicted': predictions_all_30,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd967e5-3123-4999-9f46-ab6c3163dcce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8c6f365-e57a-46df-a647-bff37403536c",
   "metadata": {},
   "source": [
    "### Attempt with Demographic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "97be3f20-5d83-4bc7-bb9b-a04f33adc25c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LSOA11CD</th>\n",
       "      <th>LSOA11NM</th>\n",
       "      <th>Index of Multiple Deprivation (IMD) Rank</th>\n",
       "      <th>Index of Multiple Deprivation (IMD) Decile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E01000001</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>29,199</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E01000002</td>\n",
       "      <td>City of London 001B</td>\n",
       "      <td>30,379</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E01000003</td>\n",
       "      <td>City of London 001C</td>\n",
       "      <td>14,915</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E01000005</td>\n",
       "      <td>City of London 001E</td>\n",
       "      <td>8,678</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E01000006</td>\n",
       "      <td>Barking and Dagenham 016A</td>\n",
       "      <td>14,486</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    LSOA11CD                   LSOA11NM  \\\n",
       "0  E01000001        City of London 001A   \n",
       "1  E01000002        City of London 001B   \n",
       "2  E01000003        City of London 001C   \n",
       "3  E01000005        City of London 001E   \n",
       "4  E01000006  Barking and Dagenham 016A   \n",
       "\n",
       "  Index of Multiple Deprivation (IMD) Rank  \\\n",
       "0                                   29,199   \n",
       "1                                   30,379   \n",
       "2                                   14,915   \n",
       "3                                    8,678   \n",
       "4                                   14,486   \n",
       "\n",
       "   Index of Multiple Deprivation (IMD) Decile  \n",
       "0                                           9  \n",
       "1                                          10  \n",
       "2                                           5  \n",
       "3                                           3  \n",
       "4                                           5  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Same Analysis on Education, Employment Status, and Multiple Deprivation Data\n",
    "\n",
    "general_health = pd.read_csv(\"data/lsoa_data/TS037_general_health.csv\", skiprows = 7, header = 0)\n",
    "employment_residential = pd.read_csv(\"data/lsoa_data/TS066_economic_activity_status.csv\", skiprows = 7, header = 0)\n",
    "education = pd.read_csv(\"data/lsoa_data/TS067_highest_qualification.csv\", skiprows = 7, header = 0)\n",
    "household_comp = pd.read_csv(\"data/lsoa_data/TS003_household_composition.csv\", skiprows = 6, header = 0)\n",
    "age_bands = pd.read_csv(\"data/lsoa_data/TS007B_age_broad_band.csv\", skiprows = 4, header = 0)\n",
    "english_lang = pd.read_csv(\"data/lsoa_data/TS029_english_language.csv\", skiprows = 6, header = 0)\n",
    "\n",
    "#Separate name into LSOA11CD and LSOA11NM (taken from DataCleaning.ipynb)\n",
    "def split_column(value):\n",
    "    if isinstance(value, str):\n",
    "        code, name = value.split(' : ')\n",
    "        return code.strip(), name.strip()\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "# Parse Code and Name out\n",
    "general_health[['LSOA11CD', 'LSOA11NM']] = general_health['2021 super output area - lower layer'].apply(lambda x: pd.Series(split_column(x)))\n",
    "employment_residential[['LSOA11CD', 'LSOA11NM']] = employment_residential['2021 super output area - lower layer'].apply(lambda x: pd.Series(split_column(x)))\n",
    "education[['LSOA11CD', 'LSOA11NM']] = education['2021 super output area - lower layer'].apply(lambda x: pd.Series(split_column(x)))\n",
    "household_comp[['LSOA11CD', 'LSOA11NM']] = household_comp['2021 super output area - lower layer'].apply(lambda x: pd.Series(split_column(x)))\n",
    "age_bands[['LSOA11CD', 'LSOA11NM']] = age_bands['2021 super output area - lower layer'].apply(lambda x: pd.Series(split_column(x)))\n",
    "english_lang[['LSOA11CD', 'LSOA11NM']] = english_lang['2021 super output area - lower layer'].apply(lambda x: pd.Series(split_column(x)))\n",
    "\n",
    "# Drop original column\n",
    "general_health = general_health.drop(columns=['2021 super output area - lower layer'])\n",
    "employment_residential = employment_residential.drop(columns=['2021 super output area - lower layer'])\n",
    "education = education.drop(columns=['2021 super output area - lower layer'])\n",
    "household_comp = household_comp.drop(columns=['2021 super output area - lower layer'])\n",
    "age_bands = age_bands.drop(columns=['2021 super output area - lower layer'])\n",
    "english_lang = english_lang.drop(columns=['2021 super output area - lower layer'])\n",
    "\n",
    "\n",
    "multiple_deprivation = pd.read_csv(\"data/lsoa_data/multiple_deprivation.csv\", header = 0)\n",
    "multiple_deprivation.rename(columns = {'LSOA code (2011)':'LSOA11CD', 'LSOA name (2011)':'LSOA11NM'}, inplace=True)\n",
    "multiple_deprivation = multiple_deprivation.drop(columns=[\"Local Authority District code (2019)\", \"Local Authority District name (2019)\"])\n",
    "\n",
    "\n",
    "multiple_deprivation.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "71b41bad-159d-47f7-bac9-3979d29972ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total: All usual residents</th>\n",
       "      <th>Very good health</th>\n",
       "      <th>Good health</th>\n",
       "      <th>Fair health</th>\n",
       "      <th>Bad health</th>\n",
       "      <th>Very bad health</th>\n",
       "      <th>LSOA11CD</th>\n",
       "      <th>LSOA11NM</th>\n",
       "      <th>Total: All usual residents aged 16 years and over</th>\n",
       "      <th>Economically active (excluding full-time students)</th>\n",
       "      <th>...</th>\n",
       "      <th>lag_veterinarian</th>\n",
       "      <th>lag_videographer</th>\n",
       "      <th>lag_vitamins_and_supplements</th>\n",
       "      <th>lag_warehouses</th>\n",
       "      <th>lag_waterproofing</th>\n",
       "      <th>lag_waxing</th>\n",
       "      <th>lag_wholesale_grocer</th>\n",
       "      <th>lag_wildlife_sanctuary</th>\n",
       "      <th>lag_wills_trusts_and_probate</th>\n",
       "      <th>lag_winery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>58.2</td>\n",
       "      <td>31.7</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>100.0</td>\n",
       "      <td>65.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100.0</td>\n",
       "      <td>60.4</td>\n",
       "      <td>30.6</td>\n",
       "      <td>6.7</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>E01000002</td>\n",
       "      <td>City of London 001B</td>\n",
       "      <td>100.0</td>\n",
       "      <td>69.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>36.4</td>\n",
       "      <td>11.5</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>E01000003</td>\n",
       "      <td>City of London 001C</td>\n",
       "      <td>100.0</td>\n",
       "      <td>70.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.0</td>\n",
       "      <td>45.5</td>\n",
       "      <td>35.3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>E01000005</td>\n",
       "      <td>City of London 001E</td>\n",
       "      <td>100.0</td>\n",
       "      <td>55.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100.0</td>\n",
       "      <td>64.6</td>\n",
       "      <td>28.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>E01032739</td>\n",
       "      <td>City of London 001F</td>\n",
       "      <td>100.0</td>\n",
       "      <td>78.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1177 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Total: All usual residents  Very good health  Good health  Fair health  \\\n",
       "0                      100.0              58.2         31.7          8.1   \n",
       "1                      100.0              60.4         30.6          6.7   \n",
       "2                      100.0              49.0         36.4         11.5   \n",
       "3                      100.0              45.5         35.3         12.0   \n",
       "4                      100.0              64.6         28.8          4.9   \n",
       "\n",
       "   Bad health  Very bad health   LSOA11CD             LSOA11NM  \\\n",
       "0         1.2              0.7  E01000001  City of London 001A   \n",
       "1         1.7              0.6  E01000002  City of London 001B   \n",
       "2         2.7              0.4  E01000003  City of London 001C   \n",
       "3         5.7              1.5  E01000005  City of London 001E   \n",
       "4         1.5              0.1  E01032739  City of London 001F   \n",
       "\n",
       "  Total: All usual residents aged 16 years and over  \\\n",
       "0                                             100.0   \n",
       "1                                             100.0   \n",
       "2                                             100.0   \n",
       "3                                             100.0   \n",
       "4                                             100.0   \n",
       "\n",
       "   Economically active (excluding full-time students)  ...  lag_veterinarian  \\\n",
       "0                                               65.7   ...          0.166667   \n",
       "1                                               69.3   ...          0.000000   \n",
       "2                                               70.3   ...          0.166667   \n",
       "3                                               55.8   ...          0.000000   \n",
       "4                                               78.4   ...          0.000000   \n",
       "\n",
       "   lag_videographer  lag_vitamins_and_supplements  lag_warehouses  \\\n",
       "0          0.333333                      0.000000        0.166667   \n",
       "1          0.000000                      0.333333        0.833333   \n",
       "2          0.166667                      0.000000        0.500000   \n",
       "3          0.000000                      0.000000        0.166667   \n",
       "4          0.000000                      0.000000        0.333333   \n",
       "\n",
       "   lag_waterproofing  lag_waxing  lag_wholesale_grocer  \\\n",
       "0                0.0    0.000000                   0.0   \n",
       "1                0.0    0.166667                   0.0   \n",
       "2                0.0    0.000000                   0.0   \n",
       "3                0.0    0.166667                   0.0   \n",
       "4                0.0    0.000000                   0.0   \n",
       "\n",
       "   lag_wildlife_sanctuary  lag_wills_trusts_and_probate  lag_winery  \n",
       "0                     0.0                      0.333333         0.0  \n",
       "1                     0.0                      0.166667         0.5  \n",
       "2                     0.0                      0.000000         0.0  \n",
       "3                     0.0                      0.000000         0.0  \n",
       "4                     0.0                      0.000000         0.5  \n",
       "\n",
       "[5 rows x 1177 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join all data together\n",
    "\n",
    "combined_census = pd.merge(general_health, employment_residential, on='LSOA11CD', suffixes=('', '_drop'))\n",
    "combined_census = pd.merge(combined_census, education, on='LSOA11CD', suffixes=('', '_drop'))\n",
    "combined_census = pd.merge(combined_census, household_comp, on='LSOA11CD', suffixes=('', '_drop'))\n",
    "combined_census = pd.merge(combined_census, age_bands, on='LSOA11CD', suffixes=('', '_drop'))\n",
    "combined_census = pd.merge(combined_census, english_lang, on='LSOA11CD', suffixes=('', '_drop'))\n",
    "combined_census = pd.merge(combined_census, multiple_deprivation, on='LSOA11CD', suffixes=('', '_drop'))\n",
    "\n",
    "# Get column lists\n",
    "combined_census = combined_census[[col for col in combined_census.columns if not col.endswith('_drop')]]\n",
    "combined_census_columns = list(combined_census.columns)\n",
    "exclude_columns = ['LSOA11CD', 'LSOA11NM', 'residual', 'Total: All usual residents', 'Total: All usual residents aged 16 years and over']\n",
    "census_feature_columns = [col for col in combined_census.columns if col not in exclude_columns]\n",
    "\n",
    "# Join with london and birmingham model output data\n",
    "combined_model = all_data_london\n",
    "combined_model = combined_model.drop(columns=['LSOA11NM'])\n",
    "combined_census = combined_census.merge(combined_model, on='LSOA11CD', how='inner')\n",
    "\n",
    "# Fix string rank data\n",
    "combined_census['Index of Multiple Deprivation (IMD) Rank'] = combined_census['Index of Multiple Deprivation (IMD) Rank'].str.replace(',', '')\n",
    "combined_census['Index of Multiple Deprivation (IMD) Rank']  = pd.to_numeric(combined_census['Index of Multiple Deprivation (IMD) Rank'] )   \n",
    "\n",
    "combined_census.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b0fb9ba4-5b58-4997-bb49-a45bd19d8f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model has already been fitted. You can use predict methods or select a new 'results_path' for a new 'fit()'.\n",
      "R^2 Score: 0.7474297689503127\n",
      "RMSE: 0.6102148294448853\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "array length 4659 does not match index length 4835",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[130], line 53\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m#Save results for plotting\u001b[39;00m\n\u001b[1;32m     51\u001b[0m predictions_all_23 \u001b[38;5;241m=\u001b[39m automl\u001b[38;5;241m.\u001b[39mpredict(combined_census[features])\n\u001b[0;32m---> 53\u001b[0m results_london_demographic \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlondon_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgeometry\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlondon_geometries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mobserved\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcombined_census\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpredicted\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions_all_23\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Save to project folder\u001b[39;00m\n\u001b[1;32m     61\u001b[0m results_london_demographic\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/combined_data/model_results_london_demographic.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/urbsim/lib/python3.11/site-packages/pandas/core/frame.py:733\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    727\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    728\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    729\u001b[0m     )\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 733\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[0;32m~/anaconda3/envs/urbsim/lib/python3.11/site-packages/pandas/core/internals/construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/urbsim/lib/python3.11/site-packages/pandas/core/internals/construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m~/anaconda3/envs/urbsim/lib/python3.11/site-packages/pandas/core/internals/construction.py:690\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lengths[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[1;32m    686\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    687\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray length \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlengths[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not match index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    688\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlength \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    689\u001b[0m         )\n\u001b[0;32m--> 690\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    692\u001b[0m     index \u001b[38;5;241m=\u001b[39m default_index(lengths[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[0;31mValueError\u001b[0m: array length 4659 does not match index length 4835"
     ]
    }
   ],
   "source": [
    "### Employment (log), NO Spatial Lag, London, Demographic Data\n",
    "\n",
    "# Ignore depracation warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london + census_feature_columns\n",
    "target = 'log_total_employment'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_census[features], combined_census[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/london_employment_demographic/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_23 = r2_score(y_test, predictions)\n",
    "rmse_23 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_23}')\n",
    "print(f'RMSE: {rmse_23}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_23 = automl.predict(combined_census[features])\n",
    "\n",
    "results_london_demographic = pd.DataFrame({\n",
    "    'name': london_names,\n",
    "    'geometry': london_geometries,\n",
    "    'observed': combined_census[target],\n",
    "    'predicted': predictions_all_23,\n",
    "})\n",
    "\n",
    "# Save to project folder\n",
    "results_london_demographic.to_csv(\"data/combined_data/model_results_london_demographic.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "urbsim",
   "language": "python",
   "name": "urbsim"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
