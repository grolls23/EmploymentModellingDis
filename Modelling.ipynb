{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7542fb7-3702-466a-8c2d-837e1e6d4ed3",
   "metadata": {},
   "source": [
    "# Modelling\n",
    "\n",
    "This is the script where I store all my ML model runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d305a93-526f-4ed4-993f-96d593fc9618",
   "metadata": {},
   "source": [
    "## Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b90b1626-165f-4b79-8d67-7b3afa023602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library Imports\n",
    "\n",
    "#Basics\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "#Shapely / Spatial\n",
    "from shapely import wkt\n",
    "import shapely.geometry\n",
    "from shapely.geometry import Polygon, MultiPolygon\n",
    "\n",
    "#Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#ML from mljar-supervised\n",
    "from supervised.automl import AutoML\n",
    "\n",
    "#Warning Supression\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31ea067-af33-4415-b9e7-4d3426573f62",
   "metadata": {},
   "source": [
    "### Import Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53f05a2a-040b-45cd-8108-192d695dea50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>LSOA11CD</th>\n",
       "      <th>LSOA11NM_x</th>\n",
       "      <th>LSOA11NM_y</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>population</th>\n",
       "      <th>Area</th>\n",
       "      <th>01 : Crop and animal production, hunting and related service activities</th>\n",
       "      <th>02 : Forestry and logging</th>\n",
       "      <th>03 : Fishing and aquaculture</th>\n",
       "      <th>...</th>\n",
       "      <th>lag_travel</th>\n",
       "      <th>lag_travel_agents</th>\n",
       "      <th>lag_trusts</th>\n",
       "      <th>lag_university_housing</th>\n",
       "      <th>lag_used_vintage_and_consignment</th>\n",
       "      <th>lag_veterinarian</th>\n",
       "      <th>lag_videographer</th>\n",
       "      <th>lag_vitamins_and_supplements</th>\n",
       "      <th>lag_warehouses</th>\n",
       "      <th>lag_window_washing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>E01008881</td>\n",
       "      <td>Birmingham 067A</td>\n",
       "      <td>Birmingham 067A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1599</td>\n",
       "      <td>lsoa2011:E01008881 : Birmingham 067A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>E01008882</td>\n",
       "      <td>Birmingham 066A</td>\n",
       "      <td>Birmingham 066A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1747</td>\n",
       "      <td>lsoa2011:E01008882 : Birmingham 066A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>E01008883</td>\n",
       "      <td>Birmingham 078A</td>\n",
       "      <td>Birmingham 078A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1816</td>\n",
       "      <td>lsoa2011:E01008883 : Birmingham 078A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>E01008884</td>\n",
       "      <td>Birmingham 078B</td>\n",
       "      <td>Birmingham 078B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1870</td>\n",
       "      <td>lsoa2011:E01008884 : Birmingham 078B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>E01008885</td>\n",
       "      <td>Birmingham 076A</td>\n",
       "      <td>Birmingham 076A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1308</td>\n",
       "      <td>lsoa2011:E01008885 : Birmingham 076A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>634</td>\n",
       "      <td>E01033646</td>\n",
       "      <td>Birmingham 031I</td>\n",
       "      <td>Birmingham 031I</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1624</td>\n",
       "      <td>lsoa2011:E01033646 : Birmingham 031I</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>635</td>\n",
       "      <td>E01033647</td>\n",
       "      <td>Birmingham 058E</td>\n",
       "      <td>Birmingham 058E</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1398</td>\n",
       "      <td>lsoa2011:E01033647 : Birmingham 058E</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>636</td>\n",
       "      <td>E01033648</td>\n",
       "      <td>Birmingham 084F</td>\n",
       "      <td>Birmingham 084F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2715</td>\n",
       "      <td>lsoa2011:E01033648 : Birmingham 084F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>637</td>\n",
       "      <td>E01033649</td>\n",
       "      <td>Birmingham 058F</td>\n",
       "      <td>Birmingham 058F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1801</td>\n",
       "      <td>lsoa2011:E01033649 : Birmingham 058F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>638</td>\n",
       "      <td>E01033650</td>\n",
       "      <td>Birmingham 077F</td>\n",
       "      <td>Birmingham 077F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2596</td>\n",
       "      <td>lsoa2011:E01033650 : Birmingham 077F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>639 rows × 742 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0   LSOA11CD       LSOA11NM_x       LSOA11NM_y  Unnamed: 2  \\\n",
       "0             0  E01008881  Birmingham 067A  Birmingham 067A         0.0   \n",
       "1             1  E01008882  Birmingham 066A  Birmingham 066A         0.0   \n",
       "2             2  E01008883  Birmingham 078A  Birmingham 078A         0.0   \n",
       "3             3  E01008884  Birmingham 078B  Birmingham 078B         0.0   \n",
       "4             4  E01008885  Birmingham 076A  Birmingham 076A         0.0   \n",
       "..          ...        ...              ...              ...         ...   \n",
       "634         634  E01033646  Birmingham 031I  Birmingham 031I         0.0   \n",
       "635         635  E01033647  Birmingham 058E  Birmingham 058E         0.0   \n",
       "636         636  E01033648  Birmingham 084F  Birmingham 084F         0.0   \n",
       "637         637  E01033649  Birmingham 058F  Birmingham 058F         0.0   \n",
       "638         638  E01033650  Birmingham 077F  Birmingham 077F         0.0   \n",
       "\n",
       "     population                                  Area  \\\n",
       "0          1599  lsoa2011:E01008881 : Birmingham 067A   \n",
       "1          1747  lsoa2011:E01008882 : Birmingham 066A   \n",
       "2          1816  lsoa2011:E01008883 : Birmingham 078A   \n",
       "3          1870  lsoa2011:E01008884 : Birmingham 078B   \n",
       "4          1308  lsoa2011:E01008885 : Birmingham 076A   \n",
       "..          ...                                   ...   \n",
       "634        1624  lsoa2011:E01033646 : Birmingham 031I   \n",
       "635        1398  lsoa2011:E01033647 : Birmingham 058E   \n",
       "636        2715  lsoa2011:E01033648 : Birmingham 084F   \n",
       "637        1801  lsoa2011:E01033649 : Birmingham 058F   \n",
       "638        2596  lsoa2011:E01033650 : Birmingham 077F   \n",
       "\n",
       "     01 : Crop and animal production, hunting and related service activities  \\\n",
       "0                                                  0.0                         \n",
       "1                                                  0.0                         \n",
       "2                                                  0.0                         \n",
       "3                                                  0.0                         \n",
       "4                                                  0.0                         \n",
       "..                                                 ...                         \n",
       "634                                                0.0                         \n",
       "635                                                0.0                         \n",
       "636                                                0.0                         \n",
       "637                                                0.0                         \n",
       "638                                                0.0                         \n",
       "\n",
       "     02 : Forestry and logging  03 : Fishing and aquaculture  ...  lag_travel  \\\n",
       "0                          0.0                           0.0  ...    0.000000   \n",
       "1                          0.0                           0.0  ...    0.166667   \n",
       "2                          0.0                           0.0  ...    0.166667   \n",
       "3                          0.0                           0.0  ...    0.333333   \n",
       "4                          0.0                           0.0  ...    0.000000   \n",
       "..                         ...                           ...  ...         ...   \n",
       "634                        0.0                           0.0  ...    0.166667   \n",
       "635                        0.0                           0.0  ...    0.166667   \n",
       "636                        0.0                           0.0  ...    0.000000   \n",
       "637                        0.0                           0.0  ...    0.333333   \n",
       "638                        0.0                           0.0  ...    0.000000   \n",
       "\n",
       "     lag_travel_agents  lag_trusts  lag_university_housing  \\\n",
       "0             0.166667         0.0                     0.0   \n",
       "1             0.000000         0.0                     0.0   \n",
       "2             0.000000         0.0                     0.0   \n",
       "3             0.000000         0.0                     0.0   \n",
       "4             0.166667         0.0                     0.0   \n",
       "..                 ...         ...                     ...   \n",
       "634           0.000000         0.0                     0.0   \n",
       "635           0.000000         0.0                     0.0   \n",
       "636           0.000000         0.0                     0.0   \n",
       "637           0.000000         0.0                     0.0   \n",
       "638           0.000000         0.0                     0.0   \n",
       "\n",
       "     lag_used_vintage_and_consignment  lag_veterinarian  lag_videographer  \\\n",
       "0                                 0.0               0.0               0.0   \n",
       "1                                 0.0               0.0               0.0   \n",
       "2                                 0.0               0.0               0.0   \n",
       "3                                 0.0               0.0               0.0   \n",
       "4                                 0.0               0.0               0.0   \n",
       "..                                ...               ...               ...   \n",
       "634                               0.0               0.0               0.0   \n",
       "635                               0.0               0.0               0.0   \n",
       "636                               0.0               0.0               0.0   \n",
       "637                               0.0               0.0               0.0   \n",
       "638                               0.0               0.0               0.0   \n",
       "\n",
       "     lag_vitamins_and_supplements  lag_warehouses  lag_window_washing  \n",
       "0                        0.000000        0.333333                 0.0  \n",
       "1                        0.000000        0.500000                 0.0  \n",
       "2                        0.000000        0.000000                 0.0  \n",
       "3                        0.166667        0.500000                 0.0  \n",
       "4                        0.000000        0.000000                 0.0  \n",
       "..                            ...             ...                 ...  \n",
       "634                      0.166667        0.000000                 0.0  \n",
       "635                      0.000000        0.000000                 0.0  \n",
       "636                      0.000000        0.000000                 0.0  \n",
       "637                      0.166667        0.000000                 0.0  \n",
       "638                      0.000000        0.000000                 0.0  \n",
       "\n",
       "[639 rows x 742 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read London CSV\n",
    "all_data_london = pd.read_csv(\"data/combined_data/lag/all_data_london_lag.csv\")\n",
    "\n",
    "# Read in feature column set\n",
    "with open(\"data/combined_data/total_feature_columns_london.csv\", 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Reconstruct\n",
    "feature_columns_london_lag = [''.join(line.strip().split(',')) for line in lines]\n",
    "\n",
    "# Create non-laged column set\n",
    "feature_columns_london = [col for col in feature_columns_london_lag if not col.startswith('lag_')]\n",
    "\n",
    "# ---\n",
    "\n",
    "# Read Birmingham CSV\n",
    "all_data_bham = pd.read_csv(\"data/combined_data/lag/all_data_bham_lag.csv\")\n",
    "\n",
    "# Read in feature column set\n",
    "with open(\"data/combined_data/total_feature_columns_bham.csv\", 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Reconstruct\n",
    "feature_columns_bham_lag = [''.join(line.strip().split(',')) for line in lines]\n",
    "\n",
    "# Create non-lagged column set\n",
    "feature_columns_bham = [col for col in feature_columns_bham_lag if not col.startswith('lag_')]\n",
    "\n",
    "# Fix null values ending up in logged variables\n",
    "all_data_london.fillna(0)\n",
    "all_data_bham.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "581a5ad1-f57d-4764-b71b-568a4e4f8c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Lag (but no building cols) feature spaces\n",
    "\n",
    "# List all building footprint related columns here\n",
    "columns_to_remove = ['num_buildings','num_retail_buildings','num_residential_buildings','num_office_buildings','num_commercial_buildings',\n",
    "                    'log_num_buildings','all_avg_building_area','all_lsoa_area_ratio','all_total_area',\n",
    "                     'retail_avg_building_area','retail_lsoa_area_ratio','retail_total_area',\n",
    "                     'residential_avg_building_area','residential_lsoa_area_ratio','residential_total_area',\n",
    "                     'commercial_avg_building_area','commercial_lsoa_area_ratio','commercial_total_area',\n",
    "                     'office_avg_building_area','office_lsoa_area_ratio','office_total_area',\n",
    "                     'lag_num_retail_buildings','lag_num_residential_buildings','lag_num_office_buildings','lag_num_commercial_buildings',\n",
    "                    'lag_log_num_buildings','lag_all_avg_building_area','lag_all_lsoa_area_ratio','lag_all_total_area',\n",
    "                     'lag_retail_avg_building_area','lag_retail_lsoa_area_ratio','lag_retail_total_area',\n",
    "                     'lag_residential_avg_building_area','lag_residential_lsoa_area_ratio','lag_residential_total_area',\n",
    "                     'lag_commercial_avg_building_area','lag_commercial_lsoa_area_ratio','lag_commercial_total_area',\n",
    "                     'lag_office_avg_building_area','lag_office_lsoa_area_ratio','lag_office_total_area',\n",
    "                    ]\n",
    "\n",
    "feature_columns_london_lag_poi = [col for col in feature_columns_london_lag if col not in columns_to_remove]\n",
    "\n",
    "feature_columns_bham_lag_poi = [col for col in feature_columns_bham_lag if col not in columns_to_remove]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa391bf0-c409-43af-811e-771e35bff90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download POI & auxillary-only feature spaces (No building footprint information)\n",
    "\n",
    "# London\n",
    "# Read in POI feature column set\n",
    "with open(\"data/combined_data/feature_columns_london_poi.csv\", 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Reconstruct\n",
    "feature_columns_london_poi = [''.join(line.strip().split(',')) for line in lines]\n",
    "\n",
    "# Birmingham\n",
    "# Read in POI feature column set\n",
    "with open(\"data/combined_data/feature_columns_bham_poi.csv\", 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Reconstruct\n",
    "feature_columns_bham_poi = [''.join(line.strip().split(',')) for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bb1bf237-cbfa-4ce2-9745-768d454fb859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get log of density columns\n",
    "\n",
    "\n",
    "min_non_zero_london_employment_density = all_data_london['employment_density'].loc[all_data_london['employment_density'] > 0].min()\n",
    "min_non_zero_london_office_employment_density = all_data_london['office_employment_density'].loc[all_data_london['office_employment_density'] > 0].min()\n",
    "\n",
    "epsilon_london_employment_density = min_non_zero_london_employment_density / 10\n",
    "epsilon_london_office_employment_density = min_non_zero_london_office_employment_density / 10\n",
    "\n",
    "all_data_london['log_employment_density'] = np.log(all_data_london['employment_density'].replace(0, epsilon_london_employment_density))\n",
    "all_data_london['log_office_employment_density'] = np.log(all_data_london['office_employment_density'].replace(0, epsilon_london_office_employment_density))\n",
    "\n",
    "# Birmingham\n",
    "min_non_zero_bham_employment_density = all_data_bham['employment_density'].loc[all_data_bham['employment_density'] > 0].min()\n",
    "min_non_zero_bham_office_employment_density = all_data_bham['office_employment_density'].loc[all_data_bham['office_employment_density'] > 0].min()\n",
    "\n",
    "epsilon_bham_employment_density = min_non_zero_bham_employment_density / 10\n",
    "epsilon_bham_office_employment_density = min_non_zero_bham_office_employment_density / 10\n",
    "\n",
    "all_data_bham['log_employment_density'] = np.log(all_data_bham['employment_density'].replace(0, epsilon_bham_employment_density))\n",
    "all_data_bham['log_office_employment_density'] = np.log(all_data_bham['office_employment_density'].replace(0, epsilon_bham_office_employment_density))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1476d20c-344b-422d-8b04-e6b747f1d5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Geometries and Names\n",
    "\n",
    "london_geometries = all_data_london['geometry']\n",
    "bham_geometries = all_data_bham['geometry']\n",
    "\n",
    "london_names = all_data_london['LSOA11CD']\n",
    "bham_names = all_data_bham['LSOA11CD']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5488444a-67fc-4aca-8e79-065018e090cb",
   "metadata": {},
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e93f99a8-c74f-4436-8877-6d11cc2f3103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model has already been fitted. You can use predict methods or select a new 'results_path' for a new 'fit()'.\n",
      "R^2 Score: 0.7207009026018532\n",
      "RMSE: 0.678412914276123\n"
     ]
    }
   ],
   "source": [
    "# Ignore depracation warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london_lag\n",
    "target = 'log_total_employment'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(results_path=\"ml_results/dummy_models/test\", mode='Explain')\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_log_employment = r2_score(y_test, predictions)\n",
    "rmse_log_employment = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_log_employment}')\n",
    "print(f'RMSE: {rmse_log_employment}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all = automl.predict(all_data_london[features])\n",
    "\n",
    "results_test = pd.DataFrame({\n",
    "    'geometry': london_geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca014449-6c4c-46d6-ba87-a578cbb9881d",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ce02ced4-41b4-46d0-89da-b9900f64442d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: ml_results/log_employment_london/\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['CatBoost', 'Xgboost', 'Random Forest']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "1_Default_Xgboost rmse 0.638237 trained in 44.72 seconds\n",
      "2_Default_CatBoost rmse 0.624872 trained in 39.45 seconds\n",
      "3_Default_RandomForest rmse 0.692124 trained in 1092.47 seconds\n",
      "* Step not_so_random will try to check up to 12 models\n",
      "4_Xgboost rmse 0.647595 trained in 31.74 seconds\n",
      "8_CatBoost rmse 0.62888 trained in 57.43 seconds\n",
      "12_RandomForest rmse 0.689969 trained in 42.49 seconds\n",
      "5_Xgboost rmse 0.646129 trained in 955.1 seconds\n",
      "9_CatBoost rmse 0.640378 trained in 954.04 seconds\n",
      "13_RandomForest rmse 0.713245 trained in 57.77 seconds\n",
      "6_Xgboost rmse 0.631339 trained in 29.05 seconds\n",
      "10_CatBoost rmse 0.627944 trained in 359.69 seconds\n",
      "14_RandomForest rmse 0.677261 trained in 62.38 seconds\n",
      "7_Xgboost rmse 0.635899 trained in 27.49 seconds\n",
      "11_CatBoost rmse 0.65143 trained in 42.03 seconds\n",
      "15_RandomForest rmse 0.67456 trained in 313.99 seconds\n",
      "Skip hill_climbing_1 because of the time limit.\n",
      "Skip hill_climbing_2 because of the time limit.\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble rmse 0.617282 trained in 0.17 seconds\n",
      "AutoML fit time: 4117.39 seconds\n",
      "AutoML best model: Ensemble\n",
      "R^2 Score: 0.7578170639491384\n",
      "RMSE: 0.6317294239997864\n"
     ]
    }
   ],
   "source": [
    "### Employment (log), NO Spatial Lag, London (1)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london\n",
    "target = 'log_total_employment'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/log_employment_london/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_1 = r2_score(y_test, predictions)\n",
    "rmse_1 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_1}')\n",
    "print(f'RMSE: {rmse_1}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_1 = automl.predict(all_data_london[features])\n",
    "london_geometries = all_data_london.loc[all_data_london[target].index, 'geometry']\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': london_geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all_1,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ac80575c-2245-4464-abdd-a8997967e727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: ml_results/log_employment_bham/\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['CatBoost', 'Xgboost', 'Random Forest']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "1_Default_Xgboost rmse 0.803686 trained in 5.65 seconds\n",
      "2_Default_CatBoost rmse 0.783334 trained in 18.54 seconds\n",
      "3_Default_RandomForest rmse 0.821087 trained in 24.78 seconds\n",
      "* Step not_so_random will try to check up to 12 models\n",
      "4_Xgboost rmse 0.807126 trained in 5.22 seconds\n",
      "8_CatBoost rmse 0.810248 trained in 22.31 seconds\n",
      "12_RandomForest rmse 0.816138 trained in 57.95 seconds\n",
      "5_Xgboost rmse 0.808929 trained in 5.8 seconds\n",
      "9_CatBoost rmse 0.830576 trained in 20.01 seconds\n",
      "13_RandomForest rmse 0.848962 trained in 56.66 seconds\n",
      "6_Xgboost rmse 0.791632 trained in 4.91 seconds\n",
      "10_CatBoost rmse 0.811724 trained in 19.82 seconds\n",
      "14_RandomForest rmse 0.817142 trained in 24.16 seconds\n",
      "7_Xgboost rmse 0.861031 trained in 4.85 seconds\n",
      "11_CatBoost rmse 0.854616 trained in 19.84 seconds\n",
      "15_RandomForest rmse 0.824156 trained in 65.1 seconds\n",
      "* Step hill_climbing_1 will try to check up to 18 models\n",
      "16_CatBoost rmse 0.795161 trained in 19.39 seconds\n",
      "17_CatBoost rmse 0.799599 trained in 18.81 seconds\n",
      "18_Xgboost rmse 0.792724 trained in 5.24 seconds\n",
      "19_Xgboost rmse 0.798389 trained in 5.27 seconds\n",
      "20_Xgboost rmse 0.801649 trained in 5.36 seconds\n",
      "21_Xgboost rmse 0.801951 trained in 5.54 seconds\n",
      "22_Xgboost rmse 0.797301 trained in 5.28 seconds\n",
      "23_Xgboost rmse 0.81387 trained in 5.55 seconds\n",
      "24_CatBoost rmse 0.809749 trained in 47.23 seconds\n",
      "25_CatBoost rmse 0.819835 trained in 20.94 seconds\n",
      "26_CatBoost rmse 0.801445 trained in 21.29 seconds\n",
      "27_CatBoost rmse 0.825881 trained in 19.57 seconds\n",
      "28_RandomForest rmse 0.812049 trained in 55.3 seconds\n",
      "29_RandomForest rmse 0.820499 trained in 26.16 seconds\n",
      "30_RandomForest rmse 0.809917 trained in 25.73 seconds\n",
      "31_RandomForest rmse 0.829734 trained in 24.04 seconds\n",
      "32_RandomForest rmse 0.816113 trained in 56.83 seconds\n",
      "33_RandomForest rmse 0.820707 trained in 24.05 seconds\n",
      "* Step hill_climbing_2 will try to check up to 10 models\n",
      "34_Xgboost rmse 0.797041 trained in 5.24 seconds\n",
      "35_Xgboost rmse 0.798353 trained in 5.45 seconds\n",
      "36_Xgboost rmse 0.798988 trained in 6.04 seconds\n",
      "37_Xgboost rmse 0.798183 trained in 5.87 seconds\n",
      "38_CatBoost rmse 0.792413 trained in 22.1 seconds\n",
      "39_Xgboost rmse 0.801037 trained in 6.73 seconds\n",
      "40_RandomForest rmse 0.805922 trained in 956.12 seconds\n",
      "41_RandomForest rmse 0.80454 trained in 29.39 seconds\n",
      "42_RandomForest rmse 0.813594 trained in 23.26 seconds\n",
      "43_RandomForest rmse 0.813903 trained in 994.4 seconds\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble rmse 0.767987 trained in 1.08 seconds\n",
      "AutoML fit time: 2821.1 seconds\n",
      "AutoML best model: Ensemble\n",
      "R^2 Score: 0.63966144185158\n",
      "RMSE: 0.7145385146141052\n"
     ]
    }
   ],
   "source": [
    "### Employment (log), NO Spatial Lag, Birmingham (2)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_bham\n",
    "target = 'log_total_employment'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_bham[features], all_data_bham[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/log_employment_bham/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_2 = r2_score(y_test, predictions)\n",
    "rmse_2 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_2}')\n",
    "print(f'RMSE: {rmse_2}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_2 = automl.predict(all_data_bham[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': bham_geometries,\n",
    "    'observed': all_data_bham[target],\n",
    "    'predicted': predictions_all_2,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cbef0bf3-04a1-489c-ae7b-5552895992bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: ml_results/log_employment_london_lag/\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['CatBoost', 'Xgboost', 'Random Forest']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "1_Default_Xgboost rmse 0.638593 trained in 1086.36 seconds\n",
      "2_Default_CatBoost rmse 0.63385 trained in 2029.01 seconds\n",
      "3_Default_RandomForest rmse 0.693922 trained in 2068.46 seconds\n",
      "Skip not_so_random because of the time limit.\n",
      "Skip hill_climbing_1 because of the time limit.\n",
      "Skip hill_climbing_2 because of the time limit.\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble rmse 0.627695 trained in 0.05 seconds\n",
      "AutoML fit time: 5186.08 seconds\n",
      "AutoML best model: Ensemble\n",
      "R^2 Score: 0.7547717661754779\n",
      "RMSE: 0.635688841342926\n"
     ]
    }
   ],
   "source": [
    "### Employment (log), Spatial Lag, London (3)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london_lag\n",
    "target = 'log_total_employment'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/log_employment_london_lag/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_3 = r2_score(y_test, predictions)\n",
    "rmse_3 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_3}')\n",
    "print(f'RMSE: {rmse_3}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_3 = automl.predict(all_data_london[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': london_geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all_3,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c5e16db-a923-45df-96fe-aa63e186fa14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gavinrolls/anaconda3/envs/urbsim/lib/python3.11/site-packages/supervised/preprocessing/exclude_missing_target.py:25: UserWarning: There are samples with missing target values in the data which will be excluded for further analysis\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model has already been fitted. You can use predict methods or select a new 'results_path' for a new 'fit()'.\n",
      "R^2 Score: 0.6180309508339799\n",
      "RMSE: 0.7356722354888916\n"
     ]
    }
   ],
   "source": [
    "### Employment (log), Spatial Lag, Birmingham (4)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_bham_lag\n",
    "target = 'log_total_employment'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_bham[features], all_data_bham[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/log_employment_bham_lag/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_4 = r2_score(y_test, predictions)\n",
    "rmse_4 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_4}')\n",
    "print(f'RMSE: {rmse_4}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_4 = automl.predict(all_data_bham[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': bham_geometries,\n",
    "    'observed': all_data_bham[target],\n",
    "    'predicted': predictions_all_4,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8e39466b-44a3-4721-b6c1-4ad1484b0f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: ml_results/employment_density_london/\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['CatBoost', 'Xgboost', 'Random Forest']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "1_Default_Xgboost rmse 0.655372 trained in 43.07 seconds\n",
      "2_Default_CatBoost rmse 0.638601 trained in 48.46 seconds\n",
      "3_Default_RandomForest rmse 0.759565 trained in 46.67 seconds\n",
      "* Step not_so_random will try to check up to 12 models\n",
      "4_Xgboost rmse 0.667123 trained in 41.61 seconds\n",
      "8_CatBoost rmse 0.637648 trained in 82.03 seconds\n",
      "12_RandomForest rmse 0.770158 trained in 87.74 seconds\n",
      "5_Xgboost rmse 0.671828 trained in 40.95 seconds\n",
      "9_CatBoost rmse 0.666059 trained in 54.78 seconds\n",
      "13_RandomForest rmse 0.799913 trained in 52.36 seconds\n",
      "6_Xgboost rmse 0.647797 trained in 36.55 seconds\n",
      "10_CatBoost rmse 0.641248 trained in 51.52 seconds\n",
      "14_RandomForest rmse 0.710489 trained in 56.34 seconds\n",
      "7_Xgboost rmse 0.66084 trained in 36.58 seconds\n",
      "11_CatBoost rmse 0.675462 trained in 55.11 seconds\n",
      "15_RandomForest rmse 0.722536 trained in 54.85 seconds\n",
      "* Step hill_climbing_1 will try to check up to 17 models\n",
      "16_CatBoost rmse 0.637003 trained in 89.21 seconds\n",
      "17_CatBoost rmse 0.642001 trained in 59.33 seconds\n",
      "18_CatBoost rmse 0.637302 trained in 58.12 seconds\n",
      "19_CatBoost rmse 0.64519 trained in 111.24 seconds\n",
      "20_CatBoost rmse 0.636417 trained in 73.15 seconds\n",
      "21_CatBoost rmse 0.646779 trained in 48.48 seconds\n",
      "22_Xgboost rmse 0.649137 trained in 38.42 seconds\n",
      "23_Xgboost rmse 0.652818 trained in 39.7 seconds\n",
      "24_Xgboost rmse 0.656074 trained in 42.09 seconds\n",
      "25_Xgboost rmse 0.6628 trained in 42.33 seconds\n",
      "26_Xgboost rmse 0.656254 trained in 39.96 seconds\n",
      "27_Xgboost rmse 0.664849 trained in 40.81 seconds\n",
      "28_RandomForest rmse 0.708202 trained in 70.21 seconds\n",
      "29_RandomForest rmse 0.711977 trained in 73.08 seconds\n",
      "30_RandomForest rmse 0.720728 trained in 72.93 seconds\n",
      "31_RandomForest rmse 0.759221 trained in 50.81 seconds\n",
      "32_RandomForest rmse 0.759991 trained in 51.4 seconds\n",
      "* Step hill_climbing_2 will try to check up to 11 models\n",
      "33_CatBoost rmse 0.637732 trained in 89.36 seconds\n",
      "34_CatBoost rmse 0.639156 trained in 103.23 seconds\n",
      "35_CatBoost rmse 0.638404 trained in 108.95 seconds\n",
      "36_CatBoost rmse 0.636576 trained in 74.29 seconds\n",
      "37_Xgboost rmse 0.649813 trained in 52.35 seconds\n",
      "38_Xgboost rmse 0.650696 trained in 51.68 seconds\n",
      "39_Xgboost rmse 0.648812 trained in 50.83 seconds\n",
      "40_Xgboost rmse 0.653762 trained in 44.75 seconds\n",
      "41_Xgboost rmse 0.652877 trained in 55.88 seconds\n",
      "42_Xgboost rmse 0.652841 trained in 58.15 seconds\n",
      "43_RandomForest rmse 0.706553 trained in 100.59 seconds\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble rmse 0.63019 trained in 1.26 seconds\n",
      "AutoML fit time: 2603.91 seconds\n",
      "AutoML best model: Ensemble\n",
      "R^2 Score: 0.7560692195505975\n",
      "RMSE: 0.6752620339393616\n"
     ]
    }
   ],
   "source": [
    "### Employment Density, NO Spatial Lag, London (5)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london\n",
    "target = 'log_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/employment_density_london/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_5 = r2_score(y_test, predictions)\n",
    "rmse_5 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_5}')\n",
    "print(f'RMSE: {rmse_5}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_5 = automl.predict(all_data_london[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': london_geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all_5,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1faae03a-3177-4923-a949-53cae255a64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: ml_results/employment_density_bham/\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['CatBoost', 'Xgboost', 'Random Forest']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "1_Default_Xgboost rmse 0.944998 trained in 6.53 seconds\n",
      "2_Default_CatBoost rmse 0.898496 trained in 19.96 seconds\n",
      "3_Default_RandomForest rmse 0.910195 trained in 20.69 seconds\n",
      "* Step not_so_random will try to check up to 12 models\n",
      "4_Xgboost rmse 0.92632 trained in 6.46 seconds\n",
      "8_CatBoost rmse 0.919499 trained in 25.68 seconds\n",
      "12_RandomForest rmse 0.917293 trained in 22.01 seconds\n",
      "5_Xgboost rmse 0.968809 trained in 7.21 seconds\n",
      "9_CatBoost rmse 0.918586 trained in 29.07 seconds\n",
      "13_RandomForest rmse 0.92085 trained in 21.78 seconds\n",
      "6_Xgboost rmse 0.899809 trained in 4.93 seconds\n",
      "10_CatBoost rmse 0.903162 trained in 15.81 seconds\n",
      "14_RandomForest rmse 0.892216 trained in 28.26 seconds\n",
      "7_Xgboost rmse 0.958589 trained in 5.24 seconds\n",
      "11_CatBoost rmse 0.960514 trained in 15.88 seconds\n",
      "15_RandomForest rmse 0.911538 trained in 26.85 seconds\n",
      "* Step hill_climbing_1 will try to check up to 16 models\n",
      "16_RandomForest rmse 0.887499 trained in 28.23 seconds\n",
      "17_RandomForest rmse 0.900514 trained in 28.03 seconds\n",
      "18_CatBoost rmse 0.893585 trained in 15.74 seconds\n",
      "19_CatBoost rmse 0.913841 trained in 14.31 seconds\n",
      "20_Xgboost rmse 0.89736 trained in 5.13 seconds\n",
      "21_Xgboost rmse 0.898403 trained in 5.76 seconds\n",
      "22_CatBoost rmse 0.906311 trained in 16.6 seconds\n",
      "23_CatBoost rmse 0.91453 trained in 14.82 seconds\n",
      "24_RandomForest rmse 0.90817 trained in 19.51 seconds\n",
      "25_RandomForest rmse 0.915941 trained in 18.53 seconds\n",
      "26_RandomForest rmse 0.90279 trained in 26.37 seconds\n",
      "27_CatBoost rmse 0.934957 trained in 19.05 seconds\n",
      "28_Xgboost rmse 0.922595 trained in 5.71 seconds\n",
      "29_Xgboost rmse 0.927998 trained in 5.75 seconds\n",
      "30_Xgboost rmse 0.934145 trained in 5.72 seconds\n",
      "31_Xgboost rmse 0.956343 trained in 5.82 seconds\n",
      "* Step hill_climbing_2 will try to check up to 10 models\n",
      "32_RandomForest rmse 0.888956 trained in 28.33 seconds\n",
      "33_CatBoost rmse 0.902477 trained in 16.32 seconds\n",
      "34_Xgboost rmse 0.883732 trained in 5.51 seconds\n",
      "35_Xgboost rmse 0.896645 trained in 5.52 seconds\n",
      "36_Xgboost rmse 0.889599 trained in 5.41 seconds\n",
      "37_Xgboost rmse 0.890508 trained in 5.92 seconds\n",
      "38_CatBoost rmse 0.90489 trained in 16.69 seconds\n",
      "39_Xgboost rmse 0.886741 trained in 6.39 seconds\n",
      "40_Xgboost rmse 0.892259 trained in 5.68 seconds\n",
      "41_CatBoost rmse 0.906349 trained in 17.38 seconds\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble rmse 0.865884 trained in 1.02 seconds\n",
      "AutoML fit time: 624.93 seconds\n",
      "AutoML best model: Ensemble\n",
      "R^2 Score: 0.5418395875461322\n",
      "RMSE: 0.7172552943229675\n"
     ]
    }
   ],
   "source": [
    "### Employment Density, NO Spatial Lag, Birmingham (6)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_bham\n",
    "target = 'log_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_bham[features], all_data_bham[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/employment_density_bham/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_6 = r2_score(y_test, predictions)\n",
    "rmse_6 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_6}')\n",
    "print(f'RMSE: {rmse_6}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_6 = automl.predict(all_data_bham[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': bham_geometries,\n",
    "    'observed': all_data_bham[target],\n",
    "    'predicted': predictions_all_6,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "907fde61-ed19-43a6-b9b6-3951fb0bd473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: ml_results/employment_density_london_lag/\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['CatBoost', 'Xgboost', 'Random Forest']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "1_Default_Xgboost rmse 0.657881 trained in 215.07 seconds\n",
      "2_Default_CatBoost rmse 0.642791 trained in 266.85 seconds\n",
      "3_Default_RandomForest rmse 0.757284 trained in 138.25 seconds\n",
      "* Step not_so_random will try to check up to 12 models\n",
      "4_Xgboost rmse 0.669616 trained in 207.17 seconds\n",
      "8_CatBoost rmse 0.64591 trained in 322.24 seconds\n",
      "12_RandomForest rmse 0.762435 trained in 209.54 seconds\n",
      "5_Xgboost rmse 0.675766 trained in 263.41 seconds\n",
      "9_CatBoost rmse 0.676002 trained in 333.31 seconds\n",
      "13_RandomForest rmse 0.79277 trained in 200.34 seconds\n",
      "6_Xgboost rmse 0.654206 trained in 194.5 seconds\n",
      "10_CatBoost rmse 0.642967 trained in 248.59 seconds\n",
      "14_RandomForest rmse 0.711916 trained in 191.7 seconds\n",
      "7_Xgboost rmse 0.669737 trained in 172.64 seconds\n",
      "11_CatBoost rmse 0.69348 trained in 1710.56 seconds\n",
      "15_RandomForest rmse 0.721518 trained in 1053.76 seconds\n",
      "Skip hill_climbing_1 because of the time limit.\n",
      "Skip hill_climbing_2 because of the time limit.\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble rmse 0.634549 trained in 0.17 seconds\n",
      "AutoML fit time: 6278.85 seconds\n",
      "AutoML best model: Ensemble\n",
      "R^2 Score: 0.7546440200953711\n",
      "RMSE: 0.6772318482398987\n"
     ]
    }
   ],
   "source": [
    "### Employment Density, Spatial Lag, London (7)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london_lag\n",
    "target = 'log_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/employment_density_london_lag/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_7 = r2_score(y_test, predictions)\n",
    "rmse_7 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_7}')\n",
    "print(f'RMSE: {rmse_7}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_7 = automl.predict(all_data_london[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': london_geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all_7,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "17bb150e-d907-41c8-a5cb-2d3d0e065417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: ml_results/employment_density_bham_lag/\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['CatBoost', 'Xgboost', 'Random Forest']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "1_Default_Xgboost rmse 0.917768 trained in 13.2 seconds\n",
      "2_Default_CatBoost rmse 0.896484 trained in 48.55 seconds\n",
      "3_Default_RandomForest rmse 0.903104 trained in 46.17 seconds\n",
      "* Step not_so_random will try to check up to 12 models\n",
      "4_Xgboost rmse 0.873724 trained in 11.28 seconds\n",
      "8_CatBoost rmse 0.891091 trained in 54.12 seconds\n",
      "12_RandomForest rmse 0.912287 trained in 52.29 seconds\n",
      "5_Xgboost rmse 0.956213 trained in 10.76 seconds\n",
      "9_CatBoost rmse 0.903869 trained in 50.05 seconds\n",
      "13_RandomForest rmse 0.931725 trained in 40.16 seconds\n",
      "6_Xgboost rmse 0.881023 trained in 12.54 seconds\n",
      "10_CatBoost rmse 0.904572 trained in 53.84 seconds\n",
      "14_RandomForest rmse 0.900206 trained in 40.67 seconds\n",
      "7_Xgboost rmse 0.931124 trained in 10.83 seconds\n",
      "11_CatBoost rmse 0.94668 trained in 53.4 seconds\n",
      "15_RandomForest rmse 0.912563 trained in 45.37 seconds\n",
      "* Step hill_climbing_1 will try to check up to 17 models\n",
      "16_Xgboost rmse 0.874716 trained in 16.28 seconds\n",
      "17_Xgboost rmse 0.884158 trained in 18.42 seconds\n",
      "18_Xgboost rmse 0.872058 trained in 13.78 seconds\n",
      "19_Xgboost rmse 0.877674 trained in 14.3 seconds\n",
      "20_CatBoost rmse 0.892623 trained in 73.98 seconds\n",
      "21_CatBoost rmse 0.914513 trained in 56.87 seconds\n",
      "22_CatBoost rmse 0.877059 trained in 56.5 seconds\n",
      "23_CatBoost rmse 0.899462 trained in 55.37 seconds\n",
      "24_RandomForest rmse 0.898814 trained in 43.99 seconds\n",
      "25_RandomForest rmse 0.900591 trained in 41.74 seconds\n",
      "26_RandomForest rmse 0.897618 trained in 52.58 seconds\n",
      "27_RandomForest rmse 0.899972 trained in 42.44 seconds\n",
      "28_CatBoost rmse 0.939824 trained in 64.78 seconds\n",
      "29_RandomForest rmse 0.912122 trained in 52.82 seconds\n",
      "30_RandomForest rmse 0.921884 trained in 54.49 seconds\n",
      "31_Xgboost rmse 0.888077 trained in 13.04 seconds\n",
      "32_Xgboost rmse 0.922151 trained in 13.96 seconds\n",
      "* Step hill_climbing_2 will try to check up to 12 models\n",
      "33_Xgboost rmse 0.882615 trained in 13.03 seconds\n",
      "34_Xgboost rmse 0.889454 trained in 13.38 seconds\n",
      "35_Xgboost rmse 0.865463 trained in 16.61 seconds\n",
      "36_Xgboost rmse 0.877722 trained in 17.69 seconds\n",
      "37_CatBoost rmse 0.883814 trained in 58.79 seconds\n",
      "38_CatBoost rmse 0.907262 trained in 158.05 seconds\n",
      "39_CatBoost rmse 0.891404 trained in 143.13 seconds\n",
      "40_CatBoost rmse 0.895777 trained in 153.09 seconds\n",
      "41_CatBoost rmse 0.897193 trained in 163.14 seconds\n",
      "42_RandomForest rmse 0.891139 trained in 68.63 seconds\n",
      "43_RandomForest rmse 0.890462 trained in 76.84 seconds\n",
      "44_RandomForest rmse 0.90629 trained in 70.41 seconds\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble rmse 0.845881 trained in 1.31 seconds\n",
      "AutoML fit time: 2204.53 seconds\n",
      "AutoML best model: Ensemble\n",
      "R^2 Score: 0.5136598216356548\n",
      "RMSE: 0.7389841079711914\n"
     ]
    }
   ],
   "source": [
    "### Employment Density, Spatial Lag, Birmingham (8)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_bham_lag\n",
    "target = 'log_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_bham[features], all_data_bham[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/employment_density_bham_lag/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_8 = r2_score(y_test, predictions)\n",
    "rmse_8 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_8}')\n",
    "print(f'RMSE: {rmse_8}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_8 = automl.predict(all_data_bham[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': bham_geometries,\n",
    "    'observed': all_data_bham[target],\n",
    "    'predicted': predictions_all_8,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2f6e4682-7e10-4638-bb3c-a08c426b9f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: ml_results/office_employment_density_london/\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['CatBoost', 'Xgboost', 'Random Forest']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "1_Default_Xgboost rmse 1.504599 trained in 45.38 seconds\n",
      "2_Default_CatBoost rmse 1.49624 trained in 50.4 seconds\n",
      "3_Default_RandomForest rmse 1.580713 trained in 54.52 seconds\n",
      "* Step not_so_random will try to check up to 12 models\n",
      "4_Xgboost rmse 1.519549 trained in 41.03 seconds\n",
      "8_CatBoost rmse 1.49358 trained in 73.17 seconds\n",
      "12_RandomForest rmse 1.579707 trained in 61.09 seconds\n",
      "5_Xgboost rmse 1.52396 trained in 39.45 seconds\n",
      "9_CatBoost rmse 1.529924 trained in 62.62 seconds\n",
      "13_RandomForest rmse 1.599111 trained in 43.35 seconds\n",
      "6_Xgboost rmse 1.506627 trained in 36.92 seconds\n",
      "10_CatBoost rmse 1.499347 trained in 58.67 seconds\n",
      "14_RandomForest rmse 1.559952 trained in 55.45 seconds\n",
      "7_Xgboost rmse 1.518912 trained in 36.43 seconds\n",
      "11_CatBoost rmse 1.543766 trained in 53.2 seconds\n",
      "15_RandomForest rmse 1.558276 trained in 59.99 seconds\n",
      "* Step hill_climbing_1 will try to check up to 17 models\n",
      "16_CatBoost rmse 1.496827 trained in 84.09 seconds\n",
      "17_CatBoost rmse 1.506616 trained in 59.52 seconds\n",
      "18_CatBoost rmse 1.493642 trained in 59.04 seconds\n",
      "19_CatBoost rmse 1.50457 trained in 48.6 seconds\n",
      "20_CatBoost rmse 1.499417 trained in 63.54 seconds\n",
      "21_CatBoost rmse 1.513165 trained in 48.39 seconds\n",
      "22_Xgboost rmse 1.50985 trained in 39.81 seconds\n",
      "23_Xgboost rmse 1.509713 trained in 40.65 seconds\n",
      "24_Xgboost rmse 1.512703 trained in 36.32 seconds\n",
      "25_Xgboost rmse 1.513459 trained in 36.95 seconds\n",
      "26_Xgboost rmse 1.51442 trained in 35.88 seconds\n",
      "27_Xgboost rmse 1.518803 trained in 36.29 seconds\n",
      "28_RandomForest rmse 1.556428 trained in 54.23 seconds\n",
      "29_RandomForest rmse 1.558761 trained in 70.65 seconds\n",
      "30_RandomForest rmse 1.561817 trained in 51.59 seconds\n",
      "31_RandomForest rmse 1.579403 trained in 62.0 seconds\n",
      "32_RandomForest rmse 1.579124 trained in 61.14 seconds\n",
      "* Step hill_climbing_2 will try to check up to 10 models\n",
      "33_CatBoost rmse 1.495484 trained in 70.21 seconds\n",
      "34_CatBoost rmse 1.49753 trained in 68.66 seconds\n",
      "35_CatBoost rmse 1.491477 trained in 61.57 seconds\n",
      "36_CatBoost rmse 1.498308 trained in 114.52 seconds\n",
      "37_Xgboost rmse 1.505752 trained in 77.51 seconds\n",
      "38_Xgboost rmse 1.509414 trained in 56.97 seconds\n",
      "39_Xgboost rmse 1.512812 trained in 57.59 seconds\n",
      "40_Xgboost rmse 1.507284 trained in 63.15 seconds\n",
      "41_RandomForest rmse 1.555271 trained in 80.1 seconds\n",
      "42_RandomForest rmse 1.558013 trained in 100.33 seconds\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble rmse 1.481163 trained in 1.2 seconds\n",
      "AutoML fit time: 2436.25 seconds\n",
      "AutoML best model: Ensemble\n",
      "R^2 Score: 0.49636777874679383\n",
      "RMSE: 1.5026206970214844\n"
     ]
    }
   ],
   "source": [
    "### Office Employment Density , NO Spatial Lag, London (9)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london\n",
    "target = 'log_office_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/office_employment_density_london/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_9 = r2_score(y_test, predictions)\n",
    "rmse_9 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_9}')\n",
    "print(f'RMSE: {rmse_9}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_9 = automl.predict(all_data_london[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': london_geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all_9,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "015c372b-1b93-4550-b7f5-ece1ad3149b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: ml_results/office_employment_density_bham/\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['CatBoost', 'Xgboost', 'Random Forest']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "1_Default_Xgboost rmse 2.101584 trained in 5.72 seconds\n",
      "2_Default_CatBoost rmse 2.049278 trained in 16.15 seconds\n",
      "3_Default_RandomForest rmse 2.06467 trained in 18.63 seconds\n",
      "* Step not_so_random will try to check up to 12 models\n",
      "4_Xgboost rmse 2.121226 trained in 5.28 seconds\n",
      "8_CatBoost rmse 2.067713 trained in 17.37 seconds\n",
      "12_RandomForest rmse 2.041724 trained in 20.69 seconds\n",
      "5_Xgboost rmse 2.16027 trained in 5.37 seconds\n",
      "9_CatBoost rmse 2.133641 trained in 16.67 seconds\n",
      "13_RandomForest rmse 2.028177 trained in 16.64 seconds\n",
      "6_Xgboost rmse 2.068129 trained in 5.09 seconds\n",
      "10_CatBoost rmse 2.047931 trained in 14.82 seconds\n",
      "14_RandomForest rmse 2.060436 trained in 24.46 seconds\n",
      "7_Xgboost rmse 2.092434 trained in 5.43 seconds\n",
      "11_CatBoost rmse 2.131989 trained in 16.7 seconds\n",
      "15_RandomForest rmse 2.044964 trained in 20.11 seconds\n",
      "* Step hill_climbing_1 will try to check up to 16 models\n",
      "16_RandomForest rmse 2.026727 trained in 16.86 seconds\n",
      "17_RandomForest rmse 2.039928 trained in 20.59 seconds\n",
      "18_RandomForest rmse 2.037699 trained in 20.63 seconds\n",
      "19_RandomForest rmse 2.048235 trained in 19.73 seconds\n",
      "20_CatBoost rmse 2.051888 trained in 16.31 seconds\n",
      "21_CatBoost rmse 2.039949 trained in 15.21 seconds\n",
      "22_CatBoost rmse 2.026534 trained in 16.21 seconds\n",
      "23_CatBoost rmse 2.051022 trained in 15.86 seconds\n",
      "24_CatBoost rmse 2.055047 trained in 21.78 seconds\n",
      "25_CatBoost rmse 2.07231 trained in 17.02 seconds\n",
      "26_Xgboost rmse 2.060469 trained in 5.75 seconds\n",
      "27_Xgboost rmse 2.069481 trained in 5.6 seconds\n",
      "28_Xgboost rmse 2.092434 trained in 5.38 seconds\n",
      "29_Xgboost rmse 2.092434 trained in 5.53 seconds\n",
      "30_Xgboost rmse 2.081194 trained in 6.01 seconds\n",
      "31_Xgboost rmse 2.132998 trained in 5.81 seconds\n",
      "* Step hill_climbing_2 will try to check up to 11 models\n",
      "32_CatBoost rmse 2.041345 trained in 15.68 seconds\n",
      "33_RandomForest rmse 2.025672 trained in 17.02 seconds\n",
      "34_RandomForest rmse 2.041818 trained in 20.91 seconds\n",
      "35_CatBoost rmse 2.047733 trained in 14.93 seconds\n",
      "36_CatBoost rmse 2.050567 trained in 15.43 seconds\n",
      "37_Xgboost rmse 2.081554 trained in 5.61 seconds\n",
      "38_Xgboost rmse 2.067095 trained in 5.38 seconds\n",
      "39_Xgboost rmse 2.085049 trained in 5.32 seconds\n",
      "40_Xgboost rmse 2.074459 trained in 5.31 seconds\n",
      "41_Xgboost rmse 2.082208 trained in 6.0 seconds\n",
      "42_Xgboost rmse 2.084756 trained in 8.28 seconds\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble rmse 1.997384 trained in 1.27 seconds\n",
      "AutoML fit time: 565.38 seconds\n",
      "AutoML best model: Ensemble\n",
      "R^2 Score: 0.3218584197146581\n",
      "RMSE: 2.0033411979675293\n"
     ]
    }
   ],
   "source": [
    "### Office Employment Density , NO Spatial Lag, Birmingham (10)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_bham\n",
    "target = 'log_office_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_bham[features], all_data_bham[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/office_employment_density_bham/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_10 = r2_score(y_test, predictions)\n",
    "rmse_10 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_10}')\n",
    "print(f'RMSE: {rmse_10}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_10 = automl.predict(all_data_bham[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': bham_geometries,\n",
    "    'observed': all_data_bham[target],\n",
    "    'predicted': predictions_all_10,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7d3160a4-8d0e-4048-acb5-a9f8e51ef901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: ml_results/office_employment_density_london_lag/\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['CatBoost', 'Xgboost', 'Random Forest']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "1_Default_Xgboost rmse 1.484074 trained in 302.33 seconds\n",
      "2_Default_CatBoost rmse 1.470179 trained in 259.86 seconds\n",
      "3_Default_RandomForest rmse 1.56113 trained in 139.17 seconds\n",
      "* Step not_so_random will try to check up to 12 models\n",
      "4_Xgboost rmse 1.495399 trained in 185.21 seconds\n",
      "8_CatBoost rmse 1.473112 trained in 285.45 seconds\n",
      "12_RandomForest rmse 1.551056 trained in 205.92 seconds\n",
      "5_Xgboost rmse 1.494743 trained in 152.86 seconds\n",
      "9_CatBoost rmse 1.514128 trained in 266.47 seconds\n",
      "13_RandomForest rmse 1.57424 trained in 138.61 seconds\n",
      "6_Xgboost rmse 1.48409 trained in 163.52 seconds\n",
      "10_CatBoost rmse 1.481145 trained in 244.16 seconds\n",
      "14_RandomForest rmse 1.544121 trained in 251.15 seconds\n",
      "7_Xgboost rmse 1.487578 trained in 159.66 seconds\n",
      "11_CatBoost rmse 1.531763 trained in 255.46 seconds\n",
      "15_RandomForest rmse 1.53686 trained in 210.29 seconds\n",
      "Skip hill_climbing_1 because of the time limit.\n",
      "* Step hill_climbing_2 will try to check up to 17 models\n",
      "16_CatBoost rmse 1.468728 trained in 267.89 seconds\n",
      "17_CatBoost rmse 1.482894 trained in 236.6 seconds\n",
      "18_CatBoost rmse 1.469471 trained in 314.35 seconds\n",
      "19_CatBoost rmse 1.477802 trained in 271.53 seconds\n",
      "20_CatBoost rmse 1.469141 trained in 275.29 seconds\n",
      "21_CatBoost rmse 1.485961 trained in 248.82 seconds\n",
      "22_Xgboost rmse 1.488884 trained in 143.58 seconds\n",
      "23_Xgboost rmse 1.497014 trained in 183.53 seconds\n",
      "24_Xgboost rmse 1.481859 trained in 192.29 seconds\n",
      "25_Xgboost rmse 1.489186 trained in 143.54 seconds\n",
      "26_Xgboost rmse 1.49634 trained in 144.01 seconds\n",
      "27_Xgboost rmse 1.488359 trained in 163.52 seconds\n",
      "28_RandomForest rmse 1.537154 trained in 181.91 seconds\n",
      "29_RandomForest rmse 1.543553 trained in 252.9 seconds\n",
      "30_RandomForest rmse 1.54562 trained in 233.61 seconds\n",
      "31_RandomForest rmse 1.551593 trained in 162.97 seconds\n",
      "32_RandomForest rmse 1.550704 trained in 183.44 seconds\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble rmse 1.451702 trained in 0.66 seconds\n",
      "AutoML fit time: 6837.77 seconds\n",
      "AutoML best model: Ensemble\n",
      "R^2 Score: 0.5199997984881497\n",
      "RMSE: 1.4669432640075684\n"
     ]
    }
   ],
   "source": [
    "### Office Employment Density, Spatial Lag, London (11)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london_lag\n",
    "target = 'log_office_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/office_employment_density_london_lag/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_11 = r2_score(y_test, predictions)\n",
    "rmse_11 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_11}')\n",
    "print(f'RMSE: {rmse_11}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_11 = automl.predict(all_data_london[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': london_geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all_11,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c793ac54-59e8-4ff0-b95a-0bb60d1edd9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: ml_results/office_employment_density_bham_lag/\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['CatBoost', 'Xgboost', 'Random Forest']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "1_Default_Xgboost rmse 2.062851 trained in 14.2 seconds\n",
      "2_Default_CatBoost rmse 1.991828 trained in 61.23 seconds\n",
      "3_Default_RandomForest rmse 2.010472 trained in 72.42 seconds\n",
      "* Step not_so_random will try to check up to 12 models\n",
      "4_Xgboost rmse 2.063623 trained in 20.46 seconds\n",
      "8_CatBoost rmse 2.01133 trained in 67.34 seconds\n",
      "12_RandomForest rmse 1.985058 trained in 44.24 seconds\n",
      "5_Xgboost rmse 2.121576 trained in 15.44 seconds\n",
      "9_CatBoost rmse 2.10722 trained in 62.0 seconds\n",
      "13_RandomForest rmse 2.010341 trained in 52.61 seconds\n",
      "6_Xgboost rmse 2.009703 trained in 17.07 seconds\n",
      "10_CatBoost rmse 2.012742 trained in 61.26 seconds\n",
      "14_RandomForest rmse 1.998174 trained in 43.74 seconds\n",
      "7_Xgboost rmse 2.026721 trained in 17.32 seconds\n",
      "11_CatBoost rmse 2.136536 trained in 62.48 seconds\n",
      "15_RandomForest rmse 2.002244 trained in 61.26 seconds\n",
      "* Step hill_climbing_1 will try to check up to 17 models\n",
      "16_RandomForest rmse 1.979969 trained in 46.16 seconds\n",
      "17_RandomForest rmse 1.990187 trained in 46.86 seconds\n",
      "18_CatBoost rmse 1.995255 trained in 61.79 seconds\n",
      "19_CatBoost rmse 2.031151 trained in 61.17 seconds\n",
      "20_RandomForest rmse 1.997922 trained in 41.75 seconds\n",
      "21_RandomForest rmse 2.004284 trained in 46.91 seconds\n",
      "22_RandomForest rmse 1.994041 trained in 42.95 seconds\n",
      "23_Xgboost rmse 2.028043 trained in 14.02 seconds\n",
      "24_Xgboost rmse 2.007397 trained in 13.53 seconds\n",
      "25_CatBoost rmse 2.025999 trained in 70.43 seconds\n",
      "26_CatBoost rmse 2.054953 trained in 63.15 seconds\n",
      "27_CatBoost rmse 2.007349 trained in 65.46 seconds\n",
      "28_CatBoost rmse 2.046938 trained in 61.26 seconds\n",
      "29_Xgboost rmse 2.026721 trained in 15.5 seconds\n",
      "30_Xgboost rmse 2.026721 trained in 15.56 seconds\n",
      "31_Xgboost rmse 2.034181 trained in 15.45 seconds\n",
      "32_Xgboost rmse 2.075595 trained in 16.02 seconds\n",
      "* Step hill_climbing_2 will try to check up to 10 models\n",
      "33_RandomForest rmse 2.001202 trained in 45.42 seconds\n",
      "34_CatBoost rmse 1.989052 trained in 59.92 seconds\n",
      "35_CatBoost rmse 1.997319 trained in 62.27 seconds\n",
      "36_CatBoost rmse 2.010433 trained in 61.92 seconds\n",
      "37_Xgboost rmse 1.979279 trained in 13.81 seconds\n",
      "38_Xgboost rmse 2.014844 trained in 13.77 seconds\n",
      "39_Xgboost rmse 1.988273 trained in 13.37 seconds\n",
      "40_Xgboost rmse 2.024596 trained in 14.2 seconds\n",
      "41_Xgboost rmse 2.021149 trained in 14.09 seconds\n",
      "42_Xgboost rmse 2.011727 trained in 15.79 seconds\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble rmse 1.951316 trained in 1.09 seconds\n",
      "AutoML fit time: 1708.23 seconds\n",
      "AutoML best model: Ensemble\n",
      "R^2 Score: 0.36409893314774844\n",
      "RMSE: 1.9399455785751343\n"
     ]
    }
   ],
   "source": [
    "### Office Employment Density (log), Spatial Lag, Birmingham (12)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_bham_lag\n",
    "target = 'log_office_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_bham[features], all_data_bham[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/office_employment_density_bham_lag/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_12 = r2_score(y_test, predictions)\n",
    "rmse_12 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_12}')\n",
    "print(f'RMSE: {rmse_12}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_12 = automl.predict(all_data_bham[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': bham_geometries,\n",
    "    'observed': all_data_bham[target],\n",
    "    'predicted': predictions_all_12,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c0592585-a869-42b2-9ccd-c7ebe0bef895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model has already been fitted. You can use predict methods or select a new 'results_path' for a new 'fit()'.\n",
      "R^2 Score: 0.7256287050510382\n",
      "RMSE: 0.672401487827301\n"
     ]
    }
   ],
   "source": [
    "### Employment (log), NO Spatial Lag, London, POI only (13)\n",
    "\n",
    "# Ignore depracation warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london_poi\n",
    "target = 'log_total_employment'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/log_employment_london_poi/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_13 = r2_score(y_test, predictions)\n",
    "rmse_13 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_13}')\n",
    "print(f'RMSE: {rmse_13}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_13 = automl.predict(all_data_london[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': london_geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all_13,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b3ff96c6-9be8-4705-83e2-67f8876eb238",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gavinrolls/anaconda3/envs/urbsim/lib/python3.11/site-packages/supervised/preprocessing/exclude_missing_target.py:25: UserWarning: There are samples with missing target values in the data which will be excluded for further analysis\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: ml_results/log_employment_bham_poi/\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['CatBoost', 'Xgboost', 'Random Forest']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "1_Default_Xgboost rmse 0.796247 trained in 1077.34 seconds\n",
      "2_Default_CatBoost rmse 0.811589 trained in 10.74 seconds\n",
      "3_Default_RandomForest rmse 0.819108 trained in 18.32 seconds\n",
      "* Step not_so_random will try to check up to 12 models\n",
      "4_Xgboost rmse 0.814556 trained in 4.52 seconds\n",
      "8_CatBoost rmse 0.820528 trained in 17.07 seconds\n",
      "12_RandomForest rmse 0.81786 trained in 18.95 seconds\n",
      "5_Xgboost rmse 0.818373 trained in 5.14 seconds\n",
      "9_CatBoost rmse 0.835969 trained in 14.25 seconds\n",
      "13_RandomForest rmse 0.847451 trained in 20.41 seconds\n",
      "6_Xgboost rmse 0.786124 trained in 4.86 seconds\n",
      "10_CatBoost rmse 0.823456 trained in 13.13 seconds\n",
      "14_RandomForest rmse 0.816404 trained in 20.54 seconds\n",
      "7_Xgboost rmse 0.860902 trained in 4.61 seconds\n",
      "11_CatBoost rmse 0.859474 trained in 13.83 seconds\n",
      "15_RandomForest rmse 0.824256 trained in 19.11 seconds\n",
      "* Step hill_climbing_1 will try to check up to 18 models\n",
      "16_Xgboost rmse 0.78515 trained in 4.85 seconds\n",
      "17_Xgboost rmse 0.789404 trained in 4.81 seconds\n",
      "18_Xgboost rmse 0.78776 trained in 4.72 seconds\n",
      "19_Xgboost rmse 0.807992 trained in 5.16 seconds\n",
      "20_CatBoost rmse 0.794589 trained in 13.96 seconds\n",
      "21_CatBoost rmse 0.810056 trained in 12.73 seconds\n",
      "22_Xgboost rmse 0.810594 trained in 5.48 seconds\n",
      "23_Xgboost rmse 0.812881 trained in 5.85 seconds\n",
      "24_RandomForest rmse 0.808417 trained in 20.7 seconds\n",
      "25_RandomForest rmse 0.828899 trained in 18.61 seconds\n",
      "26_RandomForest rmse 0.81791 trained in 19.22 seconds\n",
      "27_RandomForest rmse 0.820985 trained in 21.68 seconds\n",
      "28_RandomForest rmse 0.813939 trained in 20.54 seconds\n",
      "29_RandomForest rmse 0.825659 trained in 20.7 seconds\n",
      "30_CatBoost rmse 0.826822 trained in 22.93 seconds\n",
      "31_CatBoost rmse 0.837677 trained in 14.62 seconds\n",
      "32_CatBoost rmse 0.81028 trained in 14.74 seconds\n",
      "33_CatBoost rmse 0.818305 trained in 13.59 seconds\n",
      "* Step hill_climbing_2 will try to check up to 11 models\n",
      "34_Xgboost rmse 0.784243 trained in 4.96 seconds\n",
      "35_Xgboost rmse 0.788559 trained in 4.93 seconds\n",
      "36_Xgboost rmse 0.785134 trained in 5.0 seconds\n",
      "37_Xgboost rmse 0.788556 trained in 5.14 seconds\n",
      "38_Xgboost rmse 0.798748 trained in 5.15 seconds\n",
      "39_CatBoost rmse 0.804644 trained in 27.01 seconds\n",
      "40_RandomForest rmse 0.800958 trained in 18.56 seconds\n",
      "41_CatBoost rmse 0.814851 trained in 17.99 seconds\n",
      "42_RandomForest rmse 0.809814 trained in 17.02 seconds\n",
      "43_RandomForest rmse 0.813948 trained in 24.13 seconds\n",
      "44_RandomForest rmse 0.808648 trained in 17.94 seconds\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble rmse 0.768035 trained in 1.09 seconds\n",
      "AutoML fit time: 1676.53 seconds\n",
      "AutoML best model: Ensemble\n",
      "R^2 Score: 0.629515890174141\n",
      "RMSE: 0.7245278358459473\n"
     ]
    }
   ],
   "source": [
    "### Employment (log), NO Spatial Lag, Brimingham, POI only (14)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_bham_poi\n",
    "target = 'log_total_employment'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_bham[features], all_data_bham[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/log_employment_bham_poi/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_14 = r2_score(y_test, predictions)\n",
    "rmse_14 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_14}')\n",
    "print(f'RMSE: {rmse_14}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_14 = automl.predict(all_data_bham[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': bham_geometries,\n",
    "    'observed': all_data_bham[target],\n",
    "    'predicted': predictions_all_14,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2d4bf1d6-902a-4011-b805-4e1d2df8644e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: ml_results/employment_density_london_poi/\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['CatBoost', 'Xgboost', 'Random Forest']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "1_Default_Xgboost rmse 0.810964 trained in 41.43 seconds\n",
      "2_Default_CatBoost rmse 0.784844 trained in 51.37 seconds\n",
      "3_Default_RandomForest rmse 0.922467 trained in 78.52 seconds\n",
      "* Step not_so_random will try to check up to 12 models\n",
      "4_Xgboost rmse 0.815659 trained in 41.2 seconds\n",
      "8_CatBoost rmse 0.782558 trained in 62.33 seconds\n",
      "12_RandomForest rmse 0.918514 trained in 45.81 seconds\n",
      "5_Xgboost rmse 0.826209 trained in 42.8 seconds\n",
      "9_CatBoost rmse 0.799203 trained in 58.45 seconds\n",
      "13_RandomForest rmse 0.944806 trained in 45.33 seconds\n",
      "6_Xgboost rmse 0.789962 trained in 39.41 seconds\n",
      "10_CatBoost rmse 0.785354 trained in 51.18 seconds\n",
      "14_RandomForest rmse 0.894304 trained in 78.88 seconds\n",
      "7_Xgboost rmse 0.806051 trained in 36.19 seconds\n",
      "11_CatBoost rmse 0.813929 trained in 52.91 seconds\n",
      "15_RandomForest rmse 0.89239 trained in 76.73 seconds\n",
      "* Step hill_climbing_1 will try to check up to 17 models\n",
      "16_CatBoost rmse 0.782005 trained in 81.17 seconds\n",
      "17_CatBoost rmse 0.787997 trained in 53.28 seconds\n",
      "18_CatBoost rmse 0.783175 trained in 54.92 seconds\n",
      "19_CatBoost rmse 0.79305 trained in 47.27 seconds\n",
      "20_CatBoost rmse 0.784556 trained in 57.89 seconds\n",
      "21_CatBoost rmse 0.793598 trained in 47.21 seconds\n",
      "22_Xgboost rmse 0.793357 trained in 39.59 seconds\n",
      "23_Xgboost rmse 0.795993 trained in 38.42 seconds\n",
      "24_Xgboost rmse 0.803563 trained in 34.45 seconds\n",
      "25_Xgboost rmse 0.808658 trained in 34.73 seconds\n",
      "26_Xgboost rmse 0.806011 trained in 40.12 seconds\n",
      "27_Xgboost rmse 0.820999 trained in 40.67 seconds\n",
      "28_RandomForest rmse 0.890201 trained in 71.35 seconds\n",
      "29_RandomForest rmse 0.893161 trained in 61.73 seconds\n",
      "30_RandomForest rmse 0.894961 trained in 79.5 seconds\n",
      "31_RandomForest rmse 0.918474 trained in 46.47 seconds\n",
      "32_RandomForest rmse 0.919341 trained in 49.41 seconds\n",
      "* Step hill_climbing_2 will try to check up to 13 models\n",
      "33_CatBoost rmse 0.780313 trained in 78.13 seconds\n",
      "34_CatBoost rmse 0.782959 trained in 80.44 seconds\n",
      "35_CatBoost rmse 0.784423 trained in 62.99 seconds\n",
      "36_CatBoost rmse 0.786228 trained in 64.35 seconds\n",
      "37_CatBoost rmse 0.781632 trained in 57.28 seconds\n",
      "38_Xgboost rmse 0.791058 trained in 36.27 seconds\n",
      "39_Xgboost rmse 0.794357 trained in 38.05 seconds\n",
      "40_Xgboost rmse 0.793191 trained in 36.41 seconds\n",
      "41_Xgboost rmse 0.79203 trained in 37.29 seconds\n",
      "42_Xgboost rmse 0.794065 trained in 36.57 seconds\n",
      "43_Xgboost rmse 0.795749 trained in 38.72 seconds\n",
      "44_RandomForest rmse 0.889359 trained in 80.64 seconds\n",
      "45_RandomForest rmse 0.891102 trained in 84.73 seconds\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble rmse 0.775016 trained in 1.18 seconds\n",
      "AutoML fit time: 2437.6 seconds\n",
      "AutoML best model: Ensemble\n",
      "R^2 Score: 0.6533896491167754\n",
      "RMSE: 0.8049330711364746\n"
     ]
    }
   ],
   "source": [
    "### Employment Density, NO Spatial Lag, London, POI only (15)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london_poi\n",
    "target = 'log_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/employment_density_london_poi/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_15 = r2_score(y_test, predictions)\n",
    "rmse_15 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_15}')\n",
    "print(f'RMSE: {rmse_15}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_15 = automl.predict(all_data_london[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': london_geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all_15,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "88b18222-1efa-4451-b8a1-5d26ba8f83cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: ml_results/employment_density_bham_poi/\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['CatBoost', 'Xgboost', 'Random Forest']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "1_Default_Xgboost rmse 0.933653 trained in 5.96 seconds\n",
      "2_Default_CatBoost rmse 0.90717 trained in 14.21 seconds\n",
      "3_Default_RandomForest rmse 0.9083 trained in 23.18 seconds\n",
      "* Step not_so_random will try to check up to 12 models\n",
      "4_Xgboost rmse 0.927255 trained in 5.39 seconds\n",
      "8_CatBoost rmse 0.916364 trained in 18.89 seconds\n",
      "12_RandomForest rmse 0.92552 trained in 25.7 seconds\n",
      "5_Xgboost rmse 0.974737 trained in 5.45 seconds\n",
      "9_CatBoost rmse 0.936304 trained in 16.28 seconds\n",
      "13_RandomForest rmse 0.935442 trained in 21.21 seconds\n",
      "6_Xgboost rmse 0.884959 trained in 5.43 seconds\n",
      "10_CatBoost rmse 0.910989 trained in 15.79 seconds\n",
      "14_RandomForest rmse 0.891044 trained in 27.63 seconds\n",
      "7_Xgboost rmse 0.965723 trained in 5.16 seconds\n",
      "11_CatBoost rmse 0.942194 trained in 15.26 seconds\n",
      "15_RandomForest rmse 0.911169 trained in 29.72 seconds\n",
      "* Step hill_climbing_1 will try to check up to 17 models\n",
      "16_Xgboost rmse 0.888277 trained in 5.17 seconds\n",
      "17_Xgboost rmse 0.882937 trained in 5.43 seconds\n",
      "18_RandomForest rmse 0.890828 trained in 18.2 seconds\n",
      "19_RandomForest rmse 0.899192 trained in 27.69 seconds\n",
      "20_CatBoost rmse 0.897686 trained in 15.07 seconds\n",
      "21_CatBoost rmse 0.918197 trained in 13.72 seconds\n",
      "22_RandomForest rmse 0.907888 trained in 21.66 seconds\n",
      "23_RandomForest rmse 0.910272 trained in 22.36 seconds\n",
      "24_CatBoost rmse 0.900805 trained in 16.68 seconds\n",
      "25_CatBoost rmse 0.923518 trained in 14.67 seconds\n",
      "26_RandomForest rmse 0.903878 trained in 24.63 seconds\n",
      "27_CatBoost rmse 0.906017 trained in 25.66 seconds\n",
      "28_CatBoost rmse 0.919571 trained in 16.59 seconds\n",
      "29_Xgboost rmse 0.918503 trained in 5.5 seconds\n",
      "30_Xgboost rmse 0.922444 trained in 5.71 seconds\n",
      "31_Xgboost rmse 0.932665 trained in 5.37 seconds\n",
      "32_Xgboost rmse 0.958553 trained in 5.9 seconds\n",
      "* Step hill_climbing_2 will try to check up to 11 models\n",
      "33_Xgboost rmse 0.89098 trained in 5.71 seconds\n",
      "34_Xgboost rmse 0.894724 trained in 5.42 seconds\n",
      "35_Xgboost rmse 0.891376 trained in 5.66 seconds\n",
      "36_Xgboost rmse 0.893125 trained in 5.91 seconds\n",
      "37_Xgboost rmse 0.893545 trained in 5.82 seconds\n",
      "38_Xgboost rmse 0.894712 trained in 5.7 seconds\n",
      "39_RandomForest rmse 0.886449 trained in 22.96 seconds\n",
      "40_CatBoost rmse 0.904217 trained in 15.9 seconds\n",
      "41_CatBoost rmse 0.901771 trained in 17.65 seconds\n",
      "42_CatBoost rmse 0.913593 trained in 24.02 seconds\n",
      "43_CatBoost rmse 0.909391 trained in 23.99 seconds\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble rmse 0.86895 trained in 1.05 seconds\n",
      "AutoML fit time: 644.47 seconds\n",
      "AutoML best model: Ensemble\n",
      "R^2 Score: 0.5372484254080511\n",
      "RMSE: 0.7208401560783386\n"
     ]
    }
   ],
   "source": [
    "### Employment Density, NO Spatial Lag, Brimingham, POI only (16)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_bham_poi\n",
    "target = 'log_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_bham[features], all_data_bham[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/employment_density_bham_poi/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_16 = r2_score(y_test, predictions)\n",
    "rmse_16 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_16}')\n",
    "print(f'RMSE: {rmse_16}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_16 = automl.predict(all_data_bham[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': bham_geometries,\n",
    "    'observed': all_data_bham[target],\n",
    "    'predicted': predictions_all_16,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "154710f6-e527-4512-8861-573d0f26d504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: ml_results/office_employment_density_london_poi/\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['CatBoost', 'Xgboost', 'Random Forest']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "1_Default_Xgboost rmse 1.594738 trained in 34.7 seconds\n",
      "2_Default_CatBoost rmse 1.579013 trained in 48.37 seconds\n",
      "3_Default_RandomForest rmse 1.690103 trained in 51.23 seconds\n",
      "* Step not_so_random will try to check up to 12 models\n",
      "4_Xgboost rmse 1.606491 trained in 36.18 seconds\n",
      "8_CatBoost rmse 1.579068 trained in 58.23 seconds\n",
      "12_RandomForest rmse 1.687728 trained in 67.06 seconds\n",
      "5_Xgboost rmse 1.608838 trained in 35.24 seconds\n",
      "9_CatBoost rmse 1.602372 trained in 56.5 seconds\n",
      "13_RandomForest rmse 1.710323 trained in 51.08 seconds\n",
      "6_Xgboost rmse 1.582432 trained in 34.45 seconds\n",
      "10_CatBoost rmse 1.580143 trained in 48.1 seconds\n",
      "14_RandomForest rmse 1.670511 trained in 59.47 seconds\n",
      "7_Xgboost rmse 1.594581 trained in 34.01 seconds\n",
      "11_CatBoost rmse 1.605527 trained in 52.22 seconds\n",
      "15_RandomForest rmse 1.66745 trained in 44.23 seconds\n",
      "* Step hill_climbing_1 will try to check up to 17 models\n",
      "16_CatBoost rmse 1.577853 trained in 52.13 seconds\n",
      "17_CatBoost rmse 1.582704 trained in 46.5 seconds\n",
      "18_CatBoost rmse 1.57806 trained in 72.72 seconds\n",
      "19_CatBoost rmse 1.58344 trained in 53.59 seconds\n",
      "20_CatBoost rmse 1.574759 trained in 56.11 seconds\n",
      "21_CatBoost rmse 1.590421 trained in 47.33 seconds\n",
      "22_Xgboost rmse 1.580199 trained in 36.28 seconds\n",
      "23_Xgboost rmse 1.586017 trained in 36.66 seconds\n",
      "24_Xgboost rmse 1.596831 trained in 35.02 seconds\n",
      "25_Xgboost rmse 1.602461 trained in 35.8 seconds\n",
      "26_Xgboost rmse 1.597827 trained in 37.77 seconds\n",
      "27_Xgboost rmse 1.602149 trained in 38.3 seconds\n",
      "28_RandomForest rmse 1.667361 trained in 50.8 seconds\n",
      "29_RandomForest rmse 1.668948 trained in 60.19 seconds\n",
      "30_RandomForest rmse 1.672382 trained in 67.41 seconds\n",
      "31_RandomForest rmse 1.687761 trained in 69.25 seconds\n",
      "32_RandomForest rmse 1.687699 trained in 69.05 seconds\n",
      "* Step hill_climbing_2 will try to check up to 12 models\n",
      "33_CatBoost rmse 1.580285 trained in 59.83 seconds\n",
      "34_CatBoost rmse 1.577076 trained in 59.26 seconds\n",
      "35_CatBoost rmse 1.579149 trained in 74.85 seconds\n",
      "36_CatBoost rmse 1.577012 trained in 78.95 seconds\n",
      "37_Xgboost rmse 1.58112 trained in 36.91 seconds\n",
      "38_Xgboost rmse 1.580098 trained in 36.79 seconds\n",
      "39_Xgboost rmse 1.583197 trained in 37.51 seconds\n",
      "40_Xgboost rmse 1.58596 trained in 37.6 seconds\n",
      "41_Xgboost rmse 1.582843 trained in 39.22 seconds\n",
      "42_Xgboost rmse 1.585032 trained in 37.42 seconds\n",
      "43_RandomForest rmse 1.666481 trained in 50.07 seconds\n",
      "44_RandomForest rmse 1.667508 trained in 79.84 seconds\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble rmse 1.560889 trained in 1.19 seconds\n",
      "AutoML fit time: 2228.9 seconds\n",
      "AutoML best model: Ensemble\n",
      "R^2 Score: 0.4520162646651782\n",
      "RMSE: 1.5673878192901611\n"
     ]
    }
   ],
   "source": [
    "### Office Employment Density, NO Spatial Lag, London, POI only (17)\n",
    "\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london_poi\n",
    "target = 'log_office_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/office_employment_density_london_poi/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_17 = r2_score(y_test, predictions)\n",
    "rmse_17 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_17}')\n",
    "print(f'RMSE: {rmse_17}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_17 = automl.predict(all_data_london[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': london_geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all_17,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "27df441e-a493-4c24-88e7-a302f6e05843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: ml_results/office_employment_density_bham_poi/\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['CatBoost', 'Xgboost', 'Random Forest']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "1_Default_Xgboost rmse 2.103662 trained in 6.26 seconds\n",
      "2_Default_CatBoost rmse 2.032205 trained in 14.76 seconds\n",
      "3_Default_RandomForest rmse 2.06174 trained in 19.28 seconds\n",
      "* Step not_so_random will try to check up to 12 models\n",
      "4_Xgboost rmse 2.115326 trained in 5.91 seconds\n",
      "8_CatBoost rmse 2.063828 trained in 17.41 seconds\n",
      "12_RandomForest rmse 2.032244 trained in 21.91 seconds\n",
      "5_Xgboost rmse 2.156681 trained in 6.02 seconds\n",
      "9_CatBoost rmse 2.116306 trained in 17.34 seconds\n",
      "13_RandomForest rmse 2.046611 trained in 17.34 seconds\n",
      "6_Xgboost rmse 2.087835 trained in 5.44 seconds\n",
      "10_CatBoost rmse 2.036648 trained in 15.33 seconds\n",
      "14_RandomForest rmse 2.06592 trained in 24.6 seconds\n",
      "7_Xgboost rmse 2.089789 trained in 5.33 seconds\n",
      "11_CatBoost rmse 2.144873 trained in 16.14 seconds\n",
      "15_RandomForest rmse 2.046031 trained in 27.41 seconds\n",
      "* Step hill_climbing_1 will try to check up to 16 models\n",
      "16_CatBoost rmse 2.025246 trained in 15.75 seconds\n",
      "17_CatBoost rmse 2.029456 trained in 14.74 seconds\n",
      "18_RandomForest rmse 2.036405 trained in 18.75 seconds\n",
      "19_RandomForest rmse 2.042943 trained in 18.93 seconds\n",
      "20_CatBoost rmse 2.035841 trained in 16.55 seconds\n",
      "21_CatBoost rmse 2.059625 trained in 14.76 seconds\n",
      "22_RandomForest rmse 2.04601 trained in 28.92 seconds\n",
      "23_RandomForest rmse 2.038608 trained in 18.03 seconds\n",
      "24_CatBoost rmse 2.064289 trained in 19.27 seconds\n",
      "25_CatBoost rmse 2.054938 trained in 15.1 seconds\n",
      "26_Xgboost rmse 2.070845 trained in 5.09 seconds\n",
      "27_Xgboost rmse 2.074104 trained in 5.39 seconds\n",
      "28_Xgboost rmse 2.089789 trained in 5.02 seconds\n",
      "29_Xgboost rmse 2.089789 trained in 5.12 seconds\n",
      "30_Xgboost rmse 2.076477 trained in 5.3 seconds\n",
      "31_Xgboost rmse 2.128673 trained in 5.4 seconds\n",
      "* Step hill_climbing_2 will try to check up to 9 models\n",
      "32_CatBoost rmse 2.032423 trained in 14.71 seconds\n",
      "33_CatBoost rmse 2.046108 trained in 13.83 seconds\n",
      "34_CatBoost rmse 2.050494 trained in 14.21 seconds\n",
      "35_RandomForest rmse 2.038957 trained in 18.11 seconds\n",
      "36_Xgboost rmse 2.080163 trained in 5.3 seconds\n",
      "37_Xgboost rmse 2.068428 trained in 5.32 seconds\n",
      "38_Xgboost rmse 2.079473 trained in 5.42 seconds\n",
      "39_Xgboost rmse 2.082572 trained in 5.41 seconds\n",
      "40_Xgboost rmse 2.082101 trained in 5.37 seconds\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble rmse 2.00759 trained in 0.93 seconds\n",
      "AutoML fit time: 540.14 seconds\n",
      "AutoML best model: Ensemble\n",
      "R^2 Score: 0.3357305442471674\n",
      "RMSE: 1.9827451705932617\n"
     ]
    }
   ],
   "source": [
    "### Office Employment Density, NO Spatial Lag, Birmingham, POI only (18)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_bham_poi\n",
    "target = 'log_office_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_bham[features], all_data_bham[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/office_employment_density_bham_poi/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_18 = r2_score(y_test, predictions)\n",
    "rmse_18 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_18}')\n",
    "print(f'RMSE: {rmse_18}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_18 = automl.predict(all_data_bham[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': bham_geometries,\n",
    "    'observed': all_data_bham[target],\n",
    "    'predicted': predictions_all_18,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcb1705-7a08-4f36-97bc-fe4b06fb175f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6abadb44-cad5-4e42-afb1-696b1611f5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: ml_results/employment_london_lag_poi/\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['CatBoost', 'Xgboost', 'Random Forest']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "1_Default_Xgboost rmse 0.677317 trained in 178.57 seconds\n",
      "2_Default_CatBoost rmse 0.667763 trained in 219.62 seconds\n",
      "3_Default_RandomForest rmse 0.705324 trained in 156.94 seconds\n",
      "* Step not_so_random will try to check up to 12 models\n",
      "4_Xgboost rmse 0.682807 trained in 181.02 seconds\n",
      "8_CatBoost rmse 0.669091 trained in 270.9 seconds\n",
      "12_RandomForest rmse 0.708888 trained in 198.86 seconds\n",
      "5_Xgboost rmse 0.684443 trained in 240.9 seconds\n",
      "9_CatBoost rmse 0.682518 trained in 308.91 seconds\n",
      "13_RandomForest rmse 0.723025 trained in 193.24 seconds\n",
      "6_Xgboost rmse 0.675833 trained in 231.93 seconds\n",
      "10_CatBoost rmse 0.669446 trained in 257.29 seconds\n",
      "14_RandomForest rmse 0.695681 trained in 157.34 seconds\n",
      "7_Xgboost rmse 0.68836 trained in 183.97 seconds\n",
      "11_CatBoost rmse 0.693974 trained in 242.55 seconds\n",
      "15_RandomForest rmse 0.694723 trained in 179.1 seconds\n",
      "Skip hill_climbing_1 because of the time limit.\n",
      "* Step hill_climbing_2 will try to check up to 17 models\n",
      "16_CatBoost rmse 0.666565 trained in 303.28 seconds\n",
      "17_CatBoost rmse 0.676396 trained in 314.0 seconds\n",
      "18_CatBoost rmse 0.667542 trained in 386.75 seconds\n",
      "19_CatBoost rmse 0.671958 trained in 282.99 seconds\n",
      "20_CatBoost rmse 0.6643 trained in 392.11 seconds\n",
      "21_CatBoost rmse 0.685319 trained in 291.6 seconds\n",
      "22_Xgboost rmse 0.674757 trained in 220.89 seconds\n",
      "23_Xgboost rmse 0.678522 trained in 222.03 seconds\n",
      "24_Xgboost rmse 0.669602 trained in 214.66 seconds\n",
      "25_Xgboost rmse 0.680515 trained in 166.64 seconds\n",
      "26_Xgboost rmse 0.677202 trained in 123.23 seconds\n",
      "27_Xgboost rmse 0.688467 trained in 133.04 seconds\n",
      "28_RandomForest rmse 0.691423 trained in 126.92 seconds\n",
      "29_RandomForest rmse 0.694364 trained in 118.33 seconds\n",
      "30_RandomForest rmse 0.698424 trained in 108.41 seconds\n",
      "31_RandomForest rmse 0.704525 trained in 108.98 seconds\n",
      "32_RandomForest rmse 0.706678 trained in 127.91 seconds\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble rmse 0.658117 trained in 0.65 seconds\n",
      "AutoML fit time: 6861.2 seconds\n",
      "AutoML best model: Ensemble\n",
      "R^2 Score: 0.7263952956809839\n",
      "RMSE: 0.6714615225791931\n"
     ]
    }
   ],
   "source": [
    "### Employment (log), Spatial Lag, NO building footprints, London (19)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london_lag_poi\n",
    "target = 'log_total_employment'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/employment_london_lag_poi/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_19 = r2_score(y_test, predictions)\n",
    "rmse_19 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_19}')\n",
    "print(f'RMSE: {rmse_19}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_19 = automl.predict(all_data_london[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': london_geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all_19,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d14a7257-f1e2-4bf5-a856-8868805a693a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: ml_results/employment_bham_lag_poi/\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['CatBoost', 'Xgboost', 'Random Forest']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "1_Default_Xgboost rmse 0.834064 trained in 14.83 seconds\n",
      "2_Default_CatBoost rmse 0.828002 trained in 52.99 seconds\n",
      "3_Default_RandomForest rmse 0.831382 trained in 47.92 seconds\n",
      "* Step not_so_random will try to check up to 12 models\n",
      "4_Xgboost rmse 0.856098 trained in 13.66 seconds\n",
      "8_CatBoost rmse 0.846562 trained in 68.72 seconds\n",
      "12_RandomForest rmse 0.817336 trained in 38.78 seconds\n",
      "5_Xgboost rmse 0.869507 trained in 11.26 seconds\n",
      "9_CatBoost rmse 0.888438 trained in 50.76 seconds\n",
      "13_RandomForest rmse 0.850046 trained in 52.13 seconds\n",
      "6_Xgboost rmse 0.821908 trained in 13.16 seconds\n",
      "10_CatBoost rmse 0.843848 trained in 58.34 seconds\n",
      "14_RandomForest rmse 0.82889 trained in 44.59 seconds\n",
      "7_Xgboost rmse 0.854584 trained in 13.03 seconds\n",
      "11_CatBoost rmse 0.921937 trained in 55.3 seconds\n",
      "15_RandomForest rmse 0.83339 trained in 42.81 seconds\n",
      "* Step hill_climbing_1 will try to check up to 18 models\n",
      "16_RandomForest rmse 0.815043 trained in 41.11 seconds\n",
      "17_RandomForest rmse 0.824801 trained in 39.2 seconds\n",
      "18_Xgboost rmse 0.823448 trained in 12.67 seconds\n",
      "19_Xgboost rmse 0.819177 trained in 10.9 seconds\n",
      "20_CatBoost rmse 0.81785 trained in 56.99 seconds\n",
      "21_CatBoost rmse 0.840744 trained in 53.64 seconds\n",
      "22_RandomForest rmse 0.826507 trained in 46.84 seconds\n",
      "23_RandomForest rmse 0.831141 trained in 43.79 seconds\n",
      "24_RandomForest rmse 0.818194 trained in 37.51 seconds\n",
      "25_RandomForest rmse 0.83265 trained in 39.21 seconds\n",
      "26_Xgboost rmse 0.812436 trained in 16.97 seconds\n",
      "27_Xgboost rmse 0.856773 trained in 14.22 seconds\n",
      "28_CatBoost rmse 0.832404 trained in 62.83 seconds\n",
      "29_CatBoost rmse 0.85301 trained in 54.31 seconds\n",
      "30_CatBoost rmse 0.851475 trained in 77.67 seconds\n",
      "31_CatBoost rmse 0.849293 trained in 55.54 seconds\n",
      "32_Xgboost rmse 0.854584 trained in 12.64 seconds\n",
      "33_Xgboost rmse 0.854584 trained in 11.63 seconds\n",
      "* Step hill_climbing_2 will try to check up to 11 models\n",
      "34_Xgboost rmse 0.814138 trained in 11.39 seconds\n",
      "35_RandomForest rmse 0.818932 trained in 40.6 seconds\n",
      "36_RandomForest rmse 0.823342 trained in 38.57 seconds\n",
      "37_CatBoost rmse 0.825971 trained in 61.81 seconds\n",
      "38_RandomForest rmse 0.822641 trained in 42.85 seconds\n",
      "39_RandomForest rmse 0.825489 trained in 48.33 seconds\n",
      "40_Xgboost rmse 0.808539 trained in 13.04 seconds\n",
      "41_Xgboost rmse 0.818262 trained in 11.93 seconds\n",
      "42_Xgboost rmse 0.808561 trained in 11.77 seconds\n",
      "43_Xgboost rmse 0.820384 trained in 11.07 seconds\n",
      "44_CatBoost rmse 0.834111 trained in 62.69 seconds\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble rmse 0.790515 trained in 1.11 seconds\n",
      "AutoML fit time: 1640.84 seconds\n",
      "AutoML best model: Ensemble\n",
      "R^2 Score: 0.6074600368709149\n",
      "RMSE: 0.7457824945449829\n"
     ]
    }
   ],
   "source": [
    "### Employment (log), Spatial Lag, NO building footprints, Birmingham (20)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_bham_lag_poi\n",
    "target = 'log_total_employment'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_bham[features], all_data_bham[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/employment_bham_lag_poi/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_20 = r2_score(y_test, predictions)\n",
    "rmse_20 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_20}')\n",
    "print(f'RMSE: {rmse_20}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_20 = automl.predict(all_data_bham[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': bham_geometries,\n",
    "    'observed': all_data_bham[target],\n",
    "    'predicted': predictions_all_20,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "40f2d5e8-ab8d-4d04-9381-8fa39bc509e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: ml_results/employment_density_london_lag_poi/\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['CatBoost', 'Xgboost', 'Random Forest']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "1_Default_Xgboost rmse 0.752636 trained in 182.62 seconds\n",
      "2_Default_CatBoost rmse 0.741426 trained in 227.56 seconds\n",
      "3_Default_RandomForest rmse 0.856403 trained in 126.46 seconds\n",
      "* Step not_so_random will try to check up to 12 models\n",
      "4_Xgboost rmse 0.764233 trained in 222.06 seconds\n",
      "8_CatBoost rmse 0.742621 trained in 260.06 seconds\n",
      "12_RandomForest rmse 0.85494 trained in 162.99 seconds\n",
      "5_Xgboost rmse 0.768562 trained in 203.36 seconds\n",
      "9_CatBoost rmse 0.766185 trained in 241.98 seconds\n",
      "13_RandomForest rmse 0.87985 trained in 124.03 seconds\n",
      "6_Xgboost rmse 0.75402 trained in 153.64 seconds\n",
      "10_CatBoost rmse 0.744247 trained in 219.68 seconds\n",
      "14_RandomForest rmse 0.82898 trained in 177.22 seconds\n",
      "7_Xgboost rmse 0.758517 trained in 134.69 seconds\n",
      "11_CatBoost rmse 0.78425 trained in 230.48 seconds\n",
      "15_RandomForest rmse 0.827424 trained in 182.48 seconds\n",
      "* Step hill_climbing_1 will try to check up to 17 models\n",
      "16_CatBoost rmse 0.737474 trained in 241.56 seconds\n",
      "17_CatBoost rmse 0.754265 trained in 236.41 seconds\n",
      "18_CatBoost rmse 0.738745 trained in 322.2 seconds\n",
      "19_CatBoost rmse 0.745306 trained in 260.49 seconds\n",
      "20_CatBoost rmse 0.736969 trained in 276.43 seconds\n",
      "21_CatBoost rmse 0.75506 trained in 209.64 seconds\n",
      "22_Xgboost rmse 0.757569 trained in 143.85 seconds\n",
      "23_Xgboost rmse 0.763824 trained in 172.39 seconds\n",
      "24_Xgboost rmse 0.751309 trained in 168.55 seconds\n",
      "25_Xgboost rmse 0.752738 trained in 157.88 seconds\n",
      "26_Xgboost rmse 0.761121 trained in 146.24 seconds\n",
      "27_Xgboost rmse 0.757508 trained in 150.05 seconds\n",
      "28_RandomForest rmse 0.827607 trained in 177.13 seconds\n",
      "29_RandomForest rmse 0.827993 trained in 160.64 seconds\n",
      "30_RandomForest rmse 0.830202 trained in 174.33 seconds\n",
      "31_RandomForest rmse 0.854809 trained in 195.48 seconds\n",
      "32_RandomForest rmse 0.854369 trained in 204.44 seconds\n",
      "Skip hill_climbing_2 because of the time limit.\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble rmse 0.728823 trained in 0.64 seconds\n",
      "AutoML fit time: 6264.44 seconds\n",
      "AutoML best model: Ensemble\n",
      "R^2 Score: 0.6867792694078064\n",
      "RMSE: 0.7651811838150024\n"
     ]
    }
   ],
   "source": [
    "### Employment density (log), Spatial Lag, NO building footprints, London (21)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london_lag_poi\n",
    "target = 'log_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/employment_density_london_lag_poi/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_21 = r2_score(y_test, predictions)\n",
    "rmse_21 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_21}')\n",
    "print(f'RMSE: {rmse_21}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_21 = automl.predict(all_data_london[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': london_geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all_21,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "93b64d0d-1da7-4353-9e1d-eec5d2be71f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: ml_results/employment_density_bham_lag_poi/\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['CatBoost', 'Xgboost', 'Random Forest']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "1_Default_Xgboost rmse 0.910647 trained in 15.7 seconds\n",
      "2_Default_CatBoost rmse 0.87662 trained in 54.19 seconds\n",
      "3_Default_RandomForest rmse 0.905614 trained in 45.36 seconds\n",
      "* Step not_so_random will try to check up to 12 models\n",
      "4_Xgboost rmse 0.864314 trained in 18.83 seconds\n",
      "8_CatBoost rmse 0.903975 trained in 64.34 seconds\n",
      "12_RandomForest rmse 0.907049 trained in 54.09 seconds\n",
      "5_Xgboost rmse 0.953977 trained in 13.77 seconds\n",
      "9_CatBoost rmse 0.944015 trained in 58.04 seconds\n",
      "13_RandomForest rmse 0.9308 trained in 37.84 seconds\n",
      "6_Xgboost rmse 0.887171 trained in 13.35 seconds\n",
      "10_CatBoost rmse 0.904229 trained in 55.68 seconds\n",
      "14_RandomForest rmse 0.901923 trained in 39.85 seconds\n",
      "7_Xgboost rmse 0.941045 trained in 12.1 seconds\n",
      "11_CatBoost rmse 0.94649 trained in 56.35 seconds\n",
      "15_RandomForest rmse 0.915185 trained in 49.99 seconds\n",
      "* Step hill_climbing_1 will try to check up to 18 models\n",
      "16_Xgboost rmse 0.862313 trained in 17.23 seconds\n",
      "17_Xgboost rmse 0.87156 trained in 22.55 seconds\n",
      "18_CatBoost rmse 0.866242 trained in 56.29 seconds\n",
      "19_CatBoost rmse 0.889794 trained in 55.87 seconds\n",
      "20_Xgboost rmse 0.876888 trained in 14.91 seconds\n",
      "21_Xgboost rmse 0.884896 trained in 13.06 seconds\n",
      "22_RandomForest rmse 0.896821 trained in 39.82 seconds\n",
      "23_RandomForest rmse 0.900662 trained in 38.73 seconds\n",
      "24_CatBoost rmse 0.899602 trained in 74.47 seconds\n",
      "25_CatBoost rmse 0.905726 trained in 64.46 seconds\n",
      "26_CatBoost rmse 0.889619 trained in 59.48 seconds\n",
      "27_CatBoost rmse 0.911123 trained in 55.55 seconds\n",
      "28_RandomForest rmse 0.898307 trained in 41.98 seconds\n",
      "29_RandomForest rmse 0.910859 trained in 43.08 seconds\n",
      "30_RandomForest rmse 0.898884 trained in 50.49 seconds\n",
      "31_RandomForest rmse 0.915825 trained in 51.97 seconds\n",
      "32_Xgboost rmse 0.885413 trained in 15.48 seconds\n",
      "33_Xgboost rmse 0.920969 trained in 15.97 seconds\n",
      "* Step hill_climbing_2 will try to check up to 9 models\n",
      "34_Xgboost rmse 0.85756 trained in 16.75 seconds\n",
      "35_Xgboost rmse 0.873338 trained in 21.12 seconds\n",
      "36_CatBoost rmse 0.86743 trained in 59.03 seconds\n",
      "37_Xgboost rmse 0.862614 trained in 21.29 seconds\n",
      "38_CatBoost rmse 0.881796 trained in 65.26 seconds\n",
      "39_RandomForest rmse 0.893383 trained in 50.33 seconds\n",
      "40_RandomForest rmse 0.906553 trained in 47.88 seconds\n",
      "41_RandomForest rmse 0.904923 trained in 54.38 seconds\n",
      "42_RandomForest rmse 0.902329 trained in 43.92 seconds\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble rmse 0.841826 trained in 1.03 seconds\n",
      "AutoML fit time: 1721.79 seconds\n",
      "AutoML best model: Ensemble\n",
      "R^2 Score: 0.4910254459863381\n",
      "RMSE: 0.7559847831726074\n"
     ]
    }
   ],
   "source": [
    "### Employment density (log), Spatial Lag, NO building footprints, Birmingham (22)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_bham_lag_poi\n",
    "target = 'log_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_bham[features], all_data_bham[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/employment_density_bham_lag_poi/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_22 = r2_score(y_test, predictions)\n",
    "rmse_22 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_22}')\n",
    "print(f'RMSE: {rmse_22}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_22 = automl.predict(all_data_bham[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': bham_geometries,\n",
    "    'observed': all_data_bham[target],\n",
    "    'predicted': predictions_all_22,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "85017eb0-6561-4e24-b5be-040f01e41dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: ml_results/office_employment_density_london_lag_poi/\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['CatBoost', 'Xgboost', 'Random Forest']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "1_Default_Xgboost rmse 1.538698 trained in 152.26 seconds\n",
      "2_Default_CatBoost rmse 1.522154 trained in 229.66 seconds\n",
      "3_Default_RandomForest rmse 1.609395 trained in 133.37 seconds\n",
      "* Step not_so_random will try to check up to 12 models\n",
      "4_Xgboost rmse 1.554216 trained in 138.95 seconds\n",
      "8_CatBoost rmse 1.516223 trained in 239.88 seconds\n",
      "12_RandomForest rmse 1.601996 trained in 155.01 seconds\n",
      "5_Xgboost rmse 1.556924 trained in 162.92 seconds\n",
      "9_CatBoost rmse 1.557065 trained in 233.53 seconds\n",
      "13_RandomForest rmse 1.62409 trained in 167.7 seconds\n",
      "6_Xgboost rmse 1.530984 trained in 136.86 seconds\n",
      "10_CatBoost rmse 1.514937 trained in 236.04 seconds\n",
      "14_RandomForest rmse 1.595682 trained in 150.96 seconds\n",
      "7_Xgboost rmse 1.550613 trained in 157.51 seconds\n",
      "11_CatBoost rmse 1.56983 trained in 240.59 seconds\n",
      "15_RandomForest rmse 1.58642 trained in 172.97 seconds\n",
      "* Step hill_climbing_1 will try to check up to 17 models\n",
      "16_CatBoost rmse 1.506885 trained in 236.01 seconds\n",
      "17_CatBoost rmse 1.53877 trained in 197.15 seconds\n",
      "18_CatBoost rmse 1.507945 trained in 276.0 seconds\n",
      "19_CatBoost rmse 1.511104 trained in 238.46 seconds\n",
      "20_CatBoost rmse 1.513759 trained in 224.59 seconds\n",
      "21_CatBoost rmse 1.54044 trained in 209.71 seconds\n",
      "22_Xgboost rmse 1.526683 trained in 163.33 seconds\n",
      "23_Xgboost rmse 1.534471 trained in 145.97 seconds\n",
      "24_Xgboost rmse 1.52967 trained in 149.53 seconds\n",
      "25_Xgboost rmse 1.545443 trained in 136.86 seconds\n",
      "26_Xgboost rmse 1.547026 trained in 129.9 seconds\n",
      "27_Xgboost rmse 1.544924 trained in 129.77 seconds\n",
      "28_RandomForest rmse 1.586325 trained in 176.7 seconds\n",
      "29_RandomForest rmse 1.596112 trained in 139.75 seconds\n",
      "30_RandomForest rmse 1.596482 trained in 151.64 seconds\n",
      "31_RandomForest rmse 1.601501 trained in 158.19 seconds\n",
      "32_RandomForest rmse 1.602008 trained in 140.11 seconds\n",
      "Skip hill_climbing_2 because of the time limit.\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble rmse 1.49709 trained in 0.66 seconds\n",
      "AutoML fit time: 5729.53 seconds\n",
      "AutoML best model: Ensemble\n",
      "R^2 Score: 0.4997767941002238\n",
      "RMSE: 1.4975266456604004\n"
     ]
    }
   ],
   "source": [
    "### Office Employment Density (log), Spatial Lag, NO building footprints, London (23)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london_lag_poi\n",
    "target = 'log_office_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/office_employment_density_london_lag_poi/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_23 = r2_score(y_test, predictions)\n",
    "rmse_23 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_23}')\n",
    "print(f'RMSE: {rmse_23}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_23 = automl.predict(all_data_london[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': london_geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all_23,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "02f9d2cc-5125-442c-a25c-e1ec7e645a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: ml_results/office_employment_density_bham_lag_poi/\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['CatBoost', 'Xgboost', 'Random Forest']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "1_Default_Xgboost rmse 2.005497 trained in 17.1 seconds\n",
      "2_Default_CatBoost rmse 2.001502 trained in 54.7 seconds\n",
      "3_Default_RandomForest rmse 1.997111 trained in 51.12 seconds\n",
      "* Step not_so_random will try to check up to 12 models\n",
      "4_Xgboost rmse 2.04148 trained in 15.99 seconds\n",
      "8_CatBoost rmse 2.035985 trained in 58.98 seconds\n",
      "12_RandomForest rmse 1.980989 trained in 45.21 seconds\n",
      "5_Xgboost rmse 2.074815 trained in 13.59 seconds\n",
      "9_CatBoost rmse 2.043254 trained in 57.29 seconds\n",
      "13_RandomForest rmse 2.018145 trained in 48.2 seconds\n",
      "6_Xgboost rmse 1.995506 trained in 13.0 seconds\n",
      "10_CatBoost rmse 1.99914 trained in 55.95 seconds\n",
      "14_RandomForest rmse 1.97435 trained in 37.35 seconds\n",
      "7_Xgboost rmse 2.001806 trained in 12.4 seconds\n",
      "11_CatBoost rmse 2.11654 trained in 56.68 seconds\n",
      "15_RandomForest rmse 1.986255 trained in 54.13 seconds\n",
      "* Step hill_climbing_1 will try to check up to 17 models\n",
      "16_RandomForest rmse 1.975948 trained in 37.28 seconds\n",
      "17_RandomForest rmse 1.984551 trained in 36.49 seconds\n",
      "18_RandomForest rmse 1.979318 trained in 44.27 seconds\n",
      "19_RandomForest rmse 1.986329 trained in 45.17 seconds\n",
      "20_RandomForest rmse 1.979731 trained in 48.33 seconds\n",
      "21_Xgboost rmse 1.987151 trained in 11.69 seconds\n",
      "22_Xgboost rmse 1.993863 trained in 12.51 seconds\n",
      "23_CatBoost rmse 1.992465 trained in 56.56 seconds\n",
      "24_CatBoost rmse 2.013744 trained in 55.15 seconds\n",
      "25_CatBoost rmse 1.991441 trained in 55.81 seconds\n",
      "26_CatBoost rmse 2.011078 trained in 54.1 seconds\n",
      "27_Xgboost rmse 2.001806 trained in 13.87 seconds\n",
      "28_Xgboost rmse 2.001806 trained in 12.26 seconds\n",
      "29_Xgboost rmse 1.980066 trained in 12.92 seconds\n",
      "30_Xgboost rmse 2.055428 trained in 12.93 seconds\n",
      "31_CatBoost rmse 2.00903 trained in 63.68 seconds\n",
      "32_CatBoost rmse 1.997992 trained in 56.86 seconds\n",
      "* Step hill_climbing_2 will try to check up to 10 models\n",
      "33_RandomForest rmse 1.977964 trained in 39.91 seconds\n",
      "34_Xgboost rmse 1.976041 trained in 13.35 seconds\n",
      "35_Xgboost rmse 1.993338 trained in 12.83 seconds\n",
      "36_Xgboost rmse 1.999415 trained in 12.95 seconds\n",
      "37_CatBoost rmse 1.994439 trained in 56.16 seconds\n",
      "38_CatBoost rmse 2.017921 trained in 58.3 seconds\n",
      "39_Xgboost rmse 1.997912 trained in 13.3 seconds\n",
      "40_Xgboost rmse 1.977016 trained in 13.03 seconds\n",
      "41_CatBoost rmse 2.026696 trained in 57.52 seconds\n",
      "42_CatBoost rmse 2.020552 trained in 57.81 seconds\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble rmse 1.934671 trained in 1.07 seconds\n",
      "AutoML fit time: 1577.93 seconds\n",
      "AutoML best model: Ensemble\n",
      "R^2 Score: 0.34337548837251874\n",
      "RMSE: 1.9713027477264404\n"
     ]
    }
   ],
   "source": [
    "### Office Employment Density (log), Spatial Lag, NO building footprints, Birmingham (24)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_bham_lag_poi\n",
    "target = 'log_office_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_bham[features], all_data_bham[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/office_employment_density_bham_lag_poi/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_24 = r2_score(y_test, predictions)\n",
    "rmse_24 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_24}')\n",
    "print(f'RMSE: {rmse_24}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_24 = automl.predict(all_data_bham[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': bham_geometries,\n",
    "    'observed': all_data_bham[target],\n",
    "    'predicted': predictions_all_24,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024e2553-1a43-4da2-ac78-f84b9536d8ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "95b4bac7-1f3e-4b26-9a31-6014e0048a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model has already been fitted. You can use predict methods or select a new 'results_path' for a new 'fit()'.\n",
      "R^2 Score: 0.7102393476371849\n",
      "RMSE: 0.6910015940666199\n"
     ]
    }
   ],
   "source": [
    "### Employment (log), NO Spatial Lag, London,  POI EXCLUSIVE (25)\n",
    "\n",
    "# Ignore depracation warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london_poi = [column for column in feature_columns_london_poi if column != 'log_num_places']\n",
    "target = 'log_total_employment'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/poi_exclusive_london/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_25 = r2_score(y_test, predictions)\n",
    "rmse_25 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_25}')\n",
    "print(f'RMSE: {rmse_25}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_25 = automl.predict(all_data_london[features])\n",
    "\n",
    "results_london_poi = pd.DataFrame({\n",
    "    'name': london_names,\n",
    "    'geometry': london_geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all_25,\n",
    "})\n",
    "\n",
    "# Save to project folder\n",
    "results_london_poi.to_csv(\"data/combined_data/model_results_london_poi.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "37b651d4-c97d-41b2-86ed-5cce34f30be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model has already been fitted. You can use predict methods or select a new 'results_path' for a new 'fit()'.\n",
      "R^2 Score: 0.6226217466175756\n",
      "RMSE: 0.7312378883361816\n"
     ]
    }
   ],
   "source": [
    "### Employment (log), NO Spatial Lag, Birmingham, POI EXCLUSIVE (26)\n",
    "\n",
    "# Ignore depracation warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_bham_poi = [column for column in feature_columns_bham_poi if column != 'log_num_places']\n",
    "target = 'log_total_employment'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_bham[features], all_data_bham[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/poi_exclusive_bham/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_26 = r2_score(y_test, predictions)\n",
    "rmse_26 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_26}')\n",
    "print(f'RMSE: {rmse_26}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_26 = automl.predict(all_data_bham[features])\n",
    "\n",
    "results_bham_poi = pd.DataFrame({\n",
    "    'name': bham_names,\n",
    "    'geometry': bham_geometries,\n",
    "    'observed': all_data_bham[target],\n",
    "    'predicted': predictions_all_26,\n",
    "})\n",
    "\n",
    "# Save to project folder\n",
    "results_bham_poi.to_csv(\"data/combined_data/model_results_bham_poi.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bd9e4b08-aeb6-45c8-bb64-1d5cce0c8e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: ml_results/poi_exclusive_london_density/\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['CatBoost', 'Xgboost', 'Random Forest']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "1_Default_Xgboost rmse 0.810964 trained in 38.17 seconds\n",
      "2_Default_CatBoost rmse 0.784844 trained in 49.5 seconds\n",
      "3_Default_RandomForest rmse 0.922467 trained in 76.45 seconds\n",
      "* Step not_so_random will try to check up to 12 models\n",
      "4_Xgboost rmse 0.815659 trained in 37.39 seconds\n",
      "8_CatBoost rmse 0.782558 trained in 60.3 seconds\n",
      "12_RandomForest rmse 0.918514 trained in 44.62 seconds\n",
      "5_Xgboost rmse 0.826209 trained in 37.36 seconds\n",
      "9_CatBoost rmse 0.799203 trained in 54.8 seconds\n",
      "13_RandomForest rmse 0.944806 trained in 43.15 seconds\n",
      "6_Xgboost rmse 0.789962 trained in 35.22 seconds\n",
      "10_CatBoost rmse 0.785354 trained in 50.11 seconds\n",
      "14_RandomForest rmse 0.894304 trained in 78.62 seconds\n",
      "7_Xgboost rmse 0.806051 trained in 34.57 seconds\n",
      "11_CatBoost rmse 0.813929 trained in 51.25 seconds\n",
      "15_RandomForest rmse 0.89239 trained in 71.2 seconds\n",
      "* Step hill_climbing_1 will try to check up to 17 models\n",
      "16_CatBoost rmse 0.782005 trained in 79.87 seconds\n",
      "17_CatBoost rmse 0.787997 trained in 52.58 seconds\n",
      "18_CatBoost rmse 0.783175 trained in 53.56 seconds\n",
      "19_CatBoost rmse 0.79305 trained in 47.71 seconds\n",
      "20_CatBoost rmse 0.784556 trained in 56.41 seconds\n",
      "21_CatBoost rmse 0.793598 trained in 45.97 seconds\n",
      "22_Xgboost rmse 0.793357 trained in 37.39 seconds\n",
      "23_Xgboost rmse 0.795993 trained in 36.49 seconds\n",
      "24_Xgboost rmse 0.803563 trained in 33.78 seconds\n",
      "25_Xgboost rmse 0.808658 trained in 34.27 seconds\n",
      "26_Xgboost rmse 0.806011 trained in 38.94 seconds\n",
      "27_Xgboost rmse 0.820999 trained in 39.72 seconds\n",
      "28_RandomForest rmse 0.890201 trained in 76.49 seconds\n",
      "29_RandomForest rmse 0.893161 trained in 62.78 seconds\n",
      "30_RandomForest rmse 0.894961 trained in 80.65 seconds\n",
      "31_RandomForest rmse 0.918474 trained in 47.4 seconds\n",
      "32_RandomForest rmse 0.919341 trained in 49.44 seconds\n",
      "* Step hill_climbing_2 will try to check up to 13 models\n",
      "33_CatBoost rmse 0.780313 trained in 78.86 seconds\n",
      "34_CatBoost rmse 0.782959 trained in 74.06 seconds\n",
      "35_CatBoost rmse 0.784423 trained in 63.61 seconds\n",
      "36_CatBoost rmse 0.786228 trained in 64.7 seconds\n",
      "37_CatBoost rmse 0.781632 trained in 56.45 seconds\n",
      "38_Xgboost rmse 0.791058 trained in 36.2 seconds\n",
      "39_Xgboost rmse 0.794357 trained in 38.32 seconds\n",
      "40_Xgboost rmse 0.793191 trained in 35.09 seconds\n",
      "41_Xgboost rmse 0.79203 trained in 36.97 seconds\n",
      "42_Xgboost rmse 0.794065 trained in 36.27 seconds\n",
      "43_Xgboost rmse 0.795749 trained in 38.16 seconds\n",
      "44_RandomForest rmse 0.889359 trained in 79.62 seconds\n",
      "45_RandomForest rmse 0.891102 trained in 81.87 seconds\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble rmse 0.775016 trained in 1.27 seconds\n",
      "AutoML fit time: 2380.85 seconds\n",
      "AutoML best model: Ensemble\n",
      "R^2 Score: 0.6533896491167754\n",
      "RMSE: 0.8049330711364746\n"
     ]
    }
   ],
   "source": [
    "### Employment Density, NO Spatial Lag, London,  POI EXCLUSIVE (27)\n",
    "\n",
    "# Ignore depracation warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london_poi = [column for column in feature_columns_london_poi if column != 'log_num_places']\n",
    "target = 'log_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/poi_exclusive_london_density/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_27 = r2_score(y_test, predictions)\n",
    "rmse_27 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_27}')\n",
    "print(f'RMSE: {rmse_27}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_27 = automl.predict(all_data_london[features])\n",
    "\n",
    "results_london_poi_density = pd.DataFrame({\n",
    "    'name': london_names,\n",
    "    'geometry': london_geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all_27,\n",
    "})\n",
    "\n",
    "# Save to project folder\n",
    "results_london_poi_density.to_csv(\"data/combined_data/model_results_london_poi_density.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "44b6d36b-2df9-4a0b-87ae-1873ca72ce4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: ml_results/poi_exclusive_bham_density/\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['CatBoost', 'Xgboost', 'Random Forest']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "1_Default_Xgboost rmse 0.975145 trained in 6.78 seconds\n",
      "2_Default_CatBoost rmse 0.937522 trained in 14.95 seconds\n",
      "3_Default_RandomForest rmse 1.024099 trained in 19.68 seconds\n",
      "* Step not_so_random will try to check up to 12 models\n",
      "4_Xgboost rmse 0.943804 trained in 7.71 seconds\n",
      "8_CatBoost rmse 0.937614 trained in 21.5 seconds\n",
      "12_RandomForest rmse 0.991453 trained in 27.94 seconds\n",
      "5_Xgboost rmse 0.968603 trained in 6.12 seconds\n",
      "9_CatBoost rmse 0.978892 trained in 16.57 seconds\n",
      "13_RandomForest rmse 1.013362 trained in 22.69 seconds\n",
      "6_Xgboost rmse 0.917803 trained in 5.51 seconds\n",
      "10_CatBoost rmse 0.925068 trained in 16.49 seconds\n",
      "14_RandomForest rmse 0.989257 trained in 24.4 seconds\n",
      "7_Xgboost rmse 0.962869 trained in 5.37 seconds\n",
      "11_CatBoost rmse 0.986487 trained in 16.26 seconds\n",
      "15_RandomForest rmse 0.988078 trained in 20.75 seconds\n",
      "* Step hill_climbing_1 will try to check up to 17 models\n",
      "16_Xgboost rmse 0.91278 trained in 5.57 seconds\n",
      "17_Xgboost rmse 0.917388 trained in 5.61 seconds\n",
      "18_CatBoost rmse 0.934811 trained in 17.02 seconds\n",
      "19_CatBoost rmse 0.938406 trained in 14.95 seconds\n",
      "20_CatBoost rmse 0.922229 trained in 16.14 seconds\n",
      "21_CatBoost rmse 0.911272 trained in 14.32 seconds\n",
      "22_CatBoost rmse 0.936983 trained in 24.27 seconds\n",
      "23_CatBoost rmse 0.94866 trained in 15.92 seconds\n",
      "24_Xgboost rmse 0.945933 trained in 5.83 seconds\n",
      "25_Xgboost rmse 0.95309 trained in 5.71 seconds\n",
      "26_Xgboost rmse 0.962869 trained in 5.14 seconds\n",
      "27_Xgboost rmse 0.962869 trained in 5.09 seconds\n",
      "28_RandomForest rmse 0.971845 trained in 18.55 seconds\n",
      "29_RandomForest rmse 0.983719 trained in 24.0 seconds\n",
      "30_RandomForest rmse 1.001778 trained in 19.56 seconds\n",
      "31_RandomForest rmse 0.989677 trained in 22.12 seconds\n",
      "32_RandomForest rmse 0.994138 trained in 21.7 seconds\n",
      "* Step hill_climbing_2 will try to check up to 11 models\n",
      "33_CatBoost rmse 0.943723 trained in 13.39 seconds\n",
      "34_Xgboost rmse 0.915886 trained in 5.67 seconds\n",
      "35_Xgboost rmse 0.920153 trained in 5.43 seconds\n",
      "36_Xgboost rmse 0.909613 trained in 5.57 seconds\n",
      "37_Xgboost rmse 0.918225 trained in 5.58 seconds\n",
      "38_Xgboost rmse 0.910053 trained in 5.6 seconds\n",
      "39_Xgboost rmse 0.918646 trained in 5.49 seconds\n",
      "40_CatBoost rmse 0.926369 trained in 15.81 seconds\n",
      "41_CatBoost rmse 0.919264 trained in 14.9 seconds\n",
      "42_RandomForest rmse 0.966653 trained in 18.78 seconds\n",
      "43_RandomForest rmse 0.981085 trained in 18.97 seconds\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble rmse 0.887897 trained in 1.08 seconds\n",
      "AutoML fit time: 609.74 seconds\n",
      "AutoML best model: Ensemble\n",
      "R^2 Score: 0.5370231689967291\n",
      "RMSE: 0.7210155725479126\n"
     ]
    }
   ],
   "source": [
    "### Employment Density, NO Spatial Lag, Birmingham, POI EXCLUSIVE (28)\n",
    "\n",
    "# Ignore depracation warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_bham_poi = [column for column in feature_columns_bham_poi if column != 'log_num_places']\n",
    "target = 'log_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_bham[features], all_data_bham[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/poi_exclusive_bham_density/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_28 = r2_score(y_test, predictions)\n",
    "rmse_28 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_28}')\n",
    "print(f'RMSE: {rmse_28}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_28 = automl.predict(all_data_bham[features])\n",
    "\n",
    "results_bham_poi_density = pd.DataFrame({\n",
    "    'name': bham_names,\n",
    "    'geometry': bham_geometries,\n",
    "    'observed': all_data_bham[target],\n",
    "    'predicted': predictions_all_28,\n",
    "})\n",
    "\n",
    "# Save to project folder\n",
    "results_bham_poi_density.to_csv(\"data/combined_data/model_results_bham_poi_density.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e4dfa3-da73-4d14-8fc5-b121ae958d42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "27713eaa-20a6-4da1-81a1-c5fa18748288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: ml_results/poi_exclusive_london_office_density/\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['CatBoost', 'Xgboost', 'Random Forest']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "1_Default_Xgboost rmse 1.594738 trained in 35.25 seconds\n",
      "2_Default_CatBoost rmse 1.579013 trained in 46.64 seconds\n",
      "3_Default_RandomForest rmse 1.690103 trained in 48.36 seconds\n",
      "* Step not_so_random will try to check up to 12 models\n",
      "4_Xgboost rmse 1.606491 trained in 34.34 seconds\n",
      "8_CatBoost rmse 1.579068 trained in 55.67 seconds\n",
      "12_RandomForest rmse 1.687728 trained in 65.8 seconds\n",
      "5_Xgboost rmse 1.608838 trained in 34.87 seconds\n",
      "9_CatBoost rmse 1.602372 trained in 60.39 seconds\n",
      "13_RandomForest rmse 1.710323 trained in 56.55 seconds\n",
      "6_Xgboost rmse 1.582432 trained in 34.52 seconds\n",
      "10_CatBoost rmse 1.580143 trained in 47.35 seconds\n",
      "14_RandomForest rmse 1.670511 trained in 62.47 seconds\n",
      "7_Xgboost rmse 1.594581 trained in 32.62 seconds\n",
      "11_CatBoost rmse 1.605527 trained in 51.13 seconds\n",
      "15_RandomForest rmse 1.66745 trained in 44.07 seconds\n",
      "* Step hill_climbing_1 will try to check up to 17 models\n",
      "16_CatBoost rmse 1.577853 trained in 53.1 seconds\n",
      "17_CatBoost rmse 1.582704 trained in 45.8 seconds\n",
      "18_CatBoost rmse 1.57806 trained in 68.93 seconds\n",
      "19_CatBoost rmse 1.58344 trained in 50.77 seconds\n",
      "20_CatBoost rmse 1.574759 trained in 54.32 seconds\n",
      "21_CatBoost rmse 1.590421 trained in 45.71 seconds\n",
      "22_Xgboost rmse 1.580199 trained in 34.08 seconds\n",
      "23_Xgboost rmse 1.586017 trained in 34.69 seconds\n",
      "24_Xgboost rmse 1.596831 trained in 32.83 seconds\n",
      "25_Xgboost rmse 1.602461 trained in 33.71 seconds\n",
      "26_Xgboost rmse 1.597827 trained in 35.54 seconds\n",
      "27_Xgboost rmse 1.602149 trained in 35.48 seconds\n",
      "28_RandomForest rmse 1.667361 trained in 52.1 seconds\n",
      "29_RandomForest rmse 1.668948 trained in 58.67 seconds\n",
      "30_RandomForest rmse 1.672382 trained in 66.56 seconds\n",
      "31_RandomForest rmse 1.687761 trained in 68.45 seconds\n",
      "32_RandomForest rmse 1.687699 trained in 67.81 seconds\n",
      "* Step hill_climbing_2 will try to check up to 12 models\n",
      "33_CatBoost rmse 1.580285 trained in 53.11 seconds\n",
      "34_CatBoost rmse 1.577076 trained in 53.38 seconds\n",
      "35_CatBoost rmse 1.579149 trained in 67.27 seconds\n",
      "36_CatBoost rmse 1.577012 trained in 68.87 seconds\n",
      "37_Xgboost rmse 1.58112 trained in 33.54 seconds\n",
      "38_Xgboost rmse 1.580098 trained in 32.93 seconds\n",
      "39_Xgboost rmse 1.583197 trained in 34.21 seconds\n",
      "40_Xgboost rmse 1.58596 trained in 35.02 seconds\n",
      "41_Xgboost rmse 1.582843 trained in 36.1 seconds\n",
      "42_Xgboost rmse 1.585032 trained in 35.14 seconds\n",
      "43_RandomForest rmse 1.666481 trained in 49.48 seconds\n",
      "44_RandomForest rmse 1.667508 trained in 80.49 seconds\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble rmse 1.560889 trained in 1.2 seconds\n",
      "AutoML fit time: 2151.26 seconds\n",
      "AutoML best model: Ensemble\n",
      "R^2 Score: 0.4520162646651782\n",
      "RMSE: 1.5673878192901611\n"
     ]
    }
   ],
   "source": [
    "### Office Employment Density, NO Spatial Lag, London, POI EXCLUSIVE (29)\n",
    "\n",
    "# Ignore depracation warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london_poi = [column for column in feature_columns_london_poi if column != 'log_num_places']\n",
    "target = 'log_office_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/poi_exclusive_london_office_density/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_29 = r2_score(y_test, predictions)\n",
    "rmse_29 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_29}')\n",
    "print(f'RMSE: {rmse_29}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_29 = automl.predict(all_data_london[features])\n",
    "\n",
    "results_london_poi_density = pd.DataFrame({\n",
    "    'name': london_names,\n",
    "    'geometry': london_geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all_29,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4e10c011-c997-4083-9127-b16785ecdb0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model has already been fitted. You can use predict methods or select a new 'results_path' for a new 'fit()'.\n",
      "R^2 Score: -0.7215788525223636\n",
      "RMSE: 3.1919658184051514\n"
     ]
    }
   ],
   "source": [
    "### Office Employment Density, NO Spatial Lag, Birmingham, POI EXCLUSIVE (30)\n",
    "\n",
    "# Ignore depracation warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_bham_poi = [column for column in feature_columns_bham_poi if column != 'log_num_places']\n",
    "target = 'log_office_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_bham[features], all_data_bham[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/poi_exclusive_bham_density/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_30 = r2_score(y_test, predictions)\n",
    "rmse_30 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_30}')\n",
    "print(f'RMSE: {rmse_30}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_30 = automl.predict(all_data_bham[features])\n",
    "\n",
    "results_bham_poi_density = pd.DataFrame({\n",
    "    'name': bham_names,\n",
    "    'geometry': bham_geometries,\n",
    "    'observed': all_data_bham[target],\n",
    "    'predicted': predictions_all_30,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd967e5-3123-4999-9f46-ab6c3163dcce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8c6f365-e57a-46df-a647-bff37403536c",
   "metadata": {},
   "source": [
    "### Attempt with Demographic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "97be3f20-5d83-4bc7-bb9b-a04f33adc25c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LSOA11CD</th>\n",
       "      <th>LSOA11NM</th>\n",
       "      <th>Index of Multiple Deprivation (IMD) Rank</th>\n",
       "      <th>Index of Multiple Deprivation (IMD) Decile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E01000001</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>29,199</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E01000002</td>\n",
       "      <td>City of London 001B</td>\n",
       "      <td>30,379</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E01000003</td>\n",
       "      <td>City of London 001C</td>\n",
       "      <td>14,915</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E01000005</td>\n",
       "      <td>City of London 001E</td>\n",
       "      <td>8,678</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E01000006</td>\n",
       "      <td>Barking and Dagenham 016A</td>\n",
       "      <td>14,486</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    LSOA11CD                   LSOA11NM  \\\n",
       "0  E01000001        City of London 001A   \n",
       "1  E01000002        City of London 001B   \n",
       "2  E01000003        City of London 001C   \n",
       "3  E01000005        City of London 001E   \n",
       "4  E01000006  Barking and Dagenham 016A   \n",
       "\n",
       "  Index of Multiple Deprivation (IMD) Rank  \\\n",
       "0                                   29,199   \n",
       "1                                   30,379   \n",
       "2                                   14,915   \n",
       "3                                    8,678   \n",
       "4                                   14,486   \n",
       "\n",
       "   Index of Multiple Deprivation (IMD) Decile  \n",
       "0                                           9  \n",
       "1                                          10  \n",
       "2                                           5  \n",
       "3                                           3  \n",
       "4                                           5  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Same Analysis on Education, Employment Status, and Multiple Deprivation Data\n",
    "\n",
    "general_health = pd.read_csv(\"data/lsoa_data/TS037_general_health.csv\", skiprows = 7, header = 0)\n",
    "employment_residential = pd.read_csv(\"data/lsoa_data/TS066_economic_activity_status.csv\", skiprows = 7, header = 0)\n",
    "education = pd.read_csv(\"data/lsoa_data/TS067_highest_qualification.csv\", skiprows = 7, header = 0)\n",
    "household_comp = pd.read_csv(\"data/lsoa_data/TS003_household_composition.csv\", skiprows = 6, header = 0)\n",
    "age_bands = pd.read_csv(\"data/lsoa_data/TS007B_age_broad_band.csv\", skiprows = 4, header = 0)\n",
    "english_lang = pd.read_csv(\"data/lsoa_data/TS029_english_language.csv\", skiprows = 6, header = 0)\n",
    "\n",
    "#Separate name into LSOA11CD and LSOA11NM (taken from DataCleaning.ipynb)\n",
    "def split_column(value):\n",
    "    if isinstance(value, str):\n",
    "        code, name = value.split(' : ')\n",
    "        return code.strip(), name.strip()\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "# Parse Code and Name out\n",
    "general_health[['LSOA11CD', 'LSOA11NM']] = general_health['2021 super output area - lower layer'].apply(lambda x: pd.Series(split_column(x)))\n",
    "employment_residential[['LSOA11CD', 'LSOA11NM']] = employment_residential['2021 super output area - lower layer'].apply(lambda x: pd.Series(split_column(x)))\n",
    "education[['LSOA11CD', 'LSOA11NM']] = education['2021 super output area - lower layer'].apply(lambda x: pd.Series(split_column(x)))\n",
    "household_comp[['LSOA11CD', 'LSOA11NM']] = household_comp['2021 super output area - lower layer'].apply(lambda x: pd.Series(split_column(x)))\n",
    "age_bands[['LSOA11CD', 'LSOA11NM']] = age_bands['2021 super output area - lower layer'].apply(lambda x: pd.Series(split_column(x)))\n",
    "english_lang[['LSOA11CD', 'LSOA11NM']] = english_lang['2021 super output area - lower layer'].apply(lambda x: pd.Series(split_column(x)))\n",
    "\n",
    "# Drop original column\n",
    "general_health = general_health.drop(columns=['2021 super output area - lower layer'])\n",
    "employment_residential = employment_residential.drop(columns=['2021 super output area - lower layer'])\n",
    "education = education.drop(columns=['2021 super output area - lower layer'])\n",
    "household_comp = household_comp.drop(columns=['2021 super output area - lower layer'])\n",
    "age_bands = age_bands.drop(columns=['2021 super output area - lower layer'])\n",
    "english_lang = english_lang.drop(columns=['2021 super output area - lower layer'])\n",
    "\n",
    "\n",
    "multiple_deprivation = pd.read_csv(\"data/lsoa_data/multiple_deprivation.csv\", header = 0)\n",
    "multiple_deprivation.rename(columns = {'LSOA code (2011)':'LSOA11CD', 'LSOA name (2011)':'LSOA11NM'}, inplace=True)\n",
    "multiple_deprivation = multiple_deprivation.drop(columns=[\"Local Authority District code (2019)\", \"Local Authority District name (2019)\"])\n",
    "\n",
    "\n",
    "multiple_deprivation.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "71b41bad-159d-47f7-bac9-3979d29972ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total: All usual residents</th>\n",
       "      <th>Very good health</th>\n",
       "      <th>Good health</th>\n",
       "      <th>Fair health</th>\n",
       "      <th>Bad health</th>\n",
       "      <th>Very bad health</th>\n",
       "      <th>LSOA11CD</th>\n",
       "      <th>LSOA11NM</th>\n",
       "      <th>Total: All usual residents aged 16 years and over</th>\n",
       "      <th>Economically active (excluding full-time students)</th>\n",
       "      <th>...</th>\n",
       "      <th>lag_veterinarian</th>\n",
       "      <th>lag_videographer</th>\n",
       "      <th>lag_vitamins_and_supplements</th>\n",
       "      <th>lag_warehouses</th>\n",
       "      <th>lag_waterproofing</th>\n",
       "      <th>lag_waxing</th>\n",
       "      <th>lag_wholesale_grocer</th>\n",
       "      <th>lag_wildlife_sanctuary</th>\n",
       "      <th>lag_wills_trusts_and_probate</th>\n",
       "      <th>lag_winery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>58.2</td>\n",
       "      <td>31.7</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>100.0</td>\n",
       "      <td>65.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100.0</td>\n",
       "      <td>60.4</td>\n",
       "      <td>30.6</td>\n",
       "      <td>6.7</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>E01000002</td>\n",
       "      <td>City of London 001B</td>\n",
       "      <td>100.0</td>\n",
       "      <td>69.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>36.4</td>\n",
       "      <td>11.5</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>E01000003</td>\n",
       "      <td>City of London 001C</td>\n",
       "      <td>100.0</td>\n",
       "      <td>70.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.0</td>\n",
       "      <td>45.5</td>\n",
       "      <td>35.3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>E01000005</td>\n",
       "      <td>City of London 001E</td>\n",
       "      <td>100.0</td>\n",
       "      <td>55.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100.0</td>\n",
       "      <td>64.6</td>\n",
       "      <td>28.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>E01032739</td>\n",
       "      <td>City of London 001F</td>\n",
       "      <td>100.0</td>\n",
       "      <td>78.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1177 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Total: All usual residents  Very good health  Good health  Fair health  \\\n",
       "0                      100.0              58.2         31.7          8.1   \n",
       "1                      100.0              60.4         30.6          6.7   \n",
       "2                      100.0              49.0         36.4         11.5   \n",
       "3                      100.0              45.5         35.3         12.0   \n",
       "4                      100.0              64.6         28.8          4.9   \n",
       "\n",
       "   Bad health  Very bad health   LSOA11CD             LSOA11NM  \\\n",
       "0         1.2              0.7  E01000001  City of London 001A   \n",
       "1         1.7              0.6  E01000002  City of London 001B   \n",
       "2         2.7              0.4  E01000003  City of London 001C   \n",
       "3         5.7              1.5  E01000005  City of London 001E   \n",
       "4         1.5              0.1  E01032739  City of London 001F   \n",
       "\n",
       "  Total: All usual residents aged 16 years and over  \\\n",
       "0                                             100.0   \n",
       "1                                             100.0   \n",
       "2                                             100.0   \n",
       "3                                             100.0   \n",
       "4                                             100.0   \n",
       "\n",
       "   Economically active (excluding full-time students)  ...  lag_veterinarian  \\\n",
       "0                                               65.7   ...          0.166667   \n",
       "1                                               69.3   ...          0.000000   \n",
       "2                                               70.3   ...          0.166667   \n",
       "3                                               55.8   ...          0.000000   \n",
       "4                                               78.4   ...          0.000000   \n",
       "\n",
       "   lag_videographer  lag_vitamins_and_supplements  lag_warehouses  \\\n",
       "0          0.333333                      0.000000        0.166667   \n",
       "1          0.000000                      0.333333        0.833333   \n",
       "2          0.166667                      0.000000        0.500000   \n",
       "3          0.000000                      0.000000        0.166667   \n",
       "4          0.000000                      0.000000        0.333333   \n",
       "\n",
       "   lag_waterproofing  lag_waxing  lag_wholesale_grocer  \\\n",
       "0                0.0    0.000000                   0.0   \n",
       "1                0.0    0.166667                   0.0   \n",
       "2                0.0    0.000000                   0.0   \n",
       "3                0.0    0.166667                   0.0   \n",
       "4                0.0    0.000000                   0.0   \n",
       "\n",
       "   lag_wildlife_sanctuary  lag_wills_trusts_and_probate  lag_winery  \n",
       "0                     0.0                      0.333333         0.0  \n",
       "1                     0.0                      0.166667         0.5  \n",
       "2                     0.0                      0.000000         0.0  \n",
       "3                     0.0                      0.000000         0.0  \n",
       "4                     0.0                      0.000000         0.5  \n",
       "\n",
       "[5 rows x 1177 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join all data together\n",
    "\n",
    "combined_census = pd.merge(general_health, employment_residential, on='LSOA11CD', suffixes=('', '_drop'))\n",
    "combined_census = pd.merge(combined_census, education, on='LSOA11CD', suffixes=('', '_drop'))\n",
    "combined_census = pd.merge(combined_census, household_comp, on='LSOA11CD', suffixes=('', '_drop'))\n",
    "combined_census = pd.merge(combined_census, age_bands, on='LSOA11CD', suffixes=('', '_drop'))\n",
    "combined_census = pd.merge(combined_census, english_lang, on='LSOA11CD', suffixes=('', '_drop'))\n",
    "combined_census = pd.merge(combined_census, multiple_deprivation, on='LSOA11CD', suffixes=('', '_drop'))\n",
    "\n",
    "# Get column lists\n",
    "combined_census = combined_census[[col for col in combined_census.columns if not col.endswith('_drop')]]\n",
    "combined_census_columns = list(combined_census.columns)\n",
    "exclude_columns = ['LSOA11CD', 'LSOA11NM', 'residual', 'Total: All usual residents', 'Total: All usual residents aged 16 years and over']\n",
    "census_feature_columns = [col for col in combined_census.columns if col not in exclude_columns]\n",
    "\n",
    "# Join with london and birmingham model output data\n",
    "combined_model = all_data_london\n",
    "combined_model = combined_model.drop(columns=['LSOA11NM'])\n",
    "combined_census = combined_census.merge(combined_model, on='LSOA11CD', how='inner')\n",
    "\n",
    "# Fix string rank data\n",
    "combined_census['Index of Multiple Deprivation (IMD) Rank'] = combined_census['Index of Multiple Deprivation (IMD) Rank'].str.replace(',', '')\n",
    "combined_census['Index of Multiple Deprivation (IMD) Rank']  = pd.to_numeric(combined_census['Index of Multiple Deprivation (IMD) Rank'] )   \n",
    "\n",
    "combined_census.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b0fb9ba4-5b58-4997-bb49-a45bd19d8f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model has already been fitted. You can use predict methods or select a new 'results_path' for a new 'fit()'.\n",
      "R^2 Score: 0.7474297689503127\n",
      "RMSE: 0.6102148294448853\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "array length 4659 does not match index length 4835",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[130], line 53\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m#Save results for plotting\u001b[39;00m\n\u001b[1;32m     51\u001b[0m predictions_all_23 \u001b[38;5;241m=\u001b[39m automl\u001b[38;5;241m.\u001b[39mpredict(combined_census[features])\n\u001b[0;32m---> 53\u001b[0m results_london_demographic \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlondon_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgeometry\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlondon_geometries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mobserved\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcombined_census\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpredicted\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions_all_23\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Save to project folder\u001b[39;00m\n\u001b[1;32m     61\u001b[0m results_london_demographic\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/combined_data/model_results_london_demographic.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/urbsim/lib/python3.11/site-packages/pandas/core/frame.py:733\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    727\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    728\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    729\u001b[0m     )\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 733\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[0;32m~/anaconda3/envs/urbsim/lib/python3.11/site-packages/pandas/core/internals/construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/urbsim/lib/python3.11/site-packages/pandas/core/internals/construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m~/anaconda3/envs/urbsim/lib/python3.11/site-packages/pandas/core/internals/construction.py:690\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lengths[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[1;32m    686\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    687\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray length \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlengths[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not match index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    688\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlength \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    689\u001b[0m         )\n\u001b[0;32m--> 690\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    692\u001b[0m     index \u001b[38;5;241m=\u001b[39m default_index(lengths[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[0;31mValueError\u001b[0m: array length 4659 does not match index length 4835"
     ]
    }
   ],
   "source": [
    "### Employment (log), NO Spatial Lag, London, Demographic Data\n",
    "\n",
    "# Ignore depracation warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london + census_feature_columns\n",
    "target = 'log_total_employment'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_census[features], combined_census[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/london_employment_demographic/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_23 = r2_score(y_test, predictions)\n",
    "rmse_23 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_23}')\n",
    "print(f'RMSE: {rmse_23}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_23 = automl.predict(combined_census[features])\n",
    "\n",
    "results_london_demographic = pd.DataFrame({\n",
    "    'name': london_names,\n",
    "    'geometry': london_geometries,\n",
    "    'observed': combined_census[target],\n",
    "    'predicted': predictions_all_23,\n",
    "})\n",
    "\n",
    "# Save to project folder\n",
    "results_london_demographic.to_csv(\"data/combined_data/model_results_london_demographic.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "urbsim",
   "language": "python",
   "name": "urbsim"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
