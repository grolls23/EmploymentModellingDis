{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7542fb7-3702-466a-8c2d-837e1e6d4ed3",
   "metadata": {},
   "source": [
    "# Modelling\n",
    "\n",
    "This is the script where I store all my ML model runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d305a93-526f-4ed4-993f-96d593fc9618",
   "metadata": {},
   "source": [
    "## Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b90b1626-165f-4b79-8d67-7b3afa023602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library Imports\n",
    "\n",
    "#Basics\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "#Shapely / Spatial\n",
    "from shapely import wkt\n",
    "import shapely.geometry\n",
    "from shapely.geometry import Polygon, MultiPolygon\n",
    "\n",
    "#Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#ML from mljar-supervised\n",
    "from supervised.automl import AutoML\n",
    "\n",
    "#Warning Supression\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31ea067-af33-4415-b9e7-4d3426573f62",
   "metadata": {},
   "source": [
    "### Import Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53f05a2a-040b-45cd-8108-192d695dea50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>LSOA11CD</th>\n",
       "      <th>LSOA11NM_x</th>\n",
       "      <th>LSOA11NM_y</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>population</th>\n",
       "      <th>Area</th>\n",
       "      <th>01 : Crop and animal production, hunting and related service activities</th>\n",
       "      <th>02 : Forestry and logging</th>\n",
       "      <th>03 : Fishing and aquaculture</th>\n",
       "      <th>...</th>\n",
       "      <th>lag_travel</th>\n",
       "      <th>lag_travel_agents</th>\n",
       "      <th>lag_trusts</th>\n",
       "      <th>lag_university_housing</th>\n",
       "      <th>lag_used_vintage_and_consignment</th>\n",
       "      <th>lag_veterinarian</th>\n",
       "      <th>lag_videographer</th>\n",
       "      <th>lag_vitamins_and_supplements</th>\n",
       "      <th>lag_warehouses</th>\n",
       "      <th>lag_window_washing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>E01008881</td>\n",
       "      <td>Birmingham 067A</td>\n",
       "      <td>Birmingham 067A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1599</td>\n",
       "      <td>lsoa2011:E01008881 : Birmingham 067A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>E01008882</td>\n",
       "      <td>Birmingham 066A</td>\n",
       "      <td>Birmingham 066A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1747</td>\n",
       "      <td>lsoa2011:E01008882 : Birmingham 066A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>E01008883</td>\n",
       "      <td>Birmingham 078A</td>\n",
       "      <td>Birmingham 078A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1816</td>\n",
       "      <td>lsoa2011:E01008883 : Birmingham 078A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>E01008884</td>\n",
       "      <td>Birmingham 078B</td>\n",
       "      <td>Birmingham 078B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1870</td>\n",
       "      <td>lsoa2011:E01008884 : Birmingham 078B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>E01008885</td>\n",
       "      <td>Birmingham 076A</td>\n",
       "      <td>Birmingham 076A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1308</td>\n",
       "      <td>lsoa2011:E01008885 : Birmingham 076A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>634</td>\n",
       "      <td>E01033646</td>\n",
       "      <td>Birmingham 031I</td>\n",
       "      <td>Birmingham 031I</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1624</td>\n",
       "      <td>lsoa2011:E01033646 : Birmingham 031I</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>635</td>\n",
       "      <td>E01033647</td>\n",
       "      <td>Birmingham 058E</td>\n",
       "      <td>Birmingham 058E</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1398</td>\n",
       "      <td>lsoa2011:E01033647 : Birmingham 058E</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>636</td>\n",
       "      <td>E01033648</td>\n",
       "      <td>Birmingham 084F</td>\n",
       "      <td>Birmingham 084F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2715</td>\n",
       "      <td>lsoa2011:E01033648 : Birmingham 084F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>637</td>\n",
       "      <td>E01033649</td>\n",
       "      <td>Birmingham 058F</td>\n",
       "      <td>Birmingham 058F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1801</td>\n",
       "      <td>lsoa2011:E01033649 : Birmingham 058F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>638</td>\n",
       "      <td>E01033650</td>\n",
       "      <td>Birmingham 077F</td>\n",
       "      <td>Birmingham 077F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2596</td>\n",
       "      <td>lsoa2011:E01033650 : Birmingham 077F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>639 rows × 742 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0   LSOA11CD       LSOA11NM_x       LSOA11NM_y  Unnamed: 2  \\\n",
       "0             0  E01008881  Birmingham 067A  Birmingham 067A         0.0   \n",
       "1             1  E01008882  Birmingham 066A  Birmingham 066A         0.0   \n",
       "2             2  E01008883  Birmingham 078A  Birmingham 078A         0.0   \n",
       "3             3  E01008884  Birmingham 078B  Birmingham 078B         0.0   \n",
       "4             4  E01008885  Birmingham 076A  Birmingham 076A         0.0   \n",
       "..          ...        ...              ...              ...         ...   \n",
       "634         634  E01033646  Birmingham 031I  Birmingham 031I         0.0   \n",
       "635         635  E01033647  Birmingham 058E  Birmingham 058E         0.0   \n",
       "636         636  E01033648  Birmingham 084F  Birmingham 084F         0.0   \n",
       "637         637  E01033649  Birmingham 058F  Birmingham 058F         0.0   \n",
       "638         638  E01033650  Birmingham 077F  Birmingham 077F         0.0   \n",
       "\n",
       "     population                                  Area  \\\n",
       "0          1599  lsoa2011:E01008881 : Birmingham 067A   \n",
       "1          1747  lsoa2011:E01008882 : Birmingham 066A   \n",
       "2          1816  lsoa2011:E01008883 : Birmingham 078A   \n",
       "3          1870  lsoa2011:E01008884 : Birmingham 078B   \n",
       "4          1308  lsoa2011:E01008885 : Birmingham 076A   \n",
       "..          ...                                   ...   \n",
       "634        1624  lsoa2011:E01033646 : Birmingham 031I   \n",
       "635        1398  lsoa2011:E01033647 : Birmingham 058E   \n",
       "636        2715  lsoa2011:E01033648 : Birmingham 084F   \n",
       "637        1801  lsoa2011:E01033649 : Birmingham 058F   \n",
       "638        2596  lsoa2011:E01033650 : Birmingham 077F   \n",
       "\n",
       "     01 : Crop and animal production, hunting and related service activities  \\\n",
       "0                                                  0.0                         \n",
       "1                                                  0.0                         \n",
       "2                                                  0.0                         \n",
       "3                                                  0.0                         \n",
       "4                                                  0.0                         \n",
       "..                                                 ...                         \n",
       "634                                                0.0                         \n",
       "635                                                0.0                         \n",
       "636                                                0.0                         \n",
       "637                                                0.0                         \n",
       "638                                                0.0                         \n",
       "\n",
       "     02 : Forestry and logging  03 : Fishing and aquaculture  ...  lag_travel  \\\n",
       "0                          0.0                           0.0  ...    0.000000   \n",
       "1                          0.0                           0.0  ...    0.166667   \n",
       "2                          0.0                           0.0  ...    0.166667   \n",
       "3                          0.0                           0.0  ...    0.333333   \n",
       "4                          0.0                           0.0  ...    0.000000   \n",
       "..                         ...                           ...  ...         ...   \n",
       "634                        0.0                           0.0  ...    0.166667   \n",
       "635                        0.0                           0.0  ...    0.166667   \n",
       "636                        0.0                           0.0  ...    0.000000   \n",
       "637                        0.0                           0.0  ...    0.333333   \n",
       "638                        0.0                           0.0  ...    0.000000   \n",
       "\n",
       "     lag_travel_agents  lag_trusts  lag_university_housing  \\\n",
       "0             0.166667         0.0                     0.0   \n",
       "1             0.000000         0.0                     0.0   \n",
       "2             0.000000         0.0                     0.0   \n",
       "3             0.000000         0.0                     0.0   \n",
       "4             0.166667         0.0                     0.0   \n",
       "..                 ...         ...                     ...   \n",
       "634           0.000000         0.0                     0.0   \n",
       "635           0.000000         0.0                     0.0   \n",
       "636           0.000000         0.0                     0.0   \n",
       "637           0.000000         0.0                     0.0   \n",
       "638           0.000000         0.0                     0.0   \n",
       "\n",
       "     lag_used_vintage_and_consignment  lag_veterinarian  lag_videographer  \\\n",
       "0                                 0.0               0.0               0.0   \n",
       "1                                 0.0               0.0               0.0   \n",
       "2                                 0.0               0.0               0.0   \n",
       "3                                 0.0               0.0               0.0   \n",
       "4                                 0.0               0.0               0.0   \n",
       "..                                ...               ...               ...   \n",
       "634                               0.0               0.0               0.0   \n",
       "635                               0.0               0.0               0.0   \n",
       "636                               0.0               0.0               0.0   \n",
       "637                               0.0               0.0               0.0   \n",
       "638                               0.0               0.0               0.0   \n",
       "\n",
       "     lag_vitamins_and_supplements  lag_warehouses  lag_window_washing  \n",
       "0                        0.000000        0.333333                 0.0  \n",
       "1                        0.000000        0.500000                 0.0  \n",
       "2                        0.000000        0.000000                 0.0  \n",
       "3                        0.166667        0.500000                 0.0  \n",
       "4                        0.000000        0.000000                 0.0  \n",
       "..                            ...             ...                 ...  \n",
       "634                      0.166667        0.000000                 0.0  \n",
       "635                      0.000000        0.000000                 0.0  \n",
       "636                      0.000000        0.000000                 0.0  \n",
       "637                      0.166667        0.000000                 0.0  \n",
       "638                      0.000000        0.000000                 0.0  \n",
       "\n",
       "[639 rows x 742 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read London CSV\n",
    "all_data_london = pd.read_csv(\"data/combined_data/lag/all_data_london_lag.csv\")\n",
    "\n",
    "# Read in feature column set\n",
    "with open(\"data/combined_data/total_feature_columns_london.csv\", 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Reconstruct\n",
    "feature_columns_london_lag = [''.join(line.strip().split(',')) for line in lines]\n",
    "\n",
    "# Create non-laged column set\n",
    "feature_columns_london = [col for col in feature_columns_london_lag if not col.startswith('lag_')]\n",
    "\n",
    "# ---\n",
    "\n",
    "# Read Birmingham CSV\n",
    "all_data_bham = pd.read_csv(\"data/combined_data/lag/all_data_bham_lag.csv\")\n",
    "\n",
    "# Read in feature column set\n",
    "with open(\"data/combined_data/total_feature_columns_bham.csv\", 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Reconstruct\n",
    "feature_columns_bham_lag = [''.join(line.strip().split(',')) for line in lines]\n",
    "\n",
    "# Create non-lagged column set\n",
    "feature_columns_bham = [col for col in feature_columns_bham_lag if not col.startswith('lag_')]\n",
    "\n",
    "# Fix null values ending up in logged variables\n",
    "all_data_london.fillna(0)\n",
    "all_data_bham.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "581a5ad1-f57d-4764-b71b-568a4e4f8c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download POI & auxillary-only feature spaces (No building footprint information)\n",
    "\n",
    "# London\n",
    "# Read in POI feature column set\n",
    "with open(\"data/combined_data/feature_columns_london_poi.csv\", 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Reconstruct\n",
    "feature_columns_london_poi = [''.join(line.strip().split(',')) for line in lines]\n",
    "\n",
    "# Birmingham\n",
    "# Read in POI feature column set\n",
    "with open(\"data/combined_data/feature_columns_bham_poi.csv\", 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Reconstruct\n",
    "feature_columns_bham_poi = [''.join(line.strip().split(',')) for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb1bf237-cbfa-4ce2-9745-768d454fb859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get log of density columns\n",
    "\n",
    "epsilon = 1e-10\n",
    "\n",
    "all_data_london['log_employment_density'] = np.log(all_data_london['employment_density'].replace(0, epsilon))\n",
    "all_data_london['log_office_employment_density'] = np.log(all_data_london['office_employment_density'].replace(0, epsilon))\n",
    "\n",
    "all_data_bham['log_employment_density'] = np.log(all_data_bham['employment_density'].replace(0, epsilon))\n",
    "all_data_bham['log_office_employment_density'] = np.log(all_data_bham['office_employment_density'].replace(0, epsilon)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1476d20c-344b-422d-8b04-e6b747f1d5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Geometries and Names\n",
    "\n",
    "london_geometries = all_data_london['geometry']\n",
    "bham_geometries = all_data_bham['geometry']\n",
    "\n",
    "london_names = all_data_london['LSOA11CD']\n",
    "bham_names = all_data_bham['LSOA11CD']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5488444a-67fc-4aca-8e79-065018e090cb",
   "metadata": {},
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e93f99a8-c74f-4436-8877-6d11cc2f3103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model has already been fitted. You can use predict methods or select a new 'results_path' for a new 'fit()'.\n",
      "R^2 Score: 0.7207009026018532\n",
      "RMSE: 0.678412914276123\n"
     ]
    }
   ],
   "source": [
    "# Ignore depracation warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london_lag\n",
    "target = 'log_total_employment'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(results_path=\"ml_results/dummy_models/test\", mode='Explain')\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_log_employment = r2_score(y_test, predictions)\n",
    "rmse_log_employment = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_log_employment}')\n",
    "print(f'RMSE: {rmse_log_employment}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all = automl.predict(all_data_london[features])\n",
    "\n",
    "results_test = pd.DataFrame({\n",
    "    'geometry': london_geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca014449-6c4c-46d6-ba87-a578cbb9881d",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ce02ced4-41b4-46d0-89da-b9900f64442d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: ml_results/log_employment_london/\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['CatBoost', 'Xgboost', 'Random Forest']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "1_Default_Xgboost rmse 0.638237 trained in 44.72 seconds\n",
      "2_Default_CatBoost rmse 0.624872 trained in 39.45 seconds\n",
      "3_Default_RandomForest rmse 0.692124 trained in 1092.47 seconds\n",
      "* Step not_so_random will try to check up to 12 models\n",
      "4_Xgboost rmse 0.647595 trained in 31.74 seconds\n",
      "8_CatBoost rmse 0.62888 trained in 57.43 seconds\n",
      "12_RandomForest rmse 0.689969 trained in 42.49 seconds\n",
      "5_Xgboost rmse 0.646129 trained in 955.1 seconds\n",
      "9_CatBoost rmse 0.640378 trained in 954.04 seconds\n",
      "13_RandomForest rmse 0.713245 trained in 57.77 seconds\n",
      "6_Xgboost rmse 0.631339 trained in 29.05 seconds\n",
      "10_CatBoost rmse 0.627944 trained in 359.69 seconds\n",
      "14_RandomForest rmse 0.677261 trained in 62.38 seconds\n",
      "7_Xgboost rmse 0.635899 trained in 27.49 seconds\n",
      "11_CatBoost rmse 0.65143 trained in 42.03 seconds\n",
      "15_RandomForest rmse 0.67456 trained in 313.99 seconds\n",
      "Skip hill_climbing_1 because of the time limit.\n",
      "Skip hill_climbing_2 because of the time limit.\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble rmse 0.617282 trained in 0.17 seconds\n",
      "AutoML fit time: 4117.39 seconds\n",
      "AutoML best model: Ensemble\n",
      "R^2 Score: 0.7578170639491384\n",
      "RMSE: 0.6317294239997864\n"
     ]
    }
   ],
   "source": [
    "### Employment (log), NO Spatial Lag, London (1)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london\n",
    "target = 'log_total_employment'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/log_employment_london/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_1 = r2_score(y_test, predictions)\n",
    "rmse_1 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_1}')\n",
    "print(f'RMSE: {rmse_1}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_1 = automl.predict(all_data_london[features])\n",
    "london_geometries = all_data_london.loc[all_data_london[target].index, 'geometry']\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': london_geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all_1,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ac80575c-2245-4464-abdd-a8997967e727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: ml_results/log_employment_bham/\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['CatBoost', 'Xgboost', 'Random Forest']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "1_Default_Xgboost rmse 0.803686 trained in 5.65 seconds\n",
      "2_Default_CatBoost rmse 0.783334 trained in 18.54 seconds\n",
      "3_Default_RandomForest rmse 0.821087 trained in 24.78 seconds\n",
      "* Step not_so_random will try to check up to 12 models\n",
      "4_Xgboost rmse 0.807126 trained in 5.22 seconds\n",
      "8_CatBoost rmse 0.810248 trained in 22.31 seconds\n",
      "12_RandomForest rmse 0.816138 trained in 57.95 seconds\n",
      "5_Xgboost rmse 0.808929 trained in 5.8 seconds\n",
      "9_CatBoost rmse 0.830576 trained in 20.01 seconds\n",
      "13_RandomForest rmse 0.848962 trained in 56.66 seconds\n",
      "6_Xgboost rmse 0.791632 trained in 4.91 seconds\n",
      "10_CatBoost rmse 0.811724 trained in 19.82 seconds\n",
      "14_RandomForest rmse 0.817142 trained in 24.16 seconds\n",
      "7_Xgboost rmse 0.861031 trained in 4.85 seconds\n",
      "11_CatBoost rmse 0.854616 trained in 19.84 seconds\n",
      "15_RandomForest rmse 0.824156 trained in 65.1 seconds\n",
      "* Step hill_climbing_1 will try to check up to 18 models\n",
      "16_CatBoost rmse 0.795161 trained in 19.39 seconds\n",
      "17_CatBoost rmse 0.799599 trained in 18.81 seconds\n",
      "18_Xgboost rmse 0.792724 trained in 5.24 seconds\n",
      "19_Xgboost rmse 0.798389 trained in 5.27 seconds\n",
      "20_Xgboost rmse 0.801649 trained in 5.36 seconds\n",
      "21_Xgboost rmse 0.801951 trained in 5.54 seconds\n",
      "22_Xgboost rmse 0.797301 trained in 5.28 seconds\n",
      "23_Xgboost rmse 0.81387 trained in 5.55 seconds\n",
      "24_CatBoost rmse 0.809749 trained in 47.23 seconds\n",
      "25_CatBoost rmse 0.819835 trained in 20.94 seconds\n",
      "26_CatBoost rmse 0.801445 trained in 21.29 seconds\n",
      "27_CatBoost rmse 0.825881 trained in 19.57 seconds\n",
      "28_RandomForest rmse 0.812049 trained in 55.3 seconds\n",
      "29_RandomForest rmse 0.820499 trained in 26.16 seconds\n",
      "30_RandomForest rmse 0.809917 trained in 25.73 seconds\n",
      "31_RandomForest rmse 0.829734 trained in 24.04 seconds\n",
      "32_RandomForest rmse 0.816113 trained in 56.83 seconds\n",
      "33_RandomForest rmse 0.820707 trained in 24.05 seconds\n",
      "* Step hill_climbing_2 will try to check up to 10 models\n",
      "34_Xgboost rmse 0.797041 trained in 5.24 seconds\n",
      "35_Xgboost rmse 0.798353 trained in 5.45 seconds\n",
      "36_Xgboost rmse 0.798988 trained in 6.04 seconds\n",
      "37_Xgboost rmse 0.798183 trained in 5.87 seconds\n",
      "38_CatBoost rmse 0.792413 trained in 22.1 seconds\n",
      "39_Xgboost rmse 0.801037 trained in 6.73 seconds\n",
      "40_RandomForest rmse 0.805922 trained in 956.12 seconds\n",
      "41_RandomForest rmse 0.80454 trained in 29.39 seconds\n",
      "42_RandomForest rmse 0.813594 trained in 23.26 seconds\n",
      "43_RandomForest rmse 0.813903 trained in 994.4 seconds\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble rmse 0.767987 trained in 1.08 seconds\n",
      "AutoML fit time: 2821.1 seconds\n",
      "AutoML best model: Ensemble\n",
      "R^2 Score: 0.63966144185158\n",
      "RMSE: 0.7145385146141052\n"
     ]
    }
   ],
   "source": [
    "### Employment (log), NO Spatial Lag, Birmingham (2)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_bham\n",
    "target = 'log_total_employment'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_bham[features], all_data_bham[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/log_employment_bham/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_2 = r2_score(y_test, predictions)\n",
    "rmse_2 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_2}')\n",
    "print(f'RMSE: {rmse_2}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_2 = automl.predict(all_data_bham[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': bham_geometries,\n",
    "    'observed': all_data_bham[target],\n",
    "    'predicted': predictions_all_2,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cbef0bf3-04a1-489c-ae7b-5552895992bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: ml_results/log_employment_london_lag/\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['CatBoost', 'Xgboost', 'Random Forest']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "1_Default_Xgboost rmse 0.638593 trained in 1086.36 seconds\n",
      "2_Default_CatBoost rmse 0.63385 trained in 2029.01 seconds\n",
      "3_Default_RandomForest rmse 0.693922 trained in 2068.46 seconds\n",
      "Skip not_so_random because of the time limit.\n",
      "Skip hill_climbing_1 because of the time limit.\n",
      "Skip hill_climbing_2 because of the time limit.\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble rmse 0.627695 trained in 0.05 seconds\n",
      "AutoML fit time: 5186.08 seconds\n",
      "AutoML best model: Ensemble\n",
      "R^2 Score: 0.7547717661754779\n",
      "RMSE: 0.635688841342926\n"
     ]
    }
   ],
   "source": [
    "### Employment (log), Spatial Lag, London (3)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london_lag\n",
    "target = 'log_total_employment'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/log_employment_london_lag/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_3 = r2_score(y_test, predictions)\n",
    "rmse_3 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_3}')\n",
    "print(f'RMSE: {rmse_3}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_3 = automl.predict(all_data_london[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': london_geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all_3,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c5e16db-a923-45df-96fe-aa63e186fa14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gavinrolls/anaconda3/envs/urbsim/lib/python3.11/site-packages/supervised/preprocessing/exclude_missing_target.py:25: UserWarning: There are samples with missing target values in the data which will be excluded for further analysis\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model has already been fitted. You can use predict methods or select a new 'results_path' for a new 'fit()'.\n",
      "R^2 Score: 0.6180309508339799\n",
      "RMSE: 0.7356722354888916\n"
     ]
    }
   ],
   "source": [
    "### Employment (log), Spatial Lag, Birmingham (4)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_bham_lag\n",
    "target = 'log_total_employment'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_bham[features], all_data_bham[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/log_employment_bham_lag/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_4 = r2_score(y_test, predictions)\n",
    "rmse_4 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_4}')\n",
    "print(f'RMSE: {rmse_4}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_4 = automl.predict(all_data_bham[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': bham_geometries,\n",
    "    'observed': all_data_bham[target],\n",
    "    'predicted': predictions_all_4,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8e39466b-44a3-4721-b6c1-4ad1484b0f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: ml_results/employment_density_london/\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['CatBoost', 'Xgboost', 'Random Forest']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "1_Default_Xgboost rmse 0.711278 trained in 52.53 seconds\n",
      "2_Default_CatBoost rmse 0.679557 trained in 62.23 seconds\n",
      "3_Default_RandomForest rmse 0.803243 trained in 43.05 seconds\n",
      "* Step not_so_random will try to check up to 12 models\n",
      "4_Xgboost rmse 0.706569 trained in 43.27 seconds\n",
      "8_CatBoost rmse 0.68361 trained in 76.41 seconds\n",
      "12_RandomForest rmse 0.807704 trained in 69.05 seconds\n",
      "5_Xgboost rmse 0.728611 trained in 46.56 seconds\n",
      "9_CatBoost rmse 0.705359 trained in 70.99 seconds\n",
      "13_RandomForest rmse 0.83544 trained in 61.51 seconds\n",
      "6_Xgboost rmse 0.694949 trained in 35.09 seconds\n",
      "10_CatBoost rmse 0.682747 trained in 55.81 seconds\n",
      "14_RandomForest rmse 0.758195 trained in 68.14 seconds\n",
      "7_Xgboost rmse 0.702578 trained in 39.85 seconds\n",
      "11_CatBoost rmse 0.716132 trained in 54.48 seconds\n",
      "15_RandomForest rmse 0.764481 trained in 44.5 seconds\n",
      "* Step hill_climbing_1 will try to check up to 17 models\n",
      "16_CatBoost rmse 0.680324 trained in 64.33 seconds\n",
      "17_CatBoost rmse 0.68341 trained in 49.42 seconds\n",
      "18_CatBoost rmse 0.682535 trained in 66.0 seconds\n",
      "19_CatBoost rmse 0.691594 trained in 54.45 seconds\n",
      "20_CatBoost rmse 0.679384 trained in 102.49 seconds\n",
      "21_CatBoost rmse 0.689438 trained in 69.99 seconds\n",
      "22_Xgboost rmse 0.694574 trained in 37.01 seconds\n",
      "23_Xgboost rmse 0.692538 trained in 37.1 seconds\n",
      "24_Xgboost rmse 0.69705 trained in 42.59 seconds\n",
      "25_Xgboost rmse 0.701961 trained in 40.84 seconds\n",
      "26_Xgboost rmse 0.704639 trained in 41.86 seconds\n",
      "27_Xgboost rmse 0.712852 trained in 38.27 seconds\n",
      "28_RandomForest rmse 0.755796 trained in 56.57 seconds\n",
      "29_RandomForest rmse 0.759645 trained in 41.05 seconds\n",
      "30_RandomForest rmse 0.761312 trained in 76.44 seconds\n",
      "31_RandomForest rmse 0.802914 trained in 52.23 seconds\n",
      "32_RandomForest rmse 0.803781 trained in 42.33 seconds\n",
      "* Step hill_climbing_2 will try to check up to 11 models\n",
      "33_CatBoost rmse 0.680566 trained in 85.49 seconds\n",
      "34_CatBoost rmse 0.681903 trained in 87.42 seconds\n",
      "35_CatBoost rmse 0.684802 trained in 52.26 seconds\n",
      "36_CatBoost rmse 0.683143 trained in 59.09 seconds\n",
      "37_Xgboost rmse 0.695347 trained in 41.75 seconds\n",
      "38_Xgboost rmse 0.696322 trained in 41.4 seconds\n",
      "39_Xgboost rmse 0.688817 trained in 43.17 seconds\n",
      "40_Xgboost rmse 0.69494 trained in 40.32 seconds\n",
      "41_Xgboost rmse 0.691064 trained in 42.41 seconds\n",
      "42_Xgboost rmse 0.692203 trained in 50.16 seconds\n",
      "43_RandomForest rmse 0.754223 trained in 68.77 seconds\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble rmse 0.672166 trained in 1.12 seconds\n",
      "AutoML fit time: 2370.25 seconds\n",
      "AutoML best model: Ensemble\n",
      "R^2 Score: 0.6253442136592793\n",
      "RMSE: 0.9332378506660461\n"
     ]
    }
   ],
   "source": [
    "### Employment Density, NO Spatial Lag, London (5)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london\n",
    "target = 'log_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/employment_density_london/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_5 = r2_score(y_test, predictions)\n",
    "rmse_5 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_5}')\n",
    "print(f'RMSE: {rmse_5}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_5 = automl.predict(all_data_london[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': london_geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all_5,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1faae03a-3177-4923-a949-53cae255a64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model has already been fitted. You can use predict methods or select a new 'results_path' for a new 'fit()'.\n",
      "R^2 Score: 0.5111932494414406\n",
      "RMSE: 0.7408556938171387\n"
     ]
    }
   ],
   "source": [
    "### Employment Density, NO Spatial Lag, Birmingham (6)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_bham\n",
    "target = 'log_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_bham[features], all_data_bham[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/employment_density_bham/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_6 = r2_score(y_test, predictions)\n",
    "rmse_6 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_6}')\n",
    "print(f'RMSE: {rmse_6}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_6 = automl.predict(all_data_bham[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': bham_geometries,\n",
    "    'observed': all_data_bham[target],\n",
    "    'predicted': predictions_all_6,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907fde61-ed19-43a6-b9b6-3951fb0bd473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: ml_results/employment_density_london_lag/\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['CatBoost', 'Xgboost', 'Random Forest']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "1_Default_Xgboost rmse 0.697738 trained in 232.55 seconds\n",
      "2_Default_CatBoost rmse 0.690238 trained in 300.13 seconds\n",
      "3_Default_RandomForest rmse 0.798875 trained in 162.55 seconds\n",
      "* Step not_so_random will try to check up to 12 models\n",
      "4_Xgboost rmse 0.709979 trained in 268.49 seconds\n",
      "8_CatBoost rmse 0.688124 trained in 397.58 seconds\n",
      "12_RandomForest rmse 0.800764 trained in 184.92 seconds\n",
      "5_Xgboost rmse 0.71357 trained in 252.43 seconds\n",
      "9_CatBoost rmse 0.718557 trained in 361.72 seconds\n",
      "13_RandomForest rmse 0.831279 trained in 275.18 seconds\n",
      "6_Xgboost rmse 0.698883 trained in 274.21 seconds\n",
      "10_CatBoost rmse 0.689076 trained in 366.7 seconds\n"
     ]
    }
   ],
   "source": [
    "### Employment Density, Spatial Lag, London (7)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london_lag\n",
    "target = 'log_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/employment_density_london_lag/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_7 = r2_score(y_test, predictions)\n",
    "rmse_7 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_7}')\n",
    "print(f'RMSE: {rmse_7}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_7 = automl.predict(all_data_london[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': london_geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all_7,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bb150e-d907-41c8-a5cb-2d3d0e065417",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Employment Density, Spatial Lag, Birmingham (8)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_bham_lag\n",
    "target = 'log_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_bham[features], all_data_bham[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/employment_density_bham_lag/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_8 = r2_score(y_test, predictions)\n",
    "rmse_8 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_8}')\n",
    "print(f'RMSE: {rmse_8}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_8 = automl.predict(all_data_bham[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': bham_geometries,\n",
    "    'observed': all_data_bham[target],\n",
    "    'predicted': predictions_all_8,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6e4682-7e10-4638-bb3c-a08c426b9f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Office Employment Density , NO Spatial Lag, London (9)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london\n",
    "target = 'log_office_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/office_employment_density_london/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_9 = r2_score(y_test, predictions)\n",
    "rmse_9 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_9}')\n",
    "print(f'RMSE: {rmse_9}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_9 = automl.predict(all_data_london[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': london_geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all_9,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015c372b-1b93-4550-b7f5-ece1ad3149b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Office Employment Density , NO Spatial Lag, Birmingham (10)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_bham\n",
    "target = 'log_office_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_bham[features], all_data_bham[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/office_employment_density_bham/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_10 = r2_score(y_test, predictions)\n",
    "rmse_10 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_10}')\n",
    "print(f'RMSE: {rmse_10}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_10 = automl.predict(all_data_bham[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': bham_geometries,\n",
    "    'observed': all_data_bham[target],\n",
    "    'predicted': predictions_all_10,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3160a4-8d0e-4048-acb5-a9f8e51ef901",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Office Employment Density, Spatial Lag, London (11)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london_lag\n",
    "target = 'log_office_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/office_employment_density_london_lag/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_11 = r2_score(y_test, predictions)\n",
    "rmse_11 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_11}')\n",
    "print(f'RMSE: {rmse_11}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_11 = automl.predict(all_data_london[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': london_geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all_11,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c793ac54-59e8-4ff0-b95a-0bb60d1edd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Office Employment Density (log), Spatial Lag, Birmingham (12)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_bham_lag\n",
    "target = 'log_office_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_bham[features], all_data_bham[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/office_employment_density_bham_lag/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_12 = r2_score(y_test, predictions)\n",
    "rmse_12 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_12}')\n",
    "print(f'RMSE: {rmse_12}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_12 = automl.predict(all_data_bham[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': bham_geometries,\n",
    "    'observed': all_data_bham[target],\n",
    "    'predicted': predictions_all_12,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c0592585-a869-42b2-9ccd-c7ebe0bef895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model has already been fitted. You can use predict methods or select a new 'results_path' for a new 'fit()'.\n",
      "R^2 Score: 0.7256287050510382\n",
      "RMSE: 0.672401487827301\n"
     ]
    }
   ],
   "source": [
    "### Employment (log), NO Spatial Lag, London, POI only (13)\n",
    "\n",
    "# Ignore depracation warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london_poi\n",
    "target = 'log_total_employment'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/log_employment_london_poi/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_13 = r2_score(y_test, predictions)\n",
    "rmse_13 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_13}')\n",
    "print(f'RMSE: {rmse_13}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_13 = automl.predict(all_data_london[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': london_geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all_13,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b3ff96c6-9be8-4705-83e2-67f8876eb238",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gavinrolls/anaconda3/envs/urbsim/lib/python3.11/site-packages/supervised/preprocessing/exclude_missing_target.py:25: UserWarning: There are samples with missing target values in the data which will be excluded for further analysis\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: ml_results/log_employment_bham_poi/\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['CatBoost', 'Xgboost', 'Random Forest']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "1_Default_Xgboost rmse 0.796247 trained in 1077.34 seconds\n",
      "2_Default_CatBoost rmse 0.811589 trained in 10.74 seconds\n",
      "3_Default_RandomForest rmse 0.819108 trained in 18.32 seconds\n",
      "* Step not_so_random will try to check up to 12 models\n",
      "4_Xgboost rmse 0.814556 trained in 4.52 seconds\n",
      "8_CatBoost rmse 0.820528 trained in 17.07 seconds\n",
      "12_RandomForest rmse 0.81786 trained in 18.95 seconds\n",
      "5_Xgboost rmse 0.818373 trained in 5.14 seconds\n",
      "9_CatBoost rmse 0.835969 trained in 14.25 seconds\n",
      "13_RandomForest rmse 0.847451 trained in 20.41 seconds\n",
      "6_Xgboost rmse 0.786124 trained in 4.86 seconds\n",
      "10_CatBoost rmse 0.823456 trained in 13.13 seconds\n",
      "14_RandomForest rmse 0.816404 trained in 20.54 seconds\n",
      "7_Xgboost rmse 0.860902 trained in 4.61 seconds\n",
      "11_CatBoost rmse 0.859474 trained in 13.83 seconds\n",
      "15_RandomForest rmse 0.824256 trained in 19.11 seconds\n",
      "* Step hill_climbing_1 will try to check up to 18 models\n",
      "16_Xgboost rmse 0.78515 trained in 4.85 seconds\n",
      "17_Xgboost rmse 0.789404 trained in 4.81 seconds\n",
      "18_Xgboost rmse 0.78776 trained in 4.72 seconds\n",
      "19_Xgboost rmse 0.807992 trained in 5.16 seconds\n",
      "20_CatBoost rmse 0.794589 trained in 13.96 seconds\n",
      "21_CatBoost rmse 0.810056 trained in 12.73 seconds\n",
      "22_Xgboost rmse 0.810594 trained in 5.48 seconds\n",
      "23_Xgboost rmse 0.812881 trained in 5.85 seconds\n",
      "24_RandomForest rmse 0.808417 trained in 20.7 seconds\n",
      "25_RandomForest rmse 0.828899 trained in 18.61 seconds\n",
      "26_RandomForest rmse 0.81791 trained in 19.22 seconds\n",
      "27_RandomForest rmse 0.820985 trained in 21.68 seconds\n",
      "28_RandomForest rmse 0.813939 trained in 20.54 seconds\n",
      "29_RandomForest rmse 0.825659 trained in 20.7 seconds\n",
      "30_CatBoost rmse 0.826822 trained in 22.93 seconds\n",
      "31_CatBoost rmse 0.837677 trained in 14.62 seconds\n",
      "32_CatBoost rmse 0.81028 trained in 14.74 seconds\n",
      "33_CatBoost rmse 0.818305 trained in 13.59 seconds\n",
      "* Step hill_climbing_2 will try to check up to 11 models\n",
      "34_Xgboost rmse 0.784243 trained in 4.96 seconds\n",
      "35_Xgboost rmse 0.788559 trained in 4.93 seconds\n",
      "36_Xgboost rmse 0.785134 trained in 5.0 seconds\n",
      "37_Xgboost rmse 0.788556 trained in 5.14 seconds\n",
      "38_Xgboost rmse 0.798748 trained in 5.15 seconds\n",
      "39_CatBoost rmse 0.804644 trained in 27.01 seconds\n",
      "40_RandomForest rmse 0.800958 trained in 18.56 seconds\n",
      "41_CatBoost rmse 0.814851 trained in 17.99 seconds\n",
      "42_RandomForest rmse 0.809814 trained in 17.02 seconds\n",
      "43_RandomForest rmse 0.813948 trained in 24.13 seconds\n",
      "44_RandomForest rmse 0.808648 trained in 17.94 seconds\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble rmse 0.768035 trained in 1.09 seconds\n",
      "AutoML fit time: 1676.53 seconds\n",
      "AutoML best model: Ensemble\n",
      "R^2 Score: 0.629515890174141\n",
      "RMSE: 0.7245278358459473\n"
     ]
    }
   ],
   "source": [
    "### Employment (log), NO Spatial Lag, Brimingham, POI only (14)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_bham_poi\n",
    "target = 'log_total_employment'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_bham[features], all_data_bham[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/log_employment_bham_poi/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_14 = r2_score(y_test, predictions)\n",
    "rmse_14 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_14}')\n",
    "print(f'RMSE: {rmse_14}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_14 = automl.predict(all_data_bham[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': bham_geometries,\n",
    "    'observed': all_data_bham[target],\n",
    "    'predicted': predictions_all_14,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4bf1d6-902a-4011-b805-4e1d2df8644e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Employment Density, NO Spatial Lag, London, POI only (15)\n",
    "\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london_poi\n",
    "target = 'log_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/employment_density_london_poi/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_15 = r2_score(y_test, predictions)\n",
    "rmse_15 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_15}')\n",
    "print(f'RMSE: {rmse_15}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_15 = automl.predict(all_data_london[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': london_geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all_15,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b18222-1efa-4451-b8a1-5d26ba8f83cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Employment Density, NO Spatial Lag, Brimingham, POI only (16)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_bham_poi\n",
    "target = 'log_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_bham[features], all_data_bham[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/employment_density_bham_poi/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_16 = r2_score(y_test, predictions)\n",
    "rmse_16 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_16}')\n",
    "print(f'RMSE: {rmse_16}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_16 = automl.predict(all_data_bham[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': bham_geometries,\n",
    "    'observed': all_data_bham[target],\n",
    "    'predicted': predictions_all_16,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154710f6-e527-4512-8861-573d0f26d504",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Office Employment Density, NO Spatial Lag, London, POI only (17)\n",
    "\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london_poi\n",
    "target = 'log_office_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/office_employment_density_london_poi/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_17 = r2_score(y_test, predictions)\n",
    "rmse_17 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_17}')\n",
    "print(f'RMSE: {rmse_17}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_17 = automl.predict(all_data_london[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': london_geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all_17,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27df441e-a493-4c24-88e7-a302f6e05843",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Office Employment Density, NO Spatial Lag, Birmingham, POI only (18)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_bham_poi\n",
    "target = 'log_office_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_bham[features], all_data_bham[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/office_employment_density_bham_poi/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_18 = r2_score(y_test, predictions)\n",
    "rmse_18 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_18}')\n",
    "print(f'RMSE: {rmse_18}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_18 = automl.predict(all_data_bham[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': bham_geometries,\n",
    "    'observed': all_data_bham[target],\n",
    "    'predicted': predictions_all_18,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcb1705-7a08-4f36-97bc-fe4b06fb175f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abadb44-cad5-4e42-afb1-696b1611f5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Employment (log), Spatial Lag, NO building footprints, London (19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f2d5e8-ab8d-4d04-9381-8fa39bc509e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Employment density (log), Spatial Lag, NO building footprints, London (20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85017eb0-6561-4e24-b5be-040f01e41dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Office Employment Density (log), Spatial Lag, NO building footprints, London (21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14a7257-f1e2-4bf5-a856-8868805a693a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Employment (log), Spatial Lag, NO building footprints, Birmingham (22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b64d0d-1da7-4353-9e1d-eec5d2be71f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Employment density (log), Spatial Lag, NO building footprints, Birmingham (23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f9d2cc-5125-442c-a25c-e1ec7e645a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Office Employment Density (log), Spatial Lag, NO building footprints, Birmingham (24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024e2553-1a43-4da2-ac78-f84b9536d8ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "95b4bac7-1f3e-4b26-9a31-6014e0048a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model has already been fitted. You can use predict methods or select a new 'results_path' for a new 'fit()'.\n",
      "R^2 Score: 0.7102393476371849\n",
      "RMSE: 0.6910015940666199\n"
     ]
    }
   ],
   "source": [
    "### Employment (log), NO Spatial Lag, London,  POI EXCLUSIVE (25)\n",
    "\n",
    "# Ignore depracation warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london_poi = [column for column in feature_columns_london_poi if column != 'log_num_places']\n",
    "target = 'log_total_employment'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/poi_exclusive_london/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_19 = r2_score(y_test, predictions)\n",
    "rmse_19 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_19}')\n",
    "print(f'RMSE: {rmse_19}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_19 = automl.predict(all_data_london[features])\n",
    "\n",
    "results_london_poi = pd.DataFrame({\n",
    "    'name': london_names,\n",
    "    'geometry': london_geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all_19,\n",
    "})\n",
    "\n",
    "# Save to project folder\n",
    "results_london_poi.to_csv(\"data/combined_data/model_results_london_poi.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "37b651d4-c97d-41b2-86ed-5cce34f30be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model has already been fitted. You can use predict methods or select a new 'results_path' for a new 'fit()'.\n",
      "R^2 Score: 0.6226217466175756\n",
      "RMSE: 0.7312378883361816\n"
     ]
    }
   ],
   "source": [
    "### Employment (log), NO Spatial Lag, Birmingham, POI EXCLUSIVE (26)\n",
    "\n",
    "# Ignore depracation warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_bham_poi = [column for column in feature_columns_bham_poi if column != 'log_num_places']\n",
    "target = 'log_total_employment'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_bham[features], all_data_bham[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/poi_exclusive_bham/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_20 = r2_score(y_test, predictions)\n",
    "rmse_20 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_20}')\n",
    "print(f'RMSE: {rmse_20}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_20 = automl.predict(all_data_bham[features])\n",
    "\n",
    "results_bham_poi = pd.DataFrame({\n",
    "    'name': bham_names,\n",
    "    'geometry': bham_geometries,\n",
    "    'observed': all_data_bham[target],\n",
    "    'predicted': predictions_all_20,\n",
    "})\n",
    "\n",
    "# Save to project folder\n",
    "results_bham_poi.to_csv(\"data/combined_data/model_results_bham_poi.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9e4b08-aeb6-45c8-bb64-1d5cce0c8e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Employment Density, NO Spatial Lag, London,  POI EXCLUSIVE (27)\n",
    "\n",
    "# Ignore depracation warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london_poi = [column for column in feature_columns_london_poi if column != 'log_num_places']\n",
    "target = 'log_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/poi_exclusive_london_density/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_21 = r2_score(y_test, predictions)\n",
    "rmse_21 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_21}')\n",
    "print(f'RMSE: {rmse_21}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_21 = automl.predict(all_data_london[features])\n",
    "\n",
    "results_london_poi_density = pd.DataFrame({\n",
    "    'name': london_names,\n",
    "    'geometry': london_geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all_21,\n",
    "})\n",
    "\n",
    "# Save to project folder\n",
    "results_london_poi_density.to_csv(\"data/combined_data/model_results_london_poi_density.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b6d36b-2df9-4a0b-87ae-1873ca72ce4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Employment Density, NO Spatial Lag, Birmingham, POI EXCLUSIVE (28)\n",
    "\n",
    "# Ignore depracation warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_bham_poi = [column for column in feature_columns_bham_poi if column != 'log_num_places']\n",
    "target = 'log_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_bham[features], all_data_bham[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/poi_exclusive_bham_density/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_22 = r2_score(y_test, predictions)\n",
    "rmse_22 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_22}')\n",
    "print(f'RMSE: {rmse_22}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_22 = automl.predict(all_data_bham[features])\n",
    "\n",
    "results_bham_poi_density = pd.DataFrame({\n",
    "    'name': bham_names,\n",
    "    'geometry': bham_geometries,\n",
    "    'observed': all_data_bham[target],\n",
    "    'predicted': predictions_all_22,\n",
    "})\n",
    "\n",
    "# Save to project folder\n",
    "results_bham_poi_density.to_csv(\"data/combined_data/model_results_bham_poi_density.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e4dfa3-da73-4d14-8fc5-b121ae958d42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8c6f365-e57a-46df-a647-bff37403536c",
   "metadata": {},
   "source": [
    "### Attempt with Demographic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "97be3f20-5d83-4bc7-bb9b-a04f33adc25c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LSOA11CD</th>\n",
       "      <th>LSOA11NM</th>\n",
       "      <th>Index of Multiple Deprivation (IMD) Rank</th>\n",
       "      <th>Index of Multiple Deprivation (IMD) Decile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E01000001</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>29,199</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E01000002</td>\n",
       "      <td>City of London 001B</td>\n",
       "      <td>30,379</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E01000003</td>\n",
       "      <td>City of London 001C</td>\n",
       "      <td>14,915</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E01000005</td>\n",
       "      <td>City of London 001E</td>\n",
       "      <td>8,678</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E01000006</td>\n",
       "      <td>Barking and Dagenham 016A</td>\n",
       "      <td>14,486</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    LSOA11CD                   LSOA11NM  \\\n",
       "0  E01000001        City of London 001A   \n",
       "1  E01000002        City of London 001B   \n",
       "2  E01000003        City of London 001C   \n",
       "3  E01000005        City of London 001E   \n",
       "4  E01000006  Barking and Dagenham 016A   \n",
       "\n",
       "  Index of Multiple Deprivation (IMD) Rank  \\\n",
       "0                                   29,199   \n",
       "1                                   30,379   \n",
       "2                                   14,915   \n",
       "3                                    8,678   \n",
       "4                                   14,486   \n",
       "\n",
       "   Index of Multiple Deprivation (IMD) Decile  \n",
       "0                                           9  \n",
       "1                                          10  \n",
       "2                                           5  \n",
       "3                                           3  \n",
       "4                                           5  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Same Analysis on Education, Employment Status, and Multiple Deprivation Data\n",
    "\n",
    "general_health = pd.read_csv(\"data/lsoa_data/TS037_general_health.csv\", skiprows = 7, header = 0)\n",
    "employment_residential = pd.read_csv(\"data/lsoa_data/TS066_economic_activity_status.csv\", skiprows = 7, header = 0)\n",
    "education = pd.read_csv(\"data/lsoa_data/TS067_highest_qualification.csv\", skiprows = 7, header = 0)\n",
    "household_comp = pd.read_csv(\"data/lsoa_data/TS003_household_composition.csv\", skiprows = 6, header = 0)\n",
    "age_bands = pd.read_csv(\"data/lsoa_data/TS007B_age_broad_band.csv\", skiprows = 4, header = 0)\n",
    "english_lang = pd.read_csv(\"data/lsoa_data/TS029_english_language.csv\", skiprows = 6, header = 0)\n",
    "\n",
    "#Separate name into LSOA11CD and LSOA11NM (taken from DataCleaning.ipynb)\n",
    "def split_column(value):\n",
    "    if isinstance(value, str):\n",
    "        code, name = value.split(' : ')\n",
    "        return code.strip(), name.strip()\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "# Parse Code and Name out\n",
    "general_health[['LSOA11CD', 'LSOA11NM']] = general_health['2021 super output area - lower layer'].apply(lambda x: pd.Series(split_column(x)))\n",
    "employment_residential[['LSOA11CD', 'LSOA11NM']] = employment_residential['2021 super output area - lower layer'].apply(lambda x: pd.Series(split_column(x)))\n",
    "education[['LSOA11CD', 'LSOA11NM']] = education['2021 super output area - lower layer'].apply(lambda x: pd.Series(split_column(x)))\n",
    "household_comp[['LSOA11CD', 'LSOA11NM']] = household_comp['2021 super output area - lower layer'].apply(lambda x: pd.Series(split_column(x)))\n",
    "age_bands[['LSOA11CD', 'LSOA11NM']] = age_bands['2021 super output area - lower layer'].apply(lambda x: pd.Series(split_column(x)))\n",
    "english_lang[['LSOA11CD', 'LSOA11NM']] = english_lang['2021 super output area - lower layer'].apply(lambda x: pd.Series(split_column(x)))\n",
    "\n",
    "# Drop original column\n",
    "general_health = general_health.drop(columns=['2021 super output area - lower layer'])\n",
    "employment_residential = employment_residential.drop(columns=['2021 super output area - lower layer'])\n",
    "education = education.drop(columns=['2021 super output area - lower layer'])\n",
    "household_comp = household_comp.drop(columns=['2021 super output area - lower layer'])\n",
    "age_bands = age_bands.drop(columns=['2021 super output area - lower layer'])\n",
    "english_lang = english_lang.drop(columns=['2021 super output area - lower layer'])\n",
    "\n",
    "\n",
    "multiple_deprivation = pd.read_csv(\"data/lsoa_data/multiple_deprivation.csv\", header = 0)\n",
    "multiple_deprivation.rename(columns = {'LSOA code (2011)':'LSOA11CD', 'LSOA name (2011)':'LSOA11NM'}, inplace=True)\n",
    "multiple_deprivation = multiple_deprivation.drop(columns=[\"Local Authority District code (2019)\", \"Local Authority District name (2019)\"])\n",
    "\n",
    "\n",
    "multiple_deprivation.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "71b41bad-159d-47f7-bac9-3979d29972ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total: All usual residents</th>\n",
       "      <th>Very good health</th>\n",
       "      <th>Good health</th>\n",
       "      <th>Fair health</th>\n",
       "      <th>Bad health</th>\n",
       "      <th>Very bad health</th>\n",
       "      <th>LSOA11CD</th>\n",
       "      <th>LSOA11NM</th>\n",
       "      <th>Total: All usual residents aged 16 years and over</th>\n",
       "      <th>Economically active (excluding full-time students)</th>\n",
       "      <th>...</th>\n",
       "      <th>lag_veterinarian</th>\n",
       "      <th>lag_videographer</th>\n",
       "      <th>lag_vitamins_and_supplements</th>\n",
       "      <th>lag_warehouses</th>\n",
       "      <th>lag_waterproofing</th>\n",
       "      <th>lag_waxing</th>\n",
       "      <th>lag_wholesale_grocer</th>\n",
       "      <th>lag_wildlife_sanctuary</th>\n",
       "      <th>lag_wills_trusts_and_probate</th>\n",
       "      <th>lag_winery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>58.2</td>\n",
       "      <td>31.7</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>100.0</td>\n",
       "      <td>65.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100.0</td>\n",
       "      <td>60.4</td>\n",
       "      <td>30.6</td>\n",
       "      <td>6.7</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>E01000002</td>\n",
       "      <td>City of London 001B</td>\n",
       "      <td>100.0</td>\n",
       "      <td>69.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>36.4</td>\n",
       "      <td>11.5</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>E01000003</td>\n",
       "      <td>City of London 001C</td>\n",
       "      <td>100.0</td>\n",
       "      <td>70.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.0</td>\n",
       "      <td>45.5</td>\n",
       "      <td>35.3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>E01000005</td>\n",
       "      <td>City of London 001E</td>\n",
       "      <td>100.0</td>\n",
       "      <td>55.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100.0</td>\n",
       "      <td>64.6</td>\n",
       "      <td>28.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>E01032739</td>\n",
       "      <td>City of London 001F</td>\n",
       "      <td>100.0</td>\n",
       "      <td>78.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1177 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Total: All usual residents  Very good health  Good health  Fair health  \\\n",
       "0                      100.0              58.2         31.7          8.1   \n",
       "1                      100.0              60.4         30.6          6.7   \n",
       "2                      100.0              49.0         36.4         11.5   \n",
       "3                      100.0              45.5         35.3         12.0   \n",
       "4                      100.0              64.6         28.8          4.9   \n",
       "\n",
       "   Bad health  Very bad health   LSOA11CD             LSOA11NM  \\\n",
       "0         1.2              0.7  E01000001  City of London 001A   \n",
       "1         1.7              0.6  E01000002  City of London 001B   \n",
       "2         2.7              0.4  E01000003  City of London 001C   \n",
       "3         5.7              1.5  E01000005  City of London 001E   \n",
       "4         1.5              0.1  E01032739  City of London 001F   \n",
       "\n",
       "  Total: All usual residents aged 16 years and over  \\\n",
       "0                                             100.0   \n",
       "1                                             100.0   \n",
       "2                                             100.0   \n",
       "3                                             100.0   \n",
       "4                                             100.0   \n",
       "\n",
       "   Economically active (excluding full-time students)  ...  lag_veterinarian  \\\n",
       "0                                               65.7   ...          0.166667   \n",
       "1                                               69.3   ...          0.000000   \n",
       "2                                               70.3   ...          0.166667   \n",
       "3                                               55.8   ...          0.000000   \n",
       "4                                               78.4   ...          0.000000   \n",
       "\n",
       "   lag_videographer  lag_vitamins_and_supplements  lag_warehouses  \\\n",
       "0          0.333333                      0.000000        0.166667   \n",
       "1          0.000000                      0.333333        0.833333   \n",
       "2          0.166667                      0.000000        0.500000   \n",
       "3          0.000000                      0.000000        0.166667   \n",
       "4          0.000000                      0.000000        0.333333   \n",
       "\n",
       "   lag_waterproofing  lag_waxing  lag_wholesale_grocer  \\\n",
       "0                0.0    0.000000                   0.0   \n",
       "1                0.0    0.166667                   0.0   \n",
       "2                0.0    0.000000                   0.0   \n",
       "3                0.0    0.166667                   0.0   \n",
       "4                0.0    0.000000                   0.0   \n",
       "\n",
       "   lag_wildlife_sanctuary  lag_wills_trusts_and_probate  lag_winery  \n",
       "0                     0.0                      0.333333         0.0  \n",
       "1                     0.0                      0.166667         0.5  \n",
       "2                     0.0                      0.000000         0.0  \n",
       "3                     0.0                      0.000000         0.0  \n",
       "4                     0.0                      0.000000         0.5  \n",
       "\n",
       "[5 rows x 1177 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join all data together\n",
    "\n",
    "combined_census = pd.merge(general_health, employment_residential, on='LSOA11CD', suffixes=('', '_drop'))\n",
    "combined_census = pd.merge(combined_census, education, on='LSOA11CD', suffixes=('', '_drop'))\n",
    "combined_census = pd.merge(combined_census, household_comp, on='LSOA11CD', suffixes=('', '_drop'))\n",
    "combined_census = pd.merge(combined_census, age_bands, on='LSOA11CD', suffixes=('', '_drop'))\n",
    "combined_census = pd.merge(combined_census, english_lang, on='LSOA11CD', suffixes=('', '_drop'))\n",
    "combined_census = pd.merge(combined_census, multiple_deprivation, on='LSOA11CD', suffixes=('', '_drop'))\n",
    "\n",
    "# Get column lists\n",
    "combined_census = combined_census[[col for col in combined_census.columns if not col.endswith('_drop')]]\n",
    "combined_census_columns = list(combined_census.columns)\n",
    "exclude_columns = ['LSOA11CD', 'LSOA11NM', 'residual', 'Total: All usual residents', 'Total: All usual residents aged 16 years and over']\n",
    "census_feature_columns = [col for col in combined_census.columns if col not in exclude_columns]\n",
    "\n",
    "# Join with london and birmingham model output data\n",
    "combined_model = all_data_london\n",
    "combined_model = combined_model.drop(columns=['LSOA11NM'])\n",
    "combined_census = combined_census.merge(combined_model, on='LSOA11CD', how='inner')\n",
    "\n",
    "# Fix string rank data\n",
    "combined_census['Index of Multiple Deprivation (IMD) Rank'] = combined_census['Index of Multiple Deprivation (IMD) Rank'].str.replace(',', '')\n",
    "combined_census['Index of Multiple Deprivation (IMD) Rank']  = pd.to_numeric(combined_census['Index of Multiple Deprivation (IMD) Rank'] )   \n",
    "\n",
    "combined_census.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b0fb9ba4-5b58-4997-bb49-a45bd19d8f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model has already been fitted. You can use predict methods or select a new 'results_path' for a new 'fit()'.\n",
      "R^2 Score: 0.7474297689503127\n",
      "RMSE: 0.6102148294448853\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "array length 4659 does not match index length 4835",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[130], line 53\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m#Save results for plotting\u001b[39;00m\n\u001b[1;32m     51\u001b[0m predictions_all_23 \u001b[38;5;241m=\u001b[39m automl\u001b[38;5;241m.\u001b[39mpredict(combined_census[features])\n\u001b[0;32m---> 53\u001b[0m results_london_demographic \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlondon_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgeometry\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlondon_geometries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mobserved\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcombined_census\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpredicted\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions_all_23\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Save to project folder\u001b[39;00m\n\u001b[1;32m     61\u001b[0m results_london_demographic\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/combined_data/model_results_london_demographic.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/urbsim/lib/python3.11/site-packages/pandas/core/frame.py:733\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    727\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    728\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    729\u001b[0m     )\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 733\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[0;32m~/anaconda3/envs/urbsim/lib/python3.11/site-packages/pandas/core/internals/construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/urbsim/lib/python3.11/site-packages/pandas/core/internals/construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m~/anaconda3/envs/urbsim/lib/python3.11/site-packages/pandas/core/internals/construction.py:690\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lengths[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[1;32m    686\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    687\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray length \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlengths[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not match index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    688\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlength \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    689\u001b[0m         )\n\u001b[0;32m--> 690\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    692\u001b[0m     index \u001b[38;5;241m=\u001b[39m default_index(lengths[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[0;31mValueError\u001b[0m: array length 4659 does not match index length 4835"
     ]
    }
   ],
   "source": [
    "### Employment (log), NO Spatial Lag, London, Demographic Data\n",
    "\n",
    "# Ignore depracation warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london + census_feature_columns\n",
    "target = 'log_total_employment'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_census[features], combined_census[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/london_employment_demographic/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_23 = r2_score(y_test, predictions)\n",
    "rmse_23 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_23}')\n",
    "print(f'RMSE: {rmse_23}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_23 = automl.predict(combined_census[features])\n",
    "\n",
    "results_london_demographic = pd.DataFrame({\n",
    "    'name': london_names,\n",
    "    'geometry': london_geometries,\n",
    "    'observed': combined_census[target],\n",
    "    'predicted': predictions_all_23,\n",
    "})\n",
    "\n",
    "# Save to project folder\n",
    "results_london_demographic.to_csv(\"data/combined_data/model_results_london_demographic.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "urbsim",
   "language": "python",
   "name": "urbsim"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
