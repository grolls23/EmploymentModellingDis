{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7542fb7-3702-466a-8c2d-837e1e6d4ed3",
   "metadata": {},
   "source": [
    "# Modelling\n",
    "\n",
    "This is the script where I store all my ML model runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d305a93-526f-4ed4-993f-96d593fc9618",
   "metadata": {},
   "source": [
    "## Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b90b1626-165f-4b79-8d67-7b3afa023602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library Imports\n",
    "\n",
    "#Basics\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "#Shapely / Spatial\n",
    "from shapely import wkt\n",
    "import shapely.geometry\n",
    "from shapely.geometry import Polygon, MultiPolygon\n",
    "\n",
    "#Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#ML from mljar-supervised\n",
    "from supervised.automl import AutoML\n",
    "\n",
    "#Warning Supression\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31ea067-af33-4415-b9e7-4d3426573f62",
   "metadata": {},
   "source": [
    "### Import Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "53f05a2a-040b-45cd-8108-192d695dea50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>LSOA11CD</th>\n",
       "      <th>LSOA11NM_x</th>\n",
       "      <th>LSOA11NM_y</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>population</th>\n",
       "      <th>Area</th>\n",
       "      <th>01 : Crop and animal production, hunting and related service activities</th>\n",
       "      <th>02 : Forestry and logging</th>\n",
       "      <th>03 : Fishing and aquaculture</th>\n",
       "      <th>...</th>\n",
       "      <th>lag_travel</th>\n",
       "      <th>lag_travel_agents</th>\n",
       "      <th>lag_trusts</th>\n",
       "      <th>lag_university_housing</th>\n",
       "      <th>lag_used_vintage_and_consignment</th>\n",
       "      <th>lag_veterinarian</th>\n",
       "      <th>lag_videographer</th>\n",
       "      <th>lag_vitamins_and_supplements</th>\n",
       "      <th>lag_warehouses</th>\n",
       "      <th>lag_window_washing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>E01008881</td>\n",
       "      <td>Birmingham 067A</td>\n",
       "      <td>Birmingham 067A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1599</td>\n",
       "      <td>lsoa2011:E01008881 : Birmingham 067A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>E01008882</td>\n",
       "      <td>Birmingham 066A</td>\n",
       "      <td>Birmingham 066A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1747</td>\n",
       "      <td>lsoa2011:E01008882 : Birmingham 066A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>E01008883</td>\n",
       "      <td>Birmingham 078A</td>\n",
       "      <td>Birmingham 078A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1816</td>\n",
       "      <td>lsoa2011:E01008883 : Birmingham 078A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>E01008884</td>\n",
       "      <td>Birmingham 078B</td>\n",
       "      <td>Birmingham 078B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1870</td>\n",
       "      <td>lsoa2011:E01008884 : Birmingham 078B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>E01008885</td>\n",
       "      <td>Birmingham 076A</td>\n",
       "      <td>Birmingham 076A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1308</td>\n",
       "      <td>lsoa2011:E01008885 : Birmingham 076A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>634</td>\n",
       "      <td>E01033646</td>\n",
       "      <td>Birmingham 031I</td>\n",
       "      <td>Birmingham 031I</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1624</td>\n",
       "      <td>lsoa2011:E01033646 : Birmingham 031I</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>635</td>\n",
       "      <td>E01033647</td>\n",
       "      <td>Birmingham 058E</td>\n",
       "      <td>Birmingham 058E</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1398</td>\n",
       "      <td>lsoa2011:E01033647 : Birmingham 058E</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>636</td>\n",
       "      <td>E01033648</td>\n",
       "      <td>Birmingham 084F</td>\n",
       "      <td>Birmingham 084F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2715</td>\n",
       "      <td>lsoa2011:E01033648 : Birmingham 084F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>637</td>\n",
       "      <td>E01033649</td>\n",
       "      <td>Birmingham 058F</td>\n",
       "      <td>Birmingham 058F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1801</td>\n",
       "      <td>lsoa2011:E01033649 : Birmingham 058F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>638</td>\n",
       "      <td>E01033650</td>\n",
       "      <td>Birmingham 077F</td>\n",
       "      <td>Birmingham 077F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2596</td>\n",
       "      <td>lsoa2011:E01033650 : Birmingham 077F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>639 rows Ã— 742 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0   LSOA11CD       LSOA11NM_x       LSOA11NM_y  Unnamed: 2  \\\n",
       "0             0  E01008881  Birmingham 067A  Birmingham 067A         0.0   \n",
       "1             1  E01008882  Birmingham 066A  Birmingham 066A         0.0   \n",
       "2             2  E01008883  Birmingham 078A  Birmingham 078A         0.0   \n",
       "3             3  E01008884  Birmingham 078B  Birmingham 078B         0.0   \n",
       "4             4  E01008885  Birmingham 076A  Birmingham 076A         0.0   \n",
       "..          ...        ...              ...              ...         ...   \n",
       "634         634  E01033646  Birmingham 031I  Birmingham 031I         0.0   \n",
       "635         635  E01033647  Birmingham 058E  Birmingham 058E         0.0   \n",
       "636         636  E01033648  Birmingham 084F  Birmingham 084F         0.0   \n",
       "637         637  E01033649  Birmingham 058F  Birmingham 058F         0.0   \n",
       "638         638  E01033650  Birmingham 077F  Birmingham 077F         0.0   \n",
       "\n",
       "     population                                  Area  \\\n",
       "0          1599  lsoa2011:E01008881 : Birmingham 067A   \n",
       "1          1747  lsoa2011:E01008882 : Birmingham 066A   \n",
       "2          1816  lsoa2011:E01008883 : Birmingham 078A   \n",
       "3          1870  lsoa2011:E01008884 : Birmingham 078B   \n",
       "4          1308  lsoa2011:E01008885 : Birmingham 076A   \n",
       "..          ...                                   ...   \n",
       "634        1624  lsoa2011:E01033646 : Birmingham 031I   \n",
       "635        1398  lsoa2011:E01033647 : Birmingham 058E   \n",
       "636        2715  lsoa2011:E01033648 : Birmingham 084F   \n",
       "637        1801  lsoa2011:E01033649 : Birmingham 058F   \n",
       "638        2596  lsoa2011:E01033650 : Birmingham 077F   \n",
       "\n",
       "     01 : Crop and animal production, hunting and related service activities  \\\n",
       "0                                                  0.0                         \n",
       "1                                                  0.0                         \n",
       "2                                                  0.0                         \n",
       "3                                                  0.0                         \n",
       "4                                                  0.0                         \n",
       "..                                                 ...                         \n",
       "634                                                0.0                         \n",
       "635                                                0.0                         \n",
       "636                                                0.0                         \n",
       "637                                                0.0                         \n",
       "638                                                0.0                         \n",
       "\n",
       "     02 : Forestry and logging  03 : Fishing and aquaculture  ...  lag_travel  \\\n",
       "0                          0.0                           0.0  ...    0.000000   \n",
       "1                          0.0                           0.0  ...    0.166667   \n",
       "2                          0.0                           0.0  ...    0.166667   \n",
       "3                          0.0                           0.0  ...    0.333333   \n",
       "4                          0.0                           0.0  ...    0.000000   \n",
       "..                         ...                           ...  ...         ...   \n",
       "634                        0.0                           0.0  ...    0.166667   \n",
       "635                        0.0                           0.0  ...    0.166667   \n",
       "636                        0.0                           0.0  ...    0.000000   \n",
       "637                        0.0                           0.0  ...    0.333333   \n",
       "638                        0.0                           0.0  ...    0.000000   \n",
       "\n",
       "     lag_travel_agents  lag_trusts  lag_university_housing  \\\n",
       "0             0.166667         0.0                     0.0   \n",
       "1             0.000000         0.0                     0.0   \n",
       "2             0.000000         0.0                     0.0   \n",
       "3             0.000000         0.0                     0.0   \n",
       "4             0.166667         0.0                     0.0   \n",
       "..                 ...         ...                     ...   \n",
       "634           0.000000         0.0                     0.0   \n",
       "635           0.000000         0.0                     0.0   \n",
       "636           0.000000         0.0                     0.0   \n",
       "637           0.000000         0.0                     0.0   \n",
       "638           0.000000         0.0                     0.0   \n",
       "\n",
       "     lag_used_vintage_and_consignment  lag_veterinarian  lag_videographer  \\\n",
       "0                                 0.0               0.0               0.0   \n",
       "1                                 0.0               0.0               0.0   \n",
       "2                                 0.0               0.0               0.0   \n",
       "3                                 0.0               0.0               0.0   \n",
       "4                                 0.0               0.0               0.0   \n",
       "..                                ...               ...               ...   \n",
       "634                               0.0               0.0               0.0   \n",
       "635                               0.0               0.0               0.0   \n",
       "636                               0.0               0.0               0.0   \n",
       "637                               0.0               0.0               0.0   \n",
       "638                               0.0               0.0               0.0   \n",
       "\n",
       "     lag_vitamins_and_supplements  lag_warehouses  lag_window_washing  \n",
       "0                        0.000000        0.333333                 0.0  \n",
       "1                        0.000000        0.500000                 0.0  \n",
       "2                        0.000000        0.000000                 0.0  \n",
       "3                        0.166667        0.500000                 0.0  \n",
       "4                        0.000000        0.000000                 0.0  \n",
       "..                            ...             ...                 ...  \n",
       "634                      0.166667        0.000000                 0.0  \n",
       "635                      0.000000        0.000000                 0.0  \n",
       "636                      0.000000        0.000000                 0.0  \n",
       "637                      0.166667        0.000000                 0.0  \n",
       "638                      0.000000        0.000000                 0.0  \n",
       "\n",
       "[639 rows x 742 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read London CSV\n",
    "all_data_london = pd.read_csv(\"data/combined_data/lag/all_data_london_lag.csv\")\n",
    "\n",
    "# Read in feature column set\n",
    "with open(\"data/combined_data/total_feature_columns_london.csv\", 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Reconstruct\n",
    "feature_columns_london_lag = [''.join(line.strip().split(',')) for line in lines]\n",
    "\n",
    "# Create non-laged column set\n",
    "feature_columns_london = [col for col in feature_columns_london_lag if not col.startswith('lag_')]\n",
    "\n",
    "# ---\n",
    "\n",
    "# Read Birmingham CSV\n",
    "all_data_bham = pd.read_csv(\"data/combined_data/lag/all_data_bham_lag.csv\")\n",
    "\n",
    "# Read in feature column set\n",
    "with open(\"data/combined_data/total_feature_columns_bham.csv\", 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Reconstruct\n",
    "feature_columns_bham_lag = [''.join(line.strip().split(',')) for line in lines]\n",
    "\n",
    "# Create non-lagged column set\n",
    "feature_columns_bham = [col for col in feature_columns_bham_lag if not col.startswith('lag_')]\n",
    "\n",
    "# Fix null values ending up in logged variables\n",
    "all_data_london.fillna(0)\n",
    "all_data_bham.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "581a5ad1-f57d-4764-b71b-568a4e4f8c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Download POI & auxillary-only feature spaces (No building footprint information)\n",
    "\n",
    "# London\n",
    "# Read in POI feature column set\n",
    "with open(\"data/combined_data/feature_columns_london_poi.csv\", 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Reconstruct\n",
    "feature_columns_london_poi = [''.join(line.strip().split(',')) for line in lines]\n",
    "\n",
    "# Birmingham\n",
    "# Read in POI feature column set\n",
    "with open(\"data/combined_data/feature_columns_bham_poi.csv\", 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Reconstruct\n",
    "feature_columns_bham_poi = [''.join(line.strip().split(',')) for line in lines]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5488444a-67fc-4aca-8e79-065018e090cb",
   "metadata": {},
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e93f99a8-c74f-4436-8877-6d11cc2f3103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model has already been fitted. You can use predict methods or select a new 'results_path' for a new 'fit()'.\n",
      "R^2 Score: 0.7207009026018532\n",
      "RMSE: 0.678412914276123\n"
     ]
    }
   ],
   "source": [
    "# Ignore depracation warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london_lag\n",
    "target = 'log_total_employment'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(results_path=\"ml_results/dummy_models/test\", mode='Explain')\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_log_employment = r2_score(y_test, predictions)\n",
    "rmse_log_employment = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_log_employment}')\n",
    "print(f'RMSE: {rmse_log_employment}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all = automl.predict(all_data_london[features])\n",
    "geometries = all_data_london.loc[all_data_london[target].index, 'geometry']\n",
    "\n",
    "results_test = pd.DataFrame({\n",
    "    'geometry': geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca014449-6c4c-46d6-ba87-a578cbb9881d",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce02ced4-41b4-46d0-89da-b9900f64442d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: ml_results/log_employment_london/\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['CatBoost', 'Xgboost', 'Random Forest']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "1_Default_Xgboost rmse 0.670873 trained in 41.97 seconds\n",
      "2_Default_CatBoost rmse 0.665232 trained in 60.41 seconds\n",
      "3_Default_RandomForest rmse 0.701146 trained in 49.48 seconds\n",
      "* Step not_so_random will try to check up to 12 models\n",
      "4_Xgboost rmse 0.67397 trained in 39.45 seconds\n",
      "8_CatBoost rmse 0.664846 trained in 63.71 seconds\n",
      "12_RandomForest rmse 0.704978 trained in 80.23 seconds\n",
      "5_Xgboost rmse 0.686213 trained in 65.79 seconds\n",
      "9_CatBoost rmse 0.669095 trained in 81.25 seconds\n",
      "13_RandomForest rmse 0.72372 trained in 53.77 seconds\n",
      "6_Xgboost rmse 0.668105 trained in 36.24 seconds\n",
      "10_CatBoost rmse 0.669253 trained in 51.68 seconds\n",
      "14_RandomForest rmse 0.692957 trained in 51.66 seconds\n",
      "7_Xgboost rmse 0.676092 trained in 43.45 seconds\n",
      "11_CatBoost rmse 0.681545 trained in 71.21 seconds\n",
      "15_RandomForest rmse 0.68867 trained in 55.77 seconds\n",
      "* Step hill_climbing_1 will try to check up to 16 models\n",
      "16_CatBoost rmse 0.665654 trained in 88.59 seconds\n",
      "17_CatBoost rmse 0.668122 trained in 60.59 seconds\n",
      "18_CatBoost rmse 0.66023 trained in 65.29 seconds\n",
      "19_CatBoost rmse 0.674746 trained in 73.55 seconds\n",
      "20_Xgboost rmse 0.66376 trained in 36.33 seconds\n",
      "21_Xgboost rmse 0.668625 trained in 39.14 seconds\n",
      "22_CatBoost rmse 0.671474 trained in 85.57 seconds\n",
      "23_Xgboost rmse 0.666604 trained in 46.13 seconds\n",
      "24_Xgboost rmse 0.677411 trained in 36.9 seconds\n",
      "25_Xgboost rmse 0.672273 trained in 37.63 seconds\n",
      "26_Xgboost rmse 0.67952 trained in 51.27 seconds\n",
      "27_RandomForest rmse 0.688868 trained in 60.76 seconds\n",
      "28_RandomForest rmse 0.691155 trained in 64.31 seconds\n",
      "29_RandomForest rmse 0.694844 trained in 60.43 seconds\n",
      "30_RandomForest rmse 0.700444 trained in 73.47 seconds\n",
      "31_RandomForest rmse 0.702977 trained in 65.34 seconds\n",
      "* Step hill_climbing_2 will try to check up to 11 models\n",
      "32_CatBoost rmse 0.663098 trained in 73.17 seconds\n",
      "33_Xgboost rmse 0.664417 trained in 45.86 seconds\n",
      "34_Xgboost rmse 0.668288 trained in 40.37 seconds\n",
      "35_CatBoost rmse 0.666529 trained in 79.51 seconds\n",
      "36_CatBoost rmse 0.66529 trained in 67.04 seconds\n",
      "37_CatBoost rmse 0.665751 trained in 67.79 seconds\n",
      "38_Xgboost rmse 0.665752 trained in 48.61 seconds\n",
      "39_Xgboost rmse 0.668809 trained in 48.36 seconds\n",
      "40_Xgboost rmse 0.668185 trained in 52.85 seconds\n",
      "41_RandomForest rmse 0.688619 trained in 47.04 seconds\n",
      "42_RandomForest rmse 0.689239 trained in 70.48 seconds\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble rmse 0.653576 trained in 1.48 seconds\n",
      "AutoML fit time: 2456.73 seconds\n",
      "AutoML best model: Ensemble\n",
      "R^2 Score: 0.7310639407939545\n",
      "RMSE: 0.6657081246376038\n"
     ]
    }
   ],
   "source": [
    "### Employment (log), NO Spatial Lag, London (1)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london\n",
    "target = 'log_total_employment'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/log_employment_london/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_1 = r2_score(y_test, predictions)\n",
    "rmse_1 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_1}')\n",
    "print(f'RMSE: {rmse_1}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_1 = automl.predict(all_data_london[features])\n",
    "london_geometries = all_data_london.loc[all_data_london[target].index, 'geometry']\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': london_geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all_1,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac80575c-2245-4464-abdd-a8997967e727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: ml_results/log_employment_bham/\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['CatBoost', 'Xgboost', 'Random Forest']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "1_Default_Xgboost rmse 0.795926 trained in 6.59 seconds\n",
      "2_Default_CatBoost rmse 0.80568 trained in 19.24 seconds\n",
      "3_Default_RandomForest rmse 0.817785 trained in 18.5 seconds\n",
      "* Step not_so_random will try to check up to 12 models\n",
      "4_Xgboost rmse 0.816981 trained in 6.21 seconds\n",
      "8_CatBoost rmse 0.833023 trained in 28.18 seconds\n",
      "12_RandomForest rmse 0.81406 trained in 29.38 seconds\n",
      "5_Xgboost rmse 0.819868 trained in 6.84 seconds\n",
      "9_CatBoost rmse 0.865532 trained in 19.37 seconds\n",
      "13_RandomForest rmse 0.843877 trained in 25.56 seconds\n",
      "6_Xgboost rmse 0.795246 trained in 5.67 seconds\n",
      "10_CatBoost rmse 0.819984 trained in 20.38 seconds\n",
      "14_RandomForest rmse 0.817334 trained in 29.22 seconds\n",
      "7_Xgboost rmse 0.85528 trained in 7.29 seconds\n",
      "11_CatBoost rmse 0.856028 trained in 21.41 seconds\n",
      "15_RandomForest rmse 0.825376 trained in 17.0 seconds\n",
      "* Step hill_climbing_1 will try to check up to 18 models\n",
      "16_Xgboost rmse 0.794186 trained in 5.64 seconds\n",
      "17_Xgboost rmse 0.796791 trained in 4.9 seconds\n",
      "18_Xgboost rmse 0.789748 trained in 5.2 seconds\n",
      "19_Xgboost rmse 0.81286 trained in 6.48 seconds\n",
      "20_CatBoost rmse 0.800144 trained in 18.54 seconds\n",
      "21_CatBoost rmse 0.809845 trained in 19.86 seconds\n",
      "22_RandomForest rmse 0.814971 trained in 20.01 seconds\n",
      "23_RandomForest rmse 0.818509 trained in 22.16 seconds\n",
      "24_Xgboost rmse 0.804184 trained in 7.77 seconds\n",
      "25_Xgboost rmse 0.821259 trained in 7.35 seconds\n",
      "26_RandomForest rmse 0.809474 trained in 26.5 seconds\n",
      "27_RandomForest rmse 0.829945 trained in 27.3 seconds\n",
      "28_RandomForest rmse 0.812138 trained in 28.86 seconds\n",
      "29_RandomForest rmse 0.824722 trained in 21.99 seconds\n",
      "30_CatBoost rmse 0.811672 trained in 20.78 seconds\n",
      "31_CatBoost rmse 0.824246 trained in 17.99 seconds\n",
      "32_CatBoost rmse 0.82462 trained in 33.54 seconds\n",
      "33_CatBoost rmse 0.832533 trained in 33.32 seconds\n",
      "* Step hill_climbing_2 will try to check up to 10 models\n",
      "34_Xgboost rmse 0.794306 trained in 6.28 seconds\n",
      "35_Xgboost rmse 0.785843 trained in 10.18 seconds\n",
      "36_Xgboost rmse 0.799358 trained in 10.86 seconds\n",
      "37_Xgboost rmse 0.78635 trained in 8.23 seconds\n",
      "38_Xgboost rmse 0.80198 trained in 9.18 seconds\n",
      "39_CatBoost rmse 0.799588 trained in 28.21 seconds\n",
      "40_RandomForest rmse 0.806315 trained in 27.1 seconds\n",
      "41_RandomForest rmse 0.81292 trained in 25.86 seconds\n",
      "42_RandomForest rmse 0.814413 trained in 29.42 seconds\n",
      "43_RandomForest rmse 0.815038 trained in 26.22 seconds\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble rmse 0.770789 trained in 0.99 seconds\n",
      "AutoML fit time: 796.13 seconds\n",
      "AutoML best model: Ensemble\n",
      "R^2 Score: 0.6337440008378226\n",
      "RMSE: 0.7203816771507263\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'bham_geometries' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 51\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m#Save results for plotting\u001b[39;00m\n\u001b[1;32m     48\u001b[0m predictions_all_2 \u001b[38;5;241m=\u001b[39m automl\u001b[38;5;241m.\u001b[39mpredict(all_data_bham[features])\n\u001b[1;32m     50\u001b[0m results_office_density_cleaned_perform \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mbham_geometries\u001b[49m,\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobserved\u001b[39m\u001b[38;5;124m'\u001b[39m: all_data_bham[target],\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted\u001b[39m\u001b[38;5;124m'\u001b[39m: predictions_all_2,\n\u001b[1;32m     54\u001b[0m })\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bham_geometries' is not defined"
     ]
    }
   ],
   "source": [
    "### Employment (log), NO Spatial Lag, Birmingham (2)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_bham\n",
    "target = 'log_total_employment'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_bham[features], all_data_bham[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/log_employment_bham/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_2 = r2_score(y_test, predictions)\n",
    "rmse_2 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_2}')\n",
    "print(f'RMSE: {rmse_2}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_2 = automl.predict(all_data_bham[features])\n",
    "bham_geometries = all_data_bham.loc[all_data_bham[target].index, 'geometry']\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': bham_geometries,\n",
    "    'observed': all_data_bham[target],\n",
    "    'predicted': predictions_all_2,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cbef0bf3-04a1-489c-ae7b-5552895992bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: ml_results/log_employment_london_lag/\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['CatBoost', 'Xgboost', 'Random Forest']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "1_Default_Xgboost rmse 0.670873 trained in 37.76 seconds\n",
      "2_Default_CatBoost rmse 0.665232 trained in 58.75 seconds\n",
      "3_Default_RandomForest rmse 0.701146 trained in 55.51 seconds\n",
      "* Step not_so_random will try to check up to 12 models\n",
      "4_Xgboost rmse 0.67397 trained in 48.12 seconds\n",
      "8_CatBoost rmse 0.664846 trained in 138.48 seconds\n",
      "12_RandomForest rmse 0.704978 trained in 77.43 seconds\n",
      "5_Xgboost rmse 0.686213 trained in 52.46 seconds\n",
      "9_CatBoost rmse 0.669095 trained in 91.01 seconds\n",
      "13_RandomForest rmse 0.72372 trained in 56.85 seconds\n",
      "6_Xgboost rmse 0.668105 trained in 54.86 seconds\n",
      "10_CatBoost rmse 0.669253 trained in 78.18 seconds\n",
      "14_RandomForest rmse 0.692957 trained in 73.84 seconds\n",
      "7_Xgboost rmse 0.676092 trained in 43.56 seconds\n",
      "11_CatBoost rmse 0.681545 trained in 64.33 seconds\n",
      "15_RandomForest rmse 0.68867 trained in 49.79 seconds\n",
      "* Step hill_climbing_1 will try to check up to 16 models\n",
      "16_CatBoost rmse 0.665654 trained in 100.97 seconds\n",
      "17_CatBoost rmse 0.668122 trained in 76.82 seconds\n",
      "18_CatBoost rmse 0.66023 trained in 99.76 seconds\n",
      "19_CatBoost rmse 0.674746 trained in 74.34 seconds\n",
      "20_Xgboost rmse 0.66376 trained in 57.55 seconds\n",
      "21_Xgboost rmse 0.668625 trained in 55.6 seconds\n",
      "22_CatBoost rmse 0.671474 trained in 110.99 seconds\n",
      "23_Xgboost rmse 0.666604 trained in 47.87 seconds\n",
      "24_Xgboost rmse 0.677411 trained in 56.85 seconds\n",
      "25_Xgboost rmse 0.672273 trained in 56.97 seconds\n",
      "26_Xgboost rmse 0.67952 trained in 58.92 seconds\n",
      "27_RandomForest rmse 0.688868 trained in 79.59 seconds\n",
      "28_RandomForest rmse 0.691155 trained in 82.17 seconds\n",
      "29_RandomForest rmse 0.694844 trained in 71.31 seconds\n",
      "30_RandomForest rmse 0.700444 trained in 82.05 seconds\n",
      "31_RandomForest rmse 0.702977 trained in 76.65 seconds\n",
      "* Step hill_climbing_2 will try to check up to 11 models\n",
      "32_CatBoost rmse 0.663098 trained in 93.98 seconds\n",
      "33_Xgboost rmse 0.664417 trained in 51.11 seconds\n",
      "34_Xgboost rmse 0.668288 trained in 40.19 seconds\n",
      "35_CatBoost rmse 0.666529 trained in 115.74 seconds\n",
      "36_CatBoost rmse 0.66529 trained in 128.18 seconds\n",
      "37_CatBoost rmse 0.665751 trained in 107.66 seconds\n",
      "38_Xgboost rmse 0.665752 trained in 92.7 seconds\n",
      "39_Xgboost rmse 0.668809 trained in 87.64 seconds\n",
      "40_Xgboost rmse 0.668185 trained in 54.58 seconds\n",
      "41_RandomForest rmse 0.688619 trained in 74.97 seconds\n",
      "42_RandomForest rmse 0.689239 trained in 89.72 seconds\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble rmse 0.653576 trained in 1.39 seconds\n",
      "AutoML fit time: 3134.13 seconds\n",
      "AutoML best model: Ensemble\n",
      "R^2 Score: 0.7310639407939545\n",
      "RMSE: 0.6657081246376038\n"
     ]
    }
   ],
   "source": [
    "### Employment (log), Spatial Lag, London (3)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london_lag\n",
    "target = 'log_total_employment'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/log_employment_london_lag/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_3 = r2_score(y_test, predictions)\n",
    "rmse_3 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_3}')\n",
    "print(f'RMSE: {rmse_3}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_3 = automl.predict(all_data_london[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': london_geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all_3,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c5e16db-a923-45df-96fe-aa63e186fa14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML directory: ml_results/log_employment_bham_lag/\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['CatBoost', 'Xgboost', 'Random Forest']\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
      "Skip simple_algorithms because no parameters were generated.\n",
      "* Step default_algorithms will try to check up to 3 models\n",
      "1_Default_Xgboost rmse 0.795926 trained in 8.8 seconds\n",
      "2_Default_CatBoost rmse 0.80568 trained in 19.88 seconds\n",
      "3_Default_RandomForest rmse 0.817785 trained in 21.62 seconds\n",
      "* Step not_so_random will try to check up to 12 models\n",
      "4_Xgboost rmse 0.816981 trained in 9.77 seconds\n",
      "8_CatBoost rmse 0.833023 trained in 26.56 seconds\n",
      "12_RandomForest rmse 0.81406 trained in 34.01 seconds\n",
      "5_Xgboost rmse 0.819868 trained in 7.6 seconds\n",
      "9_CatBoost rmse 0.865532 trained in 24.66 seconds\n",
      "13_RandomForest rmse 0.843877 trained in 29.34 seconds\n",
      "6_Xgboost rmse 0.795246 trained in 6.28 seconds\n",
      "10_CatBoost rmse 0.819984 trained in 20.93 seconds\n",
      "14_RandomForest rmse 0.817334 trained in 27.97 seconds\n",
      "7_Xgboost rmse 0.85528 trained in 6.29 seconds\n",
      "11_CatBoost rmse 0.856028 trained in 23.23 seconds\n",
      "15_RandomForest rmse 0.825376 trained in 19.38 seconds\n",
      "* Step hill_climbing_1 will try to check up to 18 models\n",
      "16_Xgboost rmse 0.794186 trained in 5.88 seconds\n",
      "17_Xgboost rmse 0.796791 trained in 5.9 seconds\n",
      "18_Xgboost rmse 0.789748 trained in 5.52 seconds\n",
      "19_Xgboost rmse 0.81286 trained in 6.17 seconds\n",
      "20_CatBoost rmse 0.800144 trained in 21.32 seconds\n",
      "21_CatBoost rmse 0.809845 trained in 23.26 seconds\n",
      "22_RandomForest rmse 0.814971 trained in 21.54 seconds\n",
      "23_RandomForest rmse 0.818509 trained in 25.18 seconds\n",
      "24_Xgboost rmse 0.804184 trained in 5.85 seconds\n",
      "25_Xgboost rmse 0.821259 trained in 7.43 seconds\n",
      "26_RandomForest rmse 0.809474 trained in 27.84 seconds\n",
      "27_RandomForest rmse 0.829945 trained in 24.74 seconds\n",
      "28_RandomForest rmse 0.812138 trained in 23.66 seconds\n",
      "29_RandomForest rmse 0.824722 trained in 17.65 seconds\n",
      "30_CatBoost rmse 0.811672 trained in 21.68 seconds\n",
      "31_CatBoost rmse 0.824246 trained in 20.59 seconds\n",
      "32_CatBoost rmse 0.82462 trained in 30.44 seconds\n",
      "33_CatBoost rmse 0.832533 trained in 21.18 seconds\n",
      "* Step hill_climbing_2 will try to check up to 10 models\n",
      "34_Xgboost rmse 0.794306 trained in 5.45 seconds\n",
      "35_Xgboost rmse 0.785843 trained in 5.68 seconds\n",
      "36_Xgboost rmse 0.799358 trained in 5.26 seconds\n",
      "37_Xgboost rmse 0.78635 trained in 6.09 seconds\n",
      "38_Xgboost rmse 0.80198 trained in 6.07 seconds\n",
      "39_CatBoost rmse 0.799588 trained in 19.49 seconds\n",
      "40_RandomForest rmse 0.806315 trained in 20.84 seconds\n",
      "41_RandomForest rmse 0.81292 trained in 21.69 seconds\n",
      "42_RandomForest rmse 0.814413 trained in 22.99 seconds\n",
      "43_RandomForest rmse 0.815038 trained in 22.26 seconds\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble rmse 0.770789 trained in 1.07 seconds\n",
      "AutoML fit time: 761.22 seconds\n",
      "AutoML best model: Ensemble\n",
      "R^2 Score: 0.6337440008378226\n",
      "RMSE: 0.7203816771507263\n"
     ]
    }
   ],
   "source": [
    "### Employment (log), Spatial Lag, Birmingham (4)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_bham_lag\n",
    "target = 'log_total_employment'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_bham[features], all_data_bham[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/log_employment_bham_lag/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_4 = r2_score(y_test, predictions)\n",
    "rmse_4 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_4}')\n",
    "print(f'RMSE: {rmse_4}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_4 = automl.predict(all_data_bham[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': bham_geometries,\n",
    "    'observed': all_data_bham[target],\n",
    "    'predicted': predictions_all_4,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e39466b-44a3-4721-b6c1-4ad1484b0f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Employment Density, NO Spatial Lag, London (5)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london\n",
    "target = 'employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/employment_density_london/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_5 = r2_score(y_test, predictions)\n",
    "rmse_5 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_5}')\n",
    "print(f'RMSE: {rmse_5}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_5 = automl.predict(all_data_london[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': london_geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all_5,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1faae03a-3177-4923-a949-53cae255a64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Employment Density, NO Spatial Lag, Birmingham (6)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_bham\n",
    "target = 'employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_bham[features], all_data_bham[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/employment_density_bham/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_6 = r2_score(y_test, predictions)\n",
    "rmse_6 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_6}')\n",
    "print(f'RMSE: {rmse_6}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_6 = automl.predict(all_data_bham[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': bham_geometries,\n",
    "    'observed': all_data_bham[target],\n",
    "    'predicted': predictions_all_6,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907fde61-ed19-43a6-b9b6-3951fb0bd473",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Employment Density, Spatial Lag, London (7)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london_lag\n",
    "target = 'employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/employment_density_london_lag/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_7 = r2_score(y_test, predictions)\n",
    "rmse_7 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_7}')\n",
    "print(f'RMSE: {rmse_7}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_5 = automl.predict(all_data_london[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': london_geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all_7,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bb150e-d907-41c8-a5cb-2d3d0e065417",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Employment Density, Spatial Lag, Birmingham (8)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_bham_lag\n",
    "target = 'employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_bham[features], all_data_bham[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/employment_density_bham_lag/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_8 = r2_score(y_test, predictions)\n",
    "rmse_8 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_8}')\n",
    "print(f'RMSE: {rmse_8}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_8 = automl.predict(all_data_bham[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': bham_geometries,\n",
    "    'observed': all_data_bham[target],\n",
    "    'predicted': predictions_all_8,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6e4682-7e10-4638-bb3c-a08c426b9f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Office Employment Density , NO Spatial Lag, London (9)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london\n",
    "target = 'office_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/office_employment_density_london/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_9 = r2_score(y_test, predictions)\n",
    "rmse_9 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_9}')\n",
    "print(f'RMSE: {rmse_9}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_9 = automl.predict(all_data_london[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': london_geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all_9,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015c372b-1b93-4550-b7f5-ece1ad3149b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Office Employment Density , NO Spatial Lag, Birmingham (10)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_bham\n",
    "target = 'office_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_bham[features], all_data_bham[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/office_employment_density_bham/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_10 = r2_score(y_test, predictions)\n",
    "rmse_10 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_10}')\n",
    "print(f'RMSE: {rmse_10}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_10 = automl.predict(all_data_bham[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': bham_geometries,\n",
    "    'observed': all_data_bham[target],\n",
    "    'predicted': predictions_all_10,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3160a4-8d0e-4048-acb5-a9f8e51ef901",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Office Employment Density, Spatial Lag, London (11)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london_lag\n",
    "target = 'office_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/office_employment_density_london_lag/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_11 = r2_score(y_test, predictions)\n",
    "rmse_11 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_11}')\n",
    "print(f'RMSE: {rmse_11}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_11 = automl.predict(all_data_london[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': london_geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all_11,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c793ac54-59e8-4ff0-b95a-0bb60d1edd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Office Employment Density (log), Spatial Lag, Birmingham (12)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_bham_lag\n",
    "target = 'office_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_bham[features], all_data_bham[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/office_employment_density_bham_lag/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_12 = r2_score(y_test, predictions)\n",
    "rmse_12 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_12}')\n",
    "print(f'RMSE: {rmse_12}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_12 = automl.predict(all_data_bham[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': bham_geometries,\n",
    "    'observed': all_data_bham[target],\n",
    "    'predicted': predictions_all_12,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0592585-a869-42b2-9ccd-c7ebe0bef895",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Employment (log), NO Spatial Lag, London, POI only (13)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london_poi\n",
    "target = 'log_total_employment'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/log_employment_london_poi/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_13 = r2_score(y_test, predictions)\n",
    "rmse_13 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_13}')\n",
    "print(f'RMSE: {rmse_13}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_13 = automl.predict(all_data_london[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': london_geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all_13,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ff96c6-9be8-4705-83e2-67f8876eb238",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Employment (log), NO Spatial Lag, Brimingham, POI only (14)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_bham_poi\n",
    "target = 'log_total_employment'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_bham[features], all_data_bham[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/log_employment_bham_poi/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_14 = r2_score(y_test, predictions)\n",
    "rmse_14 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_14}')\n",
    "print(f'RMSE: {rmse_14}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_14 = automl.predict(all_data_bham[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': bham_geometries,\n",
    "    'observed': all_data_bham[target],\n",
    "    'predicted': predictions_all_14,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4bf1d6-902a-4011-b805-4e1d2df8644e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Employment Density, NO Spatial Lag, London, POI only (15)\n",
    "\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london_poi\n",
    "target = 'employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/employment_density_london_poi/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_15 = r2_score(y_test, predictions)\n",
    "rmse_15 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_15}')\n",
    "print(f'RMSE: {rmse_15}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_15 = automl.predict(all_data_london[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': london_geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all_15,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b18222-1efa-4451-b8a1-5d26ba8f83cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Employment Density, NO Spatial Lag, Brimingham, POI only (16)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_bham_poi\n",
    "target = 'employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_bham[features], all_data_bham[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/employment_density_bham_poi/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_16 = r2_score(y_test, predictions)\n",
    "rmse_16 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_16}')\n",
    "print(f'RMSE: {rmse_16}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_16 = automl.predict(all_data_bham[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': bham_geometries,\n",
    "    'observed': all_data_bham[target],\n",
    "    'predicted': predictions_all_16,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154710f6-e527-4512-8861-573d0f26d504",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Office Employment Density, NO Spatial Lag, London, POI only (17)\n",
    "\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_london_poi\n",
    "target = 'office_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_london[features], all_data_london[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/office_employment_density_london_poi/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_17 = r2_score(y_test, predictions)\n",
    "rmse_17 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_17}')\n",
    "print(f'RMSE: {rmse_17}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_17 = automl.predict(all_data_london[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': london_geometries,\n",
    "    'observed': all_data_london[target],\n",
    "    'predicted': predictions_all_17,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27df441e-a493-4c24-88e7-a302f6e05843",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Office Employment Density, NO Spatial Lag, Birmingham, POI only (18)\n",
    "\n",
    "# Create training and testing data\n",
    "features = feature_columns_bham_poi\n",
    "target = 'office_employment_density'\n",
    "\n",
    "# Split the dataset - 80/20 train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_bham[features], all_data_bham[target], test_size=0.2, random_state=3)\n",
    "\n",
    "automl = AutoML(\n",
    "    results_path ='ml_results/office_employment_density_bham_poi/',\n",
    "    algorithms=[\"CatBoost\", \"Xgboost\", \"Random Forest\"],\n",
    "    model_time_limit=1*60,\n",
    "    start_random_models=5,\n",
    "    hill_climbing_steps=2,\n",
    "    top_models_to_improve=3,\n",
    "    features_selection=False,\n",
    "    stack_models=False,\n",
    "    train_ensemble=True,\n",
    "    explain_level=1,\n",
    "    validation_strategy={\n",
    "        \"validation_type\": \"kfold\",\n",
    "        \"k_folds\": 4,\n",
    "        \"shuffle\": False,\n",
    "        \"stratify\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "predictions = automl.predict(X_test)\n",
    "predictions = predictions.astype(np.float32)\n",
    "\n",
    "# Fix NaN values\n",
    "y_test = y_test.fillna(0)\n",
    "\n",
    "r2_18 = r2_score(y_test, predictions)\n",
    "rmse_18 = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(f'R^2 Score: {r2_18}')\n",
    "print(f'RMSE: {rmse_18}')\n",
    "\n",
    "#Save results for plotting\n",
    "predictions_all_10 = automl.predict(all_data_bham[features])\n",
    "\n",
    "results_office_density_cleaned_perform = pd.DataFrame({\n",
    "    'geometry': bham_geometries,\n",
    "    'observed': all_data_bham[target],\n",
    "    'predicted': predictions_all_18,\n",
    "})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "urbsim",
   "language": "python",
   "name": "urbsim"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
